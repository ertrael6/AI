<a name="br1"></a> 

**OneTrainer – Kompletny Przewodnik (Polski)**

**Wprowadzenie**

OneTrainer (OT) to kompleksowe narzędzie do trenowania modeli generatywnych (Stable Diﬀusion) z

przyjaznym interfejsem graﬁcznym (GUI) oraz trybem konsolowym (CLI). Pozwala na pełne dostrajanie

modeli (ﬁne-tuning), trenowanie LoRA (Low-Rank Adaptation) oraz wgrywanie tekstowych osadzeń

(textual inversion) [<sub>1</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,to%20track%20the%20training%20progress)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,to%20track%20the%20training%20progress). Dzięki OneTrainer możesz trenować modele na bazie różnych wersji Stable

Diﬀusion (v1.5, v2.x, SDXL, a nawet architekturę Flux) w prosty sposób – skryptem instalacyjnym lub z

użyciem wirtualnego środowiska Pythona

[2](https://github.com/Nerogar/OneTrainer#:~:text=)

[<sub>3</sub>](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,r%20requirements.txt)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,r%20requirements.txt). Poniższy przewodnik zawiera szczegółowe instrukcje

instalacji (krok po kroku), omówienie wszystkich zakładek i opcji GUI, przygotowanie danych

treningowych, prowadzenie treningu LoRA (na modelach SDXL i Flux) oraz użycie zaawansowanych

funkcji OneTrainer. Całość jest oparta o **oﬁcjalną dokumentację** (wiki GitHub OneTrainer) – dzięki temu

masz pewność aktualności informacji na czerwiec 2025.

*(Sekcje oznaczone jako „Screenshot” zawierają miejsce na zrzuty ekranu: konﬁguracji, wyników oraz*

*uruchomienia programu, aby zilustrować proces.)*

**Spis treści**

1\. Instalacja OneTrainer (GUI i CLI)

2\. Uruchomienie programu – tryb graﬁczny i konsolowy

3\. Interfejs graﬁczny OneTrainer – przegląd zakładek

4\. Zakładka **General** (Ogólne)

5\. Zakładka **Model**

6\. Zakładka **Data** (Dane)

7\. Zakładka **Concepts** (Zbiór danych)

8\. Zakładka **Training** (Trening)

9\. Zakładka **LoRA**

10\. Zakładka **Sampling** i **Backup**

11\. Zakładka **Tools** (Narzędzia)

12\. Przygotowanie danych do treningu

13\. Obrazy i podpisy (.txt)

14\. Augmentacje obrazów

15\. Proporcje obrazu i bucketing (Aspect Ratio Buckets)

16\. Trenowanie modelu LoRA – przykłady

17\. LoRA na bazie SDXL

18\. LoRA na bazie modelu Flux

19\. Zastosowanie wytrenowanych modeli w innych narzędziach

20\. Tryb CLI – skrypty i ich zastosowania

21\. Zaawansowane opcje OneTrainer

22\. Oﬄoading do RAM (przenoszenie obciążenia na pamięć RAM)

23\. Precyzja obliczeń (precision) i typy danych

24\. Różne typy LoRA (LoRA, LoHa, DoRA)

25\. Wybór trenowanych warstw modelu

26\. Praktyczne porady i najlepsze praktyki

1

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAeAB4DASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAACQoHBv/EACMQAAEFAQEBAAICAwAAAAAAAAYCAwQFBwgBCRMUABESFUH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8AsB7q6wtOQ8hhFoLkt5veyaEcUWcYnjgxZNRLI6PSxE6THZvLRUeTIGQyDDp5ci8JWqq5TWuewW1QXFS2/fCw6m7P+yInWiSqLmXnzNqapNpydrLOe9KV3JrAPntQKFFleWnuFXg/zi2qDFIIFJCsrl09YkQvZKI3lU+5M8/FlX0/2DaPPprlhnixsvnzN+EOV9Hvu3elioPqjcbE8l6ZuQx4WGM7H2Zk0ivtOvpeQ2seoeVS18CnW16+i6bdeSlRxc18XmPanTruhfP2i3r5ysBF6DaRvHWe4bCWWHde+BfTY9bbOqHo4TVSbsf0cbIC0eGrNLWk6dXkEKsZkxZtDGfkSI6AX7O/o1uGa5rzx1wY7fSdqcj7kbieVn0/L+cGeeC3lmadOtUI2a6jTWerni7FMbSpo/lhCOOuVDNPJvpBJCu7eNTtRLGhCD+C1jomJcbeiveIciNuJb9YSypHnqZDbrTzjcpMz+/2o8ltXiXYrzXvif8Av8ka3WEblEb624T02/kprrx51B8rR1wMFpybHzas4o5PPFfNLnc/nV0GY28VAMGQS6MKVVbaDgm5NvqWDbW1DWos31b+epFWZR2j3tw2zpej6uMZvdZvq+UVJaRFpsKc55rf5nnNIjn6DfFjceIMy4ZE7ZmQjngimcN0Oa3g6lmZEktPVUQDv+0o51Dhk/trVxvHqnWuWetOZsWA9N02nJKUaKucifAD9xymJS2iKrQfjXgQXw9Ft/ZLgcyQ3FU9QM+uQYzEpS15z1qXFw59QOndlwP6Je8Y6JuGQ8vA3M9vo+dO6Jw70Mudn0wpu74j0q6FSvGqsiGaUfmRR0gg2jZA7FnzK6slKg2c1p6rbQAwNOxAtEj4ZpzAOvK56lKBsggRrqrIKSX4piRXTYFm3JiKae9WlxfqW0LS60y6haXWW1Jnw235Id9SnSbmnCut8EX8/ZOe0ueYNhm/4UKaQX8rj9fLqIDjuUkkvPrZd/dioKxcAIKQ6bamV43UXku0vbGYRIj2zIHRxtzJ2jzxoNz1BrHIME660MSbeiHoX627XrwlqeEifN0Z43NgrYuYMtpzY2Lx+XEzuAOVmej1Jlw/W+iEtgOnxYQrJn1/jd/B/NW63i6bvd3b6EeaZ1Zs2165o+n6x6URyTUWqvVjLPspOEDhX/hLEae2xYUz9wbHayuq6KuHP9WzUQmYCY6POLxn4EcuYOcVJhabL1hqWfDmd5UAD+GmPRuvJy+tvQauFqKccOUVQa13lqo2eppcokz+4cn5e1Dv7OhqA6BQNwKyK4tNS1jFbAqK+IzXUdTFTX1NZXtpq4tZDr1KgRK6DDrP1YkathxGGo8OKy0huOw2202hDaEp8D//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAATAB4DASIAAhEBAxEB/8QAGgAAAgIDAAAAAAAAAAAAAAAAAAgJCgMFBv/EACUQAAEEAwACAgIDAQAAAAAAAAUDBAYHAQIICRMAChQWERUYEv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwCUjzTeaDqvnHqCo/HH46qeXsPsSykI1MDZOUxJidjY+OSRw4aABoEFqY0bmXEiWbEtzxc8Qi7GJaCmHoVM5MK4YqTcnUH2SPGBEwnS/Vjzl7qCmzN8BkpnUdPNZ7JLHy2sFAiQWjUaeuIAO/SYlG28fcJBEWSZtIKq5UbY2V0eYW1zdnHRniS+wlGPJFfUOuZXjnoukH1SkrrTMSO3Ate2RKCTV1KE3gjYlJJBCYaFQQHKRqBx4SzYPNVyeIIBfZaGsN387D+ynxbW1Zx1vxcbddkdO2sPgxKjaPiMTsLbc5vPESm8feypyuFG7idGGRyiUoiDZ2nYIhR4w2cx5FL3b6BH30T9kez6y8p3IcBcSGM0x48rrqSi7jshxdVSqsrXhMbsoBJiBbeRPBJk0/jz1o6ZDkN2LRiWUYbbbpY2VwrnbWzryz5DeL+2U5d/kzo6vrpdwXUH+1swhAuEWDMiyb3A97oOPCBzzdo9UbbaqLM0XKCKvoTeqtVlmqbijf1C1m9+fZr8bzLsSk6+Az6xqp5gVu+hCGkfsmuh0gKxOeOz8Nd5eKyIBLwLF6knpps9cFEXO6KSv/SudM74kyF1ZWFM/Zl6Og9N1lXFRQ9j4w4y/wBYlW8Qi8CjCZMralFLEXv9BER4sTqSdKoa7u3STT2L7YzldXbbGn8hb/nkEhNkhFonYUQjM4jLsvvuuBlgMZIBW6qKe6aDjVkVbOkEnTfRdbVs6S00cN/aplFVPO2c5TrlTxk8D8gvTEm505brCtpHInAg4RPNmBGRmEi4zBP8J+GJTElIXkccI/2Lz+do6sLwr7dffhT0oes+HwN1JfH1xvZnTlX9rzmiIxIepIOPC/qlwuSUpbng36y3dtQX445ifaxxTA5uTfpo4chV8b4c75W9u2NM69j/AIw5hkvTU26kN1EBfX8ZroJVhSy9iEhQNPa//NYGcRlZq2Moh8s8E42Ed6rYG4e67j09dXWE1F9FT4fA/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAATADMDASIAAhEBAxEB/8QAGgAAAgMBAQAAAAAAAAAAAAAAAAgHCQoFC//EACUQAAEFAAMAAQQDAQAAAAAAAAQCAwUGBwEICQAKEhMVERQWF//EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwBtqH9QpdMl9su3fU3unrWM5L0jxaV2Kq0eyF56eLYRZuqzNWHpUTK2aHemJI7koAycWV9sIhBCh21fcjltPHOorrX3E629xs4c1nrRs1O12gCThMTJWKtPGiixJsYgjg4R8aZDjJMR8ZSeeEESQAAxbTZDgzrqGnVIxB9FMgybbPqy/Rqm7Vl+fbDT+Hu0Eqio6hSa3oFYTMAWrOG4+VTA2mMl4tEgC0UY2If/AFeCA0EvttutcEK4XLWGWWndZM6+rLnalnkePRcn7GQEdAZjRLHZ8Qj+IFNx0+JErkFP5MbV7LTQ2AXlsD/5M2MIaCS6A39oZBDSw1LwPr/5pWnc09YoPuHlExvJF1PoCc+acnQiSbpFOFoNgP3TkPzV3nxv6BvDZLc4sAt1hKRC3lOscOU9dzPqGMfxL1K6s9fKH2QxvjqbCn61WO8M2fRrBL2HLtHqP+riIqF4sD4YRUYR+/AAjDlQkdOsvPuuI/LwO4shvMn21qRErhfmhtNRsPmJRset2wdSh4LrT1ngqlO9ss8kVRKSf2O46zKVj/vVneTwM+NembdcZoVy3mRzhCXimhXkXq+quP8AUrPfqAfJQrQMj630PJtPqW82/fk3Gj5XWc3vMu9HXtY9t1PmwRoFXnJc2wOgLamrhyTJvyJTPDz/ACe8nhQWMepXrttec3Xqz1B8yqnWdt7ed04SF0LNLLOcR5dAo2PlCt2F+6zsMQa1JlyL1UYflFwZ4cYtipPuWcEqQkhx6+Ymuwav9Wr1veoFrks66X9qq5I3WOEsNC69QRnFlerwzrBUiDMSd0j6cxWGrECh6EFsEX/oioyRNQQqKeZY5WtefTDKav5keyfUj2aj6ddrz0ut1chaZf5zJ4WuStTxtT+RKxOiN14Kuq+5Gdpp78NYQ5TkdUC8PyzXac+VKPw0S+nXs/2JwXY4+99xOg/sH3rse57rXobRci6cYrO73DZzX6Lnh4dE1aSk4qnihFZa9X63R7ro8pHXJFYMICZcsyxnoGSGPKD0CaParJLUqoS1vrYlTtctV4CVstVekSZF2sT0nEiHS1ecPZAS0YuEOffjFEtpSh7kX8iUp4VxxwfK2fE7sNqXZ/yy6c7jtVsXbNOuueTbdosb4XARUu5VdBuNLiyzWo9hoZ09UHXYxB5/KVFSZiH5I9588sl9w+Aw9D89OmeS9p7v3IzrCK1VuzOmlTIN71oKVtj87YxLkQMbZ2TAD7CXX2uJcqHjHiFBw4ziFCN8DqZTy4lffoHTTq9lWj7jNUbF6hFndrpyTvvYng5qQsYGr26MkXXgJqyxNmOmIn8wzthmXEDxwQIXKznFKGVy2z+M+HwI2H8mfOBiE22IH6g5EMHv9jTatUUNFyQx85PgyK5USRhpZiUblaMseQ/gltihG1gXhaUJ/By2hCOJc2LpF1P37FQcR2rDKTpucBU2CpgUXcBz5ibBrMIXElR0WFeCDub0GhsmKBfIJGsrRkg6ypcgSVy+Ry6fD4E0R+PZcNnNfxVVErcjlFZqVeqULQp2OasddErtVGBArsYsKf4kuDWogWNAQG6eokhtwRl/l5RCOHfivZf5pdDcUgdmr2W9Xsvp0Zsj17I0b9dGnPSE9zpNUMqt4HHmpCQMma+BYq7JHxJkZWZCHjmxC30iijqXyv4fD4DK4FgeP9ZcgpGGYVRovO8nz+OLAp1Min5I2Pgg5OWkLAewMVNHSco6kmYlpE5XJZxCkuFLQ2pDKW20Hw+HwP/Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAATAEQDASIAAhEBAxEB/8QAHAAAAgICAwAAAAAAAAAAAAAAAAgJCgYHAgQF/8QAJxAAAQQDAAEEAwEAAwAAAAAABQIDBAYBBwgJABESEwoVIRQiI0H/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8AuAdT+SPh/iIjWAvVvRdE02fuMUk5XA5980RMlkBswsEHcwgYgm/FajfsYuGZJJMFiXl1eIS5GWZH1acvXlx8fo7kuxdf1TrLWszTMcka19Xb42wfmintsvhDc+rVOaM/Ut2KIqbIBzsR2ZYVgfORFe+shhLfyzXh8qp3Xdn82ewdUDtacH0Pec3ggIXGdd93mDlu1lVxuDMpbQARpC5w7RpixXWHlDrlXnEaTOLPMLLsqlYw5htzR346Wv8AUvRmt/NsvadY5/6BqudoUm5BJorSVRAadnHY1F6CdDXnXOqjtMBD9fQWEvSHa2IHVKuygsSZlhkdB+v6khKX4gvyAtU9HcM3LbHcG/dVhOjtPwNk7K3LUaXUj9dk1jTddtoatVaxJARoM8S5KIzrEBCMNtHsvSJplhclMRhLzrS7aR788+/lPm7A6O8blR5K0Xxum8m6fppXVEUpOt90jVieQBlbKy5VAlpTEm5kDX0WARIWmMGKy1jBhI5CZQTdSjw9czaU67/He6S0LrZ/ngN23tMDvqCQOqhVF3f8ihgNm1i4Qoll/TQpe251RI5r0CAChusSgrhGSIS03hX0KTs/x5eQ3luf4p614sOwem7v44OwSFctAmVJ19o6783bG1xT6dYk7Hq9mYsY6g06qxLbdtfVHDxaxTzKbJsCaal4lyzNjPpbmhKPxV1j5tR1I7wj+SDnqn0KbonRW4Nk6S3xVhIITQbfatcDCDYashgA82SLHK+d/XrvkQ2ZjV2c+HawJkhYjshbjUSvjV8jH5JPlW1nfttczX/gUXWNZ3tjX9lh7ToliqZV+wPBBdgTKgRgQe3RpY1ocXiqWQfmxJSJDbyUwFpaQtyNLmTrzcNA8ge1NF6N7f6y674a6J486uBVvYHUytllHtjjqnyZtK5my9NFbTjJUGm13a1UXXnLPUoUOZkaPlgJc/MWZMhu5T+OP4qLf3vzHvvY1f8AIH2ZyLDpm7m6TMpnOOxidRrtneVQK0dxZD8EcbHMPHPkRSHVImt5wkZDjJWtKUfwJp+QPJx5l/JHoGya45RJcY697I5Y33fdbdHzNqjrwnX2xaLCRGi1m90CKJohiAAlt3V03XHgrk9+bKggo9hkYiJL4hx0m175YPyL9meR+7+LIHfOCW+i9eos2TZglr48xqpbVXqES6mf8VijDJpyatwLNaRES9VYv2T/ALGl5abx92baHjK8a+mfGHow5pzU1ou97I3W4ltjbV2dsU5NI3DYl8Mx2IDtlnNvS3xIhxAiEKGuRwX+aBMkD3DEhDpafPlPVNOPEox+Zz00lDamvZO5/g2lTeUp9ud65lXvllSm84Xj3c/mc5ypWc5/uc5yFvTgqB3iI0fKjeSg5z7ZOiV3o8/EI8/RzqKHjXSxwJFZjuILV4LKQdbJN2FRBOIimsR3IHwfcV80oPUg6IrLacJR804x75/ji8ZznOffOVZ9/dWf/PfPvn2xjHv7YxjB6BQ+ieFeQuygrI/pzn7XW3kwjQU3Gn2ES5FOtz6umb+hxmyApImwuQB/7OdlAh0msS9mRnMmC/lDeUcufeMOW+Zye8LNobStO1gW33ZINw25mtMz2htysI1k6zBmygcqdKBjWYzNhMtNjQg4YL+qe62qFlCGktno9BjtE4g5M09uyV1LqvQ9C17vi60eNr6z32oD5AFwpTkOjp+Ama6PlsVKI0qYIHSHZMABFnPORUZdlLwpzC+x0JwLxr2AcrU/pPnbW+1ylLPAr1XjJwU9BOx7MCh/4RMyecAShBc5Dgw5DsZoIdmkgWWcoQ4NXhpr4Ho9B5WxfHjxVe7/AE3Ztk51oL111Xr7Ymu9eFRLJWsxqnS9swbAF2KAFA6wTD19EW1DLfZIxB10W7Lb/bSXociNISy61lfJPD/KnClHsdD5M01XtLVG7WGLcbUErxCyE4xmyrGwQyi0lyzmzspL6hkKLEy2w+zGy2ylX0/ZlS1Ho9AyM6Q8y/hDa/inMeEvKfijKfk6VejufzKc49lMpSj44/449vfGMKznOU2qfj04zpvYBXtWsaHrAjqS3S7Cmx7hjlLWqwFUkqqPBzsPwH7A7XkYkiWW4LmGAzP/AFIxlPsv3Xk9HoH/APR6PR6D/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAEAAQDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAr/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/AL+AAf/Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAEAAwDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAgK/8QAIhAAAAQGAgMAAAAAAAAAAAAAAQIEBgMFBxEUFggSABMV/8QAFQEBAQAAAAAAAAAAAAAAAAAABQf/xAAgEQEAAgECBwAAAAAAAAAAAAABAhEAAwUGFSEjUXGx/9oADAMBAAIRAxEAPwDWE+eD8KorucrzNy25usgzrcs1Xna1PK96yzW+ByKD4LYkeqLfky4oiAFTZSiwFKHcbDe56VMCFTanrWY+2vh+67LhRbfUmf7S+Z72UR1OW43BiIfprS+/HJHxIFk0GBC6j6+wvHlI4rXlW1FtEyi3p2ZHwDCNKUnThavtfMM//9k=)![ref1]![ref1]![ref1]

<a name="br2"></a> 

**Instalacja OneTrainer (GUI i CLI)**

**Wymagania wstępne:** OneTrainer wymaga zainstalowanego **Pythona w wersji 3.10–3.12** (nowszych

niż 3.13 nie wspiera) oraz **PyTorch 2.6.0+** kompatybilnego z posiadaną akceleratorem (CUDA 11.8+ dla

kart Nvidia lub ROCm 6.2.4+ dla kart AMD) [<sub>4</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection). Upewnij się, że masz co najmniej **7 GB wolnego miejsca**

**dyskowego**, ponieważ instalacja i pliki modeli tyle zajmą [<sub>5</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection). Jeśli planujesz korzystać z treningu z

oﬄoadingiem na CPU, zalecane jest 64 GB RAM (minimum 32 GB, ale mogą wystąpić błędy Out-Of-

Memory) [<sub>5</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection).

**Krok 1: Pobranie kodu źródłowego.** Najlepiej sklonować repozytorium GitHub OneTrainer. Wykonaj w

terminalu polecenie:

git clone https://github.com/Nerogar/OneTrainer.git

To pobierze wszystkie pliki programu na Twój dysk.

**Krok 2: Instalacja zależności.** OneTrainer oferuje *skrypt automatycznej instalacji*. Po sklonowaniu

repozytorium:

• **Windows:** Uruchom (poprzez dwuklik) plik install.bat w folderze OneTrainer

[2](https://github.com/Nerogar/OneTrainer#:~:text=)

[<sub>6</sub>](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,install.sh)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,install.sh).

• **Linux/macOS:** Nadaj prawa wykonywalności install.sh i uruchom go ( ./install.sh )

[<sub>6</sub>](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,install.sh)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,install.sh).

Skrypt ten automatycznie utworzy środowisko wirtualne Pythona, zainstaluje wymagane pakiety (w tym

PyTorch, biblioteki HuggingFace Diﬀusers itp.) oraz skonﬁguruje OneTrainer. Dzięki temu nie musisz

ręcznie instalować zależności – wszystko dzieje się automatycznie w kilku minutach.

**Alternatywa – instalacja manualna:** Jeżeli wolisz ręcznie kontrolować środowisko, możesz wykonać

następujące kroki (odpowiadające temu, co robi skrypt):

1\. Utwórz wirtualne środowisko: przejdź do katalogu OneTrainer i wykonaj python -m venv

venv [<sub>3</sub>](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,r%20requirements.txt)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,r%20requirements.txt).

2\. Aktywuj utworzone środowisko:

3\. Windows: venv\Scripts\activate

4\. Linux/macOS: source venv/bin/activate [<sub>7</sub>](https://github.com/Nerogar/OneTrainer#:~:text=3,r%20requirements.txt)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=3,r%20requirements.txt).

5\. Zainstaluj wymagane pakiety: pip install -r requirements.txt [<sub>8</sub>](https://github.com/Nerogar/OneTrainer#:~:text=4,r%20requirements.txt)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=4,r%20requirements.txt).

6\. (Linux) Zainstaluj dodatkowe biblioteki systemowe, jeśli potrzebne: np. na Ubuntu brakująca

może być biblioteka **libGL**, doinstalujesz ją komendą sudo apt-get install libgl1 [<sub>9</sub>](https://github.com/Nerogar/OneTrainer#:~:text=Some%20Linux%20distributions%20are%20missing,libGL)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=Some%20Linux%20distributions%20are%20missing,libGL). (W

Alpine Linux zainstaluj py3-tk , w Arch: tk – to zapewnia działanie interfejsu tkinter dla GUI

[<sub>10</sub>](https://github.com/Nerogar/OneTrainer#:~:text=sudo%20apt)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=sudo%20apt)).

Po poprawnej instalacji, w folderze OneTrainer pojawi się wirtualne środowisko ( venv ) oraz wszystkie

zależności. Możesz teraz przejść do uruchomienia programu.

2

![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAApAGMDASIAAhEBAxEB/8QAHQAAAgIDAAMAAAAAAAAAAAAAAAcEBQIDBgEICv/EAEAQAAECBAMEBgYEDwAAAAAAAAECAwAEBREGEiEHEzFBFyJRVpbVFBUyYYGRFiOS0jZCQ0VTVFVxcnWhosTR8P/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7+IIrBNTOUAhn0hxBLbKVlTacls6t9kBUDmT+IADwveJ7Sw4nMCFakXBuNLc7C/ygNkEEEAQpsW1epydaeYlZ5xhkMy6g2kGwKmgVEWUOJ14cYbMJjGiAqvTBKrfUSwtlJ/Ip53gKc4irifZqzwuFAiyrkZSdOvxBAMMmgTM0/hlMy8+44/upxYdtY3Sl0pJ14AgW14gC8KBzI0kqLnWtZPUJuTodL9hI+MNvDtjhZwBS1buXmD9tDhNx2DMVWvy4m0Au/pBW/wBqPfJX342yldrL07JMuVN5xtU6yCix1SSnMk9fmTy91/fTbpP6T+0/7jfIKQmpyKA6eo+hxQCCDmB0617gWt/W0B7CtXzLuVHhx9ngL2+Nz++8bojtkjKoBRC20quTdIJA05WHM89STGDswWk51AlN7ENjOdefHSAlwRHQtxaQoXAULi6LH4i8EArKdN4lnca1VclV6ajBMpTRS5SmMtKVMsV+SUv1op9dkpRLoS9KhgJK1Lu4VJQEgqa7SMiAkABI0SEgABPIADs+cJvZckkbS23ShCulXGbTCgPYlkercib2AFrmySbamxhytm6QQoKB1BAtYch8O3SAzggggCIExS5CadLz8s244oAFakpJISLAXIJ0GkT4ICnVQKSsWVJMEfwJ0Pu6sS2pRthn0dlpCGSkpUgAAFJFiLcDcEj/ALSbBAVPqOlfqbP2E/djEUKlocS63JMhxKrhQQkG/bew90XEEBHKHSpPWCW0hV2wAc4KcqUk3GUA6872se2KOs02rzdOUxRp9FFnN6le/baEwlSM4KgQVs5SU34X4214x0kEBzODq2xiLDlOq0u9MTDb/pbBfmmESz7r1PnpqnTK1soefSgKmJR0t2dVmbyLISVFCSOT2MEHZxRCCCDO4nsQbj8K65zEEBybFaw3s3quJpWrzVSTL4hr9UxMHFyM5NoeqFaLHrKQS1INzZS3SRKyxSpSU5vTDuwSF2vmNtWzYIIGJJkDMbXw3ilRIAAuSqiA37QLjsJjpvz/ACP8yrH+HHdQCl6a9m3eWY8M4n8lg6a9m3eWY8M4n8lhtQQCl6a9m3eWY8M4n8lg6a9m3eWY8M4n8lhtQQCl6a9m3eWY8M4n8lg6a9m3eWY8M4n8lhtQQCl6a9m3eWY8M4n8lg6a9m3eWY8M4n8lhtQQCl6a9m3eWY8M4n8ljwrbPgF1KmpCuzE5POgtycp9HsRs+lTaxll5bfO0htprfvFDW8cWhtGbMtaUgkNuCAXOzLD8/h/BNGpc7aVmWl1WadlwhCwyalWqjU0ozX1KUTib++8EMaCA/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFUDASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBQYECv/EADcQAAECBAMFBgMHBQAAAAAAAAIBAwAEBQYHERMSFyExllJVV5HU1hUicyMkMkFCUbIzNIGxwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmir181+8mJe56nQ7JtyfatyUlbab+EXS7ddJWYStiFR15ltaQ6L8jot6Oc2ompqxpDqdJKYY/d2xHEDFJpQFAJti8EJsSTmiH8PHbXimZbKZ/tGDC9ll0sR3HEcQZXFi82l21UlIB+G5oirx0nOGoCJk5sjmmQpDGxLsNsttA22gtCjaIIIAig/pEU4IiZ8k4QBXuxLxExY6vT0EW7EvETFjq9PQQtaTXYHyi0muwPlAEu7EvETFjq9PQRbsS8RMWOr09BC1pNdgfKLSa7A+UAS7sS8RMWOr09BFuxLxExY6vT0ELWk12B8otJrsD5QBLuxLxExY6vT0Ea5MN22ao0SYh4pzDzRhNOybt3Kcs4y0H4Z9lacgvMPEgsECOIqg4iZpyhr0muwPlGBxoBMERODpKJIvFEQRzRA7PzIhLl+pNrnAF9m3NPT9VvG36mLhT9q1aSlTfpwo2y7KVWnM1imgYkeavStPmpeXcPkZtkSIKLspR5rIk5VzEXGc3GGnDWvWkhGYCRls2XSkRSJUzVURETNfySKA8IVmi4dVOrydWGsS0hXa1Vq4dSapk9VpaZmamsvwbbpLE/NAQaOZarDaEhjkq5KibkcbsN1zRKrWvkVQXOyb5TinPnbaZp+ypmi/kqx3Tv9vS/qtf8AUbhef+B/0kAX77cOO9az0VfHtuLfbhx3rWeir49twnxQBhvtw471rPRV8e24t9uHHetZ6Kvj23CfFAGG+3DjvWs9FXx7bi324cd61noq+PbcJ8UAYb7cOO9az0VfHtuMR41YdETRJVasiC4gptWdegKSmmyn4reTZyVeKlkmXHPLjCpHO1Xm79aX/gEBpLPpJsV29rqZmG5qnXpP0Oo04AZm5eZl2adQZOlODNszkvLm2449LE62giX2RDtbJ5ilCAx/QZ+k3/AYoD//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAHQDASIAAhEBAxEB/8QAGwABAQADAAMAAAAAAAAAAAAABwADBQYCBAr/xAA4EAAAAwUECQEFCQEAAAAAAAABAgMABAUGBxETF5YhMVFSVVeR1NYSFSI0QXEUJEJyc4GhsbLC/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuSNHp5j85IO8zxOByTLj+lLjo6y0n7ImlWa4SLwEbKSI37ymMIVKu43Kdza9iU4nFC6LedI6Ux+7plLUCqSQkKBDJoTgBkymDWAH9nl9Y6QtN6Qt2Ngpeiiqao6igKAV1qxOaQ+sRMJiF9m2gAjpulNF4QAsU9JbQsKDMaDugmimkRNMCpFBMAKQCFKBfwlKGgAC3UGhgK8MTcxKsZvDsGsMTcxKsZvDsGWrpLcL0auktwvRgJcMTcxKsZvDsGsMTcxKsZvDsGWrpLcL0auktwvRgJcMTcxKsZvDsGsMTcxKsZvDsGWrpLcL0auktwvRgJcMTcxKsZvDsGsMTcxKsZvDsGWrpLcL0auktwvRgJcMTcxKsZvDsGsMTcxKsZvDsGWrpLcL0auktwvRgJcMTcxKsZvDsGwr0tE5LDVHq2mURD3nebwIvot0GOLiPqLsCwLAZguktwvRvEzuifQYgGLuiACUB2gA6h2/QGDkoXATwlyScixyY4gCQW/a4tGReX5T1WDassDqUDiHy0aNLTdkUpShYUAAA1AGoPoHyaYA4kZgtOonF3OLFjDs4R2NRaOHiSUMfos7PLzExd9CacJQf3ohiXNpr1BMDActgjYIBuS1upuNoBFY17giQbZJnkNIa9cthaGwQtAfkIt3Svw8L/VS/6bcDr/Yv9AwF+NtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtjVrjTZEl4pFY0BLQABLJM8qCIjtInLZ1CgG0xQAdYCym3rofGPH5Uv8CwaiEzjAI04pRGHvD2o6r2ikdeERlzUMAWaTO77D3Z5Jr1KJFH+Wm6dpg//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZACQDASIAAhEBAxEB/8QAGwABAQABBQAAAAAAAAAAAAAABwADAQQFBgr/xAA3EAABAwIEAgQLCQAAAAAAAAABAgMEBQYABxESEyIUFyFRFSMxNEFSdJGWsbMWM0JVV3Jz1Nb/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A9z9Ry3XUJb8s37mJTVPgAx6Zc/CjcpURtT0I+gkFOug7+7GcsCkISMwc00bEJSQzdgQklI0KinoJ5z+I69uFpLaEJCUJCEg6hKewe7u78RabJJKEkntJIwBJ1Yq/UTNj4vH9DF1ayWvGxcxczkyWvGRzNuUTYQfRzMmXD6Kz0uKHAkyI3Ga47W9rit794WuE16ifdi4TfqJ92AIaLfDUXwnRKzVnaxXrdqaqVXKhGt9umxn5zkGDV2uBE8KyihCKbVYCCS8oqcS4dB5MWDqKzHVd+aIXGjOKTfbYLjjDbjrmtk2Yvc64tJU4ob9iSo6pbShA5UDFgFipZw2HSJb0KfPqzL7OmobtS7ZSFakjldiUJ9o6EHt36eTQ92Drry8SElypVlBWlKwn7G3qvlUNQdzdvLT292uo9IGO8T/OXv4W/mrHIsfctfsT8sAa9duXH5rWfgq+P83jRWduXm1XBqFafe2nhMizbzaLzmh2NB2Rb7TDZcVogOPutsoJ3OOIQFKChjazvMpnssj6K8AJUG1arUJ113GtCILF13EiuQocskS48QW7b9HCZQaDjSXVP0l91IQ4scJxrUhZUlNhnh+Zw/ZWPpjFgP/Z)![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAM8DASIAAhEBAxEB/8QAGQABAQEBAQEAAAAAAAAAAAAABwAFBgMK/8QAOBAAAAQEAwcDAQQLAAAAAAAAAAECAwQFBgcTF5YRUlVXkdTWEhUhMRQiNFEjJDNBQnN1gbG0wv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmlT6uZ/WTEPU8zkdE05HtU5CQtNN+0VS7VcpOIKdpRMceJbOUOpfgcFvB2xZpWazYwk4nSQlsf1dtKbgXSaNCSQptisCU2lRfUiX7en1n8ltV6S2/kPC17LLqrjuOE4SYW7FZtH6zNRqQn23aRGfzhOfGIgi2OelO0tiSDGxDsNsttIbbJLSSbIkoJCUkn+FKS+CItv0L4AFeWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCgHpnR9QymnptVcfP4WoER7FKQ0fKURM4hnJVCqmU0cm9QKmSTmS1sKUUOZS6Gw2iaZ+8TfrUtYTW4noCisGmlXMtEhbTbiVO1wkicQSybNNNLWamtv7Na9vpcUnYa0ESD+CAZCJzJbdTObwc2TOIaAns6m08XMmpZHTaGiYmZnD/DbcpYj4pCkYO1WKw2SiWnYZ7DItlN7rbntIprOvuGaD20TXJfJfX602W0vyMtpH+4zHdO/h5X/ADWv+hsH9f7J/wAEAL87bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsZkPNWa+rWj6ikjMY3I6PdqJURHzCDipf7h7zJfsDKYODjGWI9tTL6v0xRkLDbUEa2/Wk0mpiGLL/AMVO/wCoN/6UIA//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZADgDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAFBgIDBAr/xAA2EAACAQIEAwMJCAMAAAAAAAABAgMEBQAGBxESEyEXMZYVQVJVV2GR1NYiJDI0QlGBsXFzwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bomv2eb/AJygp8z3Ox5Jy5XxZcpKXLUfkjNMua7SagXtUuPPqYzaJVnoeTHyd6sq5cwcpeZslJpj93jVdQNUoiihGjgzgGjVh3gP5PXjPUbtwjf9sdGl8MMrajySCQLS6sZziPGSxZF8m7gE9eVJ05iAbScK7jZRhjgp4I4Y4kjjCxKIwFQIqhf0qo6ADfuHTAFfZi3tE1Y8Xj5DF2Yt7RNWPF4+QwtcqL0F+GLlRegvwwBL2Yt7RNWPF4+Qx5ajTRYtw2peqcRnVkCtm8rKzDbhKSLb24NuuxKkdfdhk5UXoL8McTAhZWBdNu8RsVVvc4HRh/nu82AJjl/O9hTLdPljMtRd6GGviS9Q5tkN0uc1AynnzR31WgKvEwQJTG3kTcxmMsfLCvYVTTwxpskUQXmcbBgACx33Y9NuP39/vxYAXS82XTq53ejuy3imoL7ertfHuUVsrrtTVNTczT9I47TBX1SMnJ3bmwRhg67E7EDMrrdpudwLrevsEod8k55HUd/flsbj9iNwfMTjepfy9r/2xf8AWMwe/wDhf6GAL+23Tj1refBWePpvF226cetbz4Kzx9N4T8WAMO23Tj1refBWePpvF226cetbz4Kzx9N4T8WAJ59VrZfJrfbcjQVt/uk9wpxW0ldYMx2WGGzhZBWVgq7za7dRs8Ehp1WAVBmkEjGOJwjlbC0n4h/P9HFgP//Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZABsDASIAAhEBAxEB/8QAGgAAAgIDAAAAAAAAAAAAAAAABQcCBgMECv/EAC0QAAIBBAAFAgQHAQAAAAAAAAECAwQFBhEABxITITEyFBUiMxdxcnOBsbLB/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/AO29Bfc5vmYwQ5RdLJhePXKLHbfSYynybJpcmtQqIr6rXEzVUbWeQz0xijEG6kr3HaHsBZbJTcsdQRqvMHmlF0qFaOnzDqiRlGmCubevXog/X0r1eoAHGPlnDDL+IMkgkC0/NPNID17YsomogRsn7EmwZE10yFULewcOGGngjijjRE6IkWNQqBFAQdICqPCgAaAHgcApZeXV5pEaosXMfOUuaKRAMnuYyOzMr/RMKqzat3xh7DSdlfjIe3N25dt0dJK43dYMsstHfaGtyPsVPxNKWR4rdG9Taque01skVCstUtNFLWUM8kUYqJdRspLbJAYslNC4BKAMh60ZfpZSPPhh5AIHSwHqpKnwTwn+TVpo5+XlomZZEZ7llZKxSNFGCMvvw2qLpRvW20PLEsfJPAa8d8snLu53aiu/zmloL3eLrfDcY7XX3amqqq5SQPqJLRT3CpRkWJi3ehjBDeCdaBgc7uW53q63rwxU7wnOR5U6PrjY2N+hHg+oJHF5k+xav3U/xJwZf3H+P6HAKqXnXgzp27bNfrpXSlY6aghxLK6SWpkdgoRKi5WWjoovXZaoqYkAB2w4OcsrNWY5hNotNyCR1sU15q5ogwJiF0vtzusMTHeu5HBWxpLolRIrBSV0TcJffD+s/wDOJSe9vz4D/9k=)![ref2]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]

<a name="br3"></a> 

**Uruchomienie programu – tryb graﬁczny i konsolowy**

OneTrainer oferuje dwa tryby działania [<sub>11</sub>](https://github.com/Nerogar/OneTrainer#:~:text=Usage)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=Usage):

• **GUI (graﬁczny interfejs użytkownika):** Przyjazny interfejs okienkowy, pozwalający

konﬁgurować trening za pomocą formularzy i przycisków.

• **CLI (interfejs konsolowy):** Zestaw skryptów Pythona umożliwiających uruchamianie treningu i

narzędzi z linii poleceń, co przydaje się przy automatyzacji, zdalnej pracy (np. serwery bez

środowiska graﬁcznego) lub bardziej zaawansowanej kontroli.

**Uruchomienie GUI:**

• **Windows:** Uruchom plik start-ui.bat (np. dwukrotnie klikając go lub przez konsolę) w

katalogu głównym OneTrainer [<sub>12</sub>](https://github.com/Nerogar/OneTrainer#:~:text=GUI%20Mode)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=GUI%20Mode). Spowoduje to otwarcie okienkowego interfejsu OT.

• **Linux/macOS:** Wykonaj skrypt start-ui.sh ( ./start-ui.sh ) w katalogu OneTrainer –

aplikacja graﬁczna powinna się uruchomić [<sub>13</sub>](https://github.com/Nerogar/OneTrainer#:~:text=)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=). Uwaga: na systemach Linux wymagane może być

zainstalowanie pakietu tk (jeśli GUI nie startuje).

Po chwili powinna pojawić się główna **aplikacja OneTrainer** – okno z menu zakładek (omówimy je w

kolejnym rozdziale). *Jeśli GUI nie uruchamia się*, sprawdź czy Python i zależności zostały poprawnie

zainstalowane (uruchom ponownie install.sh / install.bat ), a na Linux/macOS czy masz

zainstalowane tkinter/GUI (czasem trzeba doinstalować). Również upewnij się, że posiadasz kartę

graﬁczną spełniającą wymagania (min. 8 GB VRAM zalecane dla SDXL/Flux).

**Uruchomienie CLI:**

Aby korzystać z trybu konsolowego, otwórz terminal/wiersz poleceń **wewnątrz aktywowanego**

**środowiska wirtualnego OneTrainer** (tj. po activate – dzięki temu używany jest poprawny Python i

zainstalowane pakiety). W folderze OneTrainer znajduje się katalog scripts , zawierający różne

skrypty odpowiadające funkcjom programu [<sub>14</sub>](https://github.com/Nerogar/OneTrainer#:~:text=All%20functionality%20is%20split%20into,directory.%20This%20currently%20includes)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=All%20functionality%20is%20split%20into,directory.%20This%20currently%20includes). Każdy skrypt możesz uruchomić za pomocą Pythona,

np.:

cd OneTrainer

\# aktywuj venv, jeśli jeszcze nie jest aktywny

python scripts/train.py --help

Powyższe polecenie wyświetli dostępne opcje głównego skryptu treningowego train.py . Podobnie,

python scripts/generate\_captions.py -h pokaże opcje automatycznego generowania

podpisów dla obrazów datasetu [<sub>15</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,every%20image%20in%20your%20dataset)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,every%20image%20in%20your%20dataset)itd.

**Uwaga:** Wszystkie komendy muszą być wykonywane w aktywnym środowisku wirtualnym, aby używać

właściwych zależności [<sub>16</sub>](https://github.com/Nerogar/OneTrainer#:~:text=CLI%20Mode)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=CLI%20Mode). Jeśli używasz Linux/Unix, możesz zapoznać się z dokumentacją skryptów

startowych (launch scripts) dla wskazówek odnośnie uruchamiania OneTrainer i skryptów w różnych

systemach [<sub>17</sub>](https://github.com/Nerogar/OneTrainer#:~:text=To%20learn%20more%20about%20the,h)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=To%20learn%20more%20about%20the,h).

*(Screenshot: Ekran startowy OneTrainer po uruchomieniu GUI – miejsce na zrzut interfejsu aplikacji.)*

3

![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAGoDASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAFBgIDCv/EAD4QAAAEAwUFBgIFDQAAAAAAAAECAwUABAYHERMXliExUlXWEhVBV5HUFFEiJDVCYSYyMzRxcnN0gbGys8L/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25Iz9XL/WSEvU7mx0TTk+lTkpK00n3RVKtVtIzAPZSOOPMpi0KlXkcFPBvmxKcTihhFxOklLMfq6ZS2gWpJCQoEMmhWAGTKYN4Afu8vbHaF5uyF/wAo9Fl6KKprR1FAUAsraxWaQ9sRMJiF7tvABHbhKbMQgBcp2S3hcUIY0JdBNFNIiaYFSKCYAUgEKUC/dKUNgAF+4NkAV5Ym8xLWNXh7CLLE3mJaxq8PYQtYSXAX0iwkuAvpAEuWJvMS1jV4ewiyxN5iWsavD2ELWElwF9IsJLgL6QBLlibzEtY1eHsIssTeYlrGrw9hC1hJcBfSLCS4C+kAS5Ym8xLWNXh7CLLE3mJaxq8PYQtYSXAX0iwkuAvpAEuWJvMS1jV4ewjxNZgIlNfaJauAdkbxGr9gBd43SG75wuYSXAX0iwU+AofiAXCH7B8BgAxOlpummx5emasKyfpmWklAlkqsfTPDSieUL8RNqy8p8JKiVVNGXXlSHFS4MbxDYO9TlcSz7TzE+JSc8km8szW6ppFEvZTI4yKE2RMu380hVgKH4AEdrUKRO4KiLdeCbI5gAjtEwHkJgTgcfvAYdpr94774HbOJCSy8oP6qgH5GUvuSIAfYcj4XbIDUI8stnTm7ybsV4lpB9enZ8O5JNk87S0zMuYy+xNNpQn5ohiYN5sVBMDActwjcIBsltus3G8AdXr6AiQb6JrkNob99NheHyELwHwEY7pX9Xa/4qX/UbA7/AOhf7BAF+dtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edE1z03CfFAEhrUqNqaXnGVnnHRdxfZRwbpBCZpmqG0p1hkpkgGPMObNJy6aZhD6JlFSX3h84z6PbKgZqSpZomWCeNMtVOMjbMGTXb+wZeRbJWVVEl84A9gVEjCW8AG668AGE16+02T+YV/0qRtp/o0/3C/4hAf/2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFUDASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBQYECv/EADcQAAECBAMFBgMHBQAAAAAAAAIBAwAEBQYHERMSFyExllJVV5HU1hUicyMkMkFCUbIzNIGxwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmir181+8mJe56nQ7JtyfatyUlbab+EXS7ddJWYStiFR15ltaQ6L8jot6Oc2ompqxpDqdJKYY/d2xHEDFJpQFAJti8EJsSTmiH8PHbXimZbKZ/tGDC9ll0sR3HEcQZXFi82l21UlIB+G5oirx0nOGoCJk5sjmmQpDGxLsNsttA22gtCjaIIIAig/pEU4IiZ8k4QBXuxLxExY6vT0EW7EvETFjq9PQQtaTXYHyi0muwPlAEu7EvETFjq9PQRbsS8RMWOr09BC1pNdgfKLSa7A+UAS7sS8RMWOr09BFuxLxExY6vT0ELWk12B8otJrsD5QBLuxLxExY6vT0Ea5MN22ao0SYh4pzDzRhNOybt3Kcs4y0H4Z9lacgvMPEgsECOIqg4iZpyhr0muwPlGBxoBMERODpKJIvFEQRzRA7PzIhLl+pNrnAF9m3NPT9VvG36mLhT9q1aSlTfpwo2y7KVWnM1imgYkeavStPmpeXcPkZtkSIKLspR5rIk5VzEXGc3GGnDWvWkhGYCRls2XSkRSJUzVURETNfySKA8IVmi4dVOrydWGsS0hXa1Vq4dSapk9VpaZmamsvwbbpLE/NAQaOZarDaEhjkq5KibkcbsN1zRKrWvkVQXOyb5TinPnbaZp+ypmi/kqx3Tv9vS/qtf8AUbhef+B/0kAX77cOO9az0VfHtuLfbhx3rWeir49twnxQBhvtw471rPRV8e24t9uHHetZ6Kvj23CfFAGG+3DjvWs9FXx7bi324cd61noq+PbcJ8UAYb7cOO9az0VfHtuMR41YdETRJVasiC4gptWdegKSmmyn4reTZyVeKlkmXHPLjCpHO1Xm79aX/gEBpLPpJsV29rqZmG5qnXpP0Oo04AZm5eZl2adQZOlODNszkvLm2449LE62giX2RDtbJ5ilCAx/QZ+k3/AYoD//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFwDASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAFBgMECv/EADgQAAECAwUECAQFBQAAAAAAAAECAwAEBQYHERMXEiFSlhUxUVVXkdTWFBYiNSQ0QXOxQnKBssL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25pVetzX7ZMS9p6nQ7E2cn2rOSkrZpvoi1Ltq6SZgVtKKjnzLZpDqX5HJbycZspWVljKTmdJKXY/h20pvAvSaKEhCm2LYBTaVDrAX0enbO8Yq2Rj2R4Lr2WXVXjuOBwJlb2LZtHbJUVIT0biATvynN2YgDBzZTiMEiGNiXYbZbaQ22EtJDYCUBCUhP9KUjcAMeoboAr0xV4iXsc3j0EWmKvES9jm8eghaymuBPlFlNcCfKAJdMVeIl7HN49BFpirxEvY5vHoIWsprgT5RZTXAnygCXTFXiJexzePQRaYq8RL2Obx6CFrKa4E+UWU1wJ8oAl0xV4iXsc3j0EWmKvES9jm8eghaymuBPlFlNcCfKAK5a79VMmWJ/56vJnFSrgdRL1S0vxlPWsJUE/GS4k2y6wCRtpCwSN2Ma1lJa0xp0x89zlDnawKlOCXfpkmuXYVSdpHR4caW64RMBG3nEKIJIwjunWkBO5CMCcFY7sU4EkDtViBgIyhKy76W3XJhYKm04Bf1LCBuSFKJxUoDrUd5/WAKkVmi3dVOrydWTWJaQrtaq1cXUmqZPVaWmZmpmX3Nt0lifmkKRk4qzWGwoLTgTgQNlN9125xAqta+glBxsTbkbx19dmxiOwjEH9CY7p38vS/wB1r/qNg9f+E/wIAv1tu471rPJVuPbcWtt3HetZ5Ktx7bhPigDDW27jvWs8lW49txa23cd61nkq3HtuE+KAMNbbuO9azyVbj23Frbdx3rWeSrce24T4oAw1tu471rPJVuPbcWtt3HetZ5Ktx7bhPigCt6+m7laARU6ypTag4hJsbbdsKUnEAKWuzyEAfVv2lBOOBPbGjQbS1uqSbs8qzbsxKzE5MLpjrZlmCqmEpMnmszT7D7b2wTmJW2CCR1x2lU+3Tn7C/wCI9ehfbJb+wf6pgP/Z)![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAD8DASIAAhEBAxEB/8QAGgABAQEAAwEAAAAAAAAAAAAABwAFAQMGCv/EADYQAAIBAgQDBAgEBwAAAAAAAAECAwQFAAYHERITIRUXIpYxQVJVV5HU1hZRc7E0NWFygbTC/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuja+54v8AnKCnzPcrJknLlfFlulpctRdkZplzVajUC+BLjz6mM2eRaih5ScjeqKuzmDlKJPSUmmG1PEo1A1SiKKEaOnzgGjVh6QH7PXmH834Rxfljo0vhhlbUeSQSBaXVjOcOzkuWQdmggb7nlSbjmIBs/Cu42UYY4KeCOGOJI0CRKI1CoEVQvQKqjoAB0AHTAFfdi3xE1Y83j6DF3Yt8RNWPN4+gwtcqL2F+WLlRewvywBL3Yt8RNWPN4+gxd2LfETVjzePoMLXKi9hfli5UXsL8sAO1WlrTRPCuomrCzSo6wzLnERSQuFJ4km7PcxE7cJYI/QkbevHFvlrMsX+x2K7Zxud/o81RVlBlime3iW+09XYqCS5XWS5ZketVq5XggmKjsun3YhdyPEV6WngI5hiTmRK7RPwjijYoVLI3pUkEjcerBbm6NRqRo5I28jm4Z1KtJ4zGTk2sDGIkbxlx0cqRxAkHocBkJebLp3c7vR3YXimoL7errfXuUVsrrtTVNTcjTdI47TBX1SOnI8XNgjDB12J4SBtLrdpudwLrevCSp3yTnkdV6H05b6j+o3B9ROPcy/w9r/Vi/wCsbB9P+F/YYAv77dOPet58lZ4+28Xfbpx71vPkrPH23hPxYAw77dOPet58lZ4+28Xfbpx71vPkrPH23hPxYAufWzThhyxdbzxSBlXfJOedt+EnxN+G9lG3rYj8huemM2C7U+fc45Kvlkiq1s2TqjME1bcLhRVltSrN2sNRaoYqOCvgpqsvHPKrSmaCJAm/CzMOHDIPQ/8AY37Yw1/lMn67f7DYD//Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAEYDASIAAhEBAxEB/8QAHAABAQABBQEAAAAAAAAAAAAABwAEAQIDBQYK/8QAOhAAAQIEAwMIBgsBAAAAAAAAAQIDAAQFBgcRExchlhIxUlVXkdTWFRYiNFHCJCYzQUJxcnN0gbGy/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuaVXr5r95MS9z1Oh2Tbk+1bkpK2036Iul266SZgVtKKjrzLZpDqX5HRb0c5spWVljSTqeklMMfo7aU4gYpNFCQhTbF4BTaVDnAX6PTyzvGauSM/hHBheyy6rEdxwOBMrixebR5ZKipCfRuYBO/Sc3aiAMnOSnMZJEMbEuw2y20htsJaSGwEoCEpCfwpSNwAz5hugCvZirtExY4vHgItmKu0TFji8eAha0mugnui0mugnugCXZirtExY4vHgItmKu0TFji8eAha0mugnui0mugnugCXZirtExY4vHgI0VhieSc8Q8WCMjmPW4HMZbxkZHI582Rhb0mugnui0Wjztp7hACguGdo94ydlzMy7UJNy0F1ilzz7uhWZdqkzlLpU1LVWaIdTPvzb1RRMreShkBbJ9hXLzFGBddPk3sY7fD7Db4bwzuZLYeSlwISq6bVUUoChklIyASBkANwigMxFZouHVTq8nVk1iWkK7WqtXF1JqmT1WlpmZqZl9zbdJYn5pCkaOatVhsKC05E5EDuU43YbnMCq1r2CUHOyb5G8c/PbYzHwIzB+4mPdO+70v8Ada+aO4PP/Sf8EAX7bcOOtazwVfHluLbbhx1rWeCr48twnxQBhttw461rPBV8eW4ttuHHWtZ4Kvjy3CfFAGG23DjrWs8FXx5biONuHABJqtZyG8/Uq+PLcJ8bHPs3P0K/5MAJF83dfdDvKgy83N0H1Hr9JEy9JzVOcM29cNAmWkmVqbMnNoDjMo84krYTmB+WdDHJe7yv8ZPyxQH/2Q==)![](data:image/jpeg;base64,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)![ref1]![ref1]![ref1]

<a name="br4"></a> 

**Interfejs graﬁczny OneTrainer – przegląd zakładek**

Po uruchomieniu GUI zobaczysz główne okno OneTrainer, które składa się z menu **zakładek** (tabs) u

góry oraz paneli z opcjami. Interfejs jest dość prosty i uporządkowany: ustawienia treningu podzielono

na sekcje tematyczne, dostępne jako osobne zakładki [<sub>18</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=1)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=1). Warto zaznaczyć, że OneTrainer udostępnia

również gotowe **preset conﬁgurations** – w lewym górnym rogu znajdziesz menu wyboru konﬁguracji

(domyślnie puste, możesz tam wybrać np. gotowe presety dla LoRA SD1.5, LoRA SDXL itp., co

automatycznie ustawi wiele opcji) [<sub>18</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=1)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=1). Jako początkujący możesz skorzystać z tych presetów, aby mieć

punkt wyjścia.

Poniżej opisujemy **każdą zakładkę** i znajdujące się w niej opcje:

**Zakładka General (Ogólne)**

Zakładka **General** służy do ustawienia podstawowych ścieżek i globalnych opcji treningu. Tutaj

deﬁniujemy katalogi robocze i zachowanie programu podczas treningu. Główne opcje w tej zakładce to

[19](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=In%20the%20general%20tab%2C%20you,Image%3A%20image)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=In%20the%20general%20tab%2C%20you,Image%3A%20image)[<sub>20</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=runtime%20to%20store%20your%20cached,This%20means)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=runtime%20to%20store%20your%20cached,This%20means):

• **Workspace Directory** – katalog roboczy (domyślnie workspace/run ). OneTrainer zapisuje tu

wszelkie dane z przebiegu treningu: wygenerowane próbki (obrazy podglądowe), logi

TensorBoard, kopie zapasowe modelu itp. [<sub>21</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Workspace%20Directory%20%28default%20,backup%20from%20the%20selected%20workspace)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Workspace%20Directory%20%28default%20,backup%20from%20the%20selected%20workspace). Możesz utrzymywać jeden wspólny folder lub

utworzyć osobny folder dla każdego projektu (druga opcja jest zalecana przy wielu równoległych

projektach, by dane się nie mieszały).

• **Cache Directory** – katalog cache (domyślnie workspace-cache/run ). Tutaj traﬁają

*przetworzone obrazy i teksty* w trakcie treningu (patrz: latent caching w zakładce Data). Zostaw

domyślną ścieżkę, chyba że musisz umieścić cache na innym dysku (np. szybszym) [<sub>22</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=projects%2Ftries.%20,enable%20and%20disable%20the%20debug)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=projects%2Ftries.%20,enable%20and%20disable%20the%20debug).

• **Continue from last backup** – (domyślnie wyłączone) włączenie tej opcji spowoduje, że jeśli

istnieje kopia zapasowa modelu w katalogu roboczym (np. po wcześniejszym przerwanym

treningu), trening zostanie wznowiony od tej kopii [<sub>20</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=runtime%20to%20store%20your%20cached,This%20means)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=runtime%20to%20store%20your%20cached,This%20means). Używaj, gdy chcesz kontynuować trening

zamiast zaczynać od nowa.

• **Debug Mode** – (domyślnie oﬀ) tryb debugowania, w którym OneTrainer generuje dodatkowe

dane diagnostyczne podczas treningu [<sub>23</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=backup%20from%20the%20selected%20workspace,being%20sent%20through%20the%20VAE)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=backup%20from%20the%20selected%20workspace,being%20sent%20through%20the%20VAE). W trybie debug otrzymasz np. obrazy przedstawiające

porównanie przewidywania modelu vs rzeczywistego obrazu na krokach treningowych, co

pomaga zrozumieć postępy. *Uwaga:* Obrazy debug generowane są poprzez VAE modelu z

zachowanych tensorów, więc ich jakość może być niższa niż oryginałów, ale nadal są przydatne

do analizy [<sub>24</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=mode%20during%20training.%20,All)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=mode%20during%20training.%20,All). Po włączeniu debug mode, musisz też podać **Debug Directory** (domyślnie

debug ) – folder, gdzie te dane się zapiszą [<sub>25</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=they%20will%20go%20through%20the,switch%20on%20the%20Debug%20mode)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=they%20will%20go%20through%20the,switch%20on%20the%20Debug%20mode).

• **TensorBoard** – (domyślnie włączone) czy uruchamiać serwer TensorBoard podczas treningu [<sub>26</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=the%20Debug%20mode.%20,for%20how%20often%20you%20would)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=the%20Debug%20mode.%20,for%20how%20often%20you%20would).

TensorBoard umożliwia śledzenie wykresów strat (loss), ewentualnie podgląd próbek w trakcie

treningu itp. OneTrainer integruje się z TensorBoard automatycznie – jeżeli opcja jest ON, po

starcie treningu możesz kliknąć przycisk *“Tensorboard”* i obserwować statystyki w przeglądarce.

• **Expose Tensorboard** – (domyślnie oﬀ) jeżeli włączysz, TensorBoard zostanie wystawiony na

interfejs sieciowy (nie tylko *localhost*). Przydatne, gdy trenujesz zdalnie (np. serwer) i chcesz

podejrzeć wykresy ze swojego komputera [<sub>26</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=the%20Debug%20mode.%20,for%20how%20often%20you%20would)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=the%20Debug%20mode.%20,for%20how%20often%20you%20would).

• **Validation** – (domyślnie oﬀ) włącza mechanizm walidacji modelu w trakcie treningu [<sub>27</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Expose%20Tensorboard%20%28default%20,for%20choosing%20the%20GPU%20to)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Expose%20Tensorboard%20%28default%20,for%20choosing%20the%20GPU%20to).

Walidacja polega na okresowym sprawdzaniu straty (loss) na osobnym zbiorze walidacyjnym, aby

wykryć nadmierne dopasowanie (overﬁtting) [<sub>28</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Validation)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Validation)[29</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,validation%20loss%20graph%20for%20each)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,validation%20loss%20graph%20for%20each). Gdy włączysz tę opcję, w zakładce *Concepts*

będziesz mógł dodać specjalny koncept walidacyjny (zbiory obrazów nieuczestniczących w

treningu) i ustalić co ile kroków/epok przeprowadzać walidację (**Validate after** – wartość

4

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAGoDASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAFBgIDCv/EAD4QAAAEAwUFBgIFDQAAAAAAAAECAwUABAYHERMXliExUlXWEhVBV5HUFFEiJDVCYSYyMzRxcnN0gbGys8L/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25Iz9XL/WSEvU7mx0TTk+lTkpK00n3RVKtVtIzAPZSOOPMpi0KlXkcFPBvmxKcTihhFxOklLMfq6ZS2gWpJCQoEMmhWAGTKYN4Afu8vbHaF5uyF/wAo9Fl6KKprR1FAUAsraxWaQ9sRMJiF7tvABHbhKbMQgBcp2S3hcUIY0JdBNFNIiaYFSKCYAUgEKUC/dKUNgAF+4NkAV5Ym8xLWNXh7CLLE3mJaxq8PYQtYSXAX0iwkuAvpAEuWJvMS1jV4ewiyxN5iWsavD2ELWElwF9IsJLgL6QBLlibzEtY1eHsIssTeYlrGrw9hC1hJcBfSLCS4C+kAS5Ym8xLWNXh7CLLE3mJaxq8PYQtYSXAX0iwkuAvpAEuWJvMS1jV4ewjxNZgIlNfaJauAdkbxGr9gBd43SG75wuYSXAX0iwU+AofiAXCH7B8BgAxOlpummx5emasKyfpmWklAlkqsfTPDSieUL8RNqy8p8JKiVVNGXXlSHFS4MbxDYO9TlcSz7TzE+JSc8km8szW6ppFEvZTI4yKE2RMu380hVgKH4AEdrUKRO4KiLdeCbI5gAjtEwHkJgTgcfvAYdpr94774HbOJCSy8oP6qgH5GUvuSIAfYcj4XbIDUI8stnTm7ybsV4lpB9enZ8O5JNk87S0zMuYy+xNNpQn5ohiYN5sVBMDActwjcIBsltus3G8AdXr6AiQb6JrkNob99NheHyELwHwEY7pX9Xa/4qX/UbA7/AOhf7BAF+dtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edE1z03CfFAEhrUqNqaXnGVnnHRdxfZRwbpBCZpmqG0p1hkpkgGPMObNJy6aZhD6JlFSX3h84z6PbKgZqSpZomWCeNMtVOMjbMGTXb+wZeRbJWVVEl84A9gVEjCW8AG668AGE16+02T+YV/0qRtp/o0/3C/4hAf/2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAJUDASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBQYECv/EADkQAAADBQUHAgQDCQAAAAAAAAECAwAEBQYHERMXIZYSUlVXkdTWFSIUMUGxFiNRMzQ1YXFyc4HC/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuSNHp5j85IO8zxOByTLj+lLjo6y0n6RNKs1wkXgI2UkRv3lMYQqVdxuU7m17EpxOKF0W86R0pjY7plCoFUkhIUCmIhOG0mUwfMAP6eXbH9T7IW/pk2Cl6KKpqjqKAoBXWrE5pDtiJhMQvptoAI53SmV4QAsU2S2hYUGY0HdBNFNIiZAImUCFApAIUoF+hShkAB8ssmArwxNzEqxq8OwawxNzEqxq8OwZauktwvRq6S3C9GAlwxNzEqxq8OwawxNzEqxq8OwZauktwvRq6S3C9GAlwxNzEqxq8OwawxNzEqxq8OwZauktwvRq6S3C9GAlwxNzEqxq8OwawxNzEqxq8OwZauktwvRq6S3C9GAlwxNzEqxq8OwawxNzEqxq8OwZauktwvRq6S3C9GAlwxNzEqxq8OwawxNzEqxq8OwZauktwvRq6S3C9GAlwxNzEqxq8OwawxNzEqxq8OwZauktwvRq6S3C9GAlwxNzEqxq8OwbVYWHM8vF7UeqvuEu0kpO4nT+FNkQwpDCgLtHOCpTIXg5FAdv3CAN90luF6N4lyoiAXyRAIm8pCntEKcLwpiimoUBAdkwHD2nDMohaFmVoC8lTbFYZEZnlucXssQjMNeXGJur3BXT4dwVl6LA+O8IFcFHgxzxkFoPEfUz7JSCQXIS2iJgLNzEX2E6vzyUdsTfhCnhhESB7tp+nywdratOOQ2mHOywPpYEwdcSMwWnUTi7nFixh2cI7GotHDxJKGP0Wdnl5iYu+SacJQf3ohiXNpr1BMDActgjYIBui1upxmARWNe0RKNskzyGZchstlvMP5haA/QRbuVf3eF/5Uv8AptwPz/0X7AwF+NtOOKxnRU8eNtY2044rGdFTx42ye0wGGNtOOKxnRU8eNtY2044rGdFTx42ye0wGGNtOOKxnRU8eNtY2044rGdFTx42ye0wGGNtOOKxnRU8eNtY2044rGdFTx42ye0wGGNtOOKxnRU8eNtY2044rGdFTx42ye0wGGNtOOKxnRU8eNtY2044rGdFTx42ye0wGGNtOOKxnRU8eNtY2044rGdFTx42ye0wGGNtOOKxnRU8eNthPWmngrlTPEovYqRNRCyTpzMJh2xC0QLLxhSELAGxUCGzD6MqtpXb+JvH9xvsLAYQWXXObo7HJ8R9adyxyHQKEkSfkQdAMjAVo2ukui7KGKukVUY2cDFWSSP8Alk9tttkzYh+yJ/QfuLTB/9k=)![ref3]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]

<a name="br5"></a> 

liczbowa oraz jednostka: np. 1000 steps lub 1 epoch ) [<sub>30</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Expose%20Tensorboard%20%28default%20,example%3A%20cuda%3A1)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Expose%20Tensorboard%20%28default%20,example%3A%20cuda%3A1)[31</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Validation%20%28default%20,To%20disable%20this)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Validation%20%28default%20,To%20disable%20this). Wyniki walidacji obejrzysz w

TensorBoard jako osobny wykres straty dla zbioru walidacyjnego [<sub>32</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Quick%20steps%20to%20enable%20it%3A)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Quick%20steps%20to%20enable%20it%3A)[33</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept).

• **Train device** – (domyślnie cuda ) określa urządzenie do trenowania. W praktyce wpisujesz tu

np. cuda (dla domyślnej karty GPU) lub cuda:1 (jeśli masz wiele GPU i chcesz użyć drugiego)

[<sub>34</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=,To%20disable%20this)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=,To%20disable%20this). OneTrainer nie obsługuje jednoczesnego multi-GPU, ale można wskazać konkretną kartę.

Ustawienie cpu spowoduje trenowanie na procesorze (bardzo wolne – tylko do testów).

• **Temp device** – (domyślnie cpu ) określa urządzenie tymczasowe, na którym przechowywane

będą elementy modelu, gdy nie są aktualnie używane [<sub>35</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Train%20device%20%28default%20,To%20disable%20this)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Train%20device%20%28default%20,To%20disable%20this). Domyślnie jest to CPU (pamięć RAM),

co oznacza, że OneTrainer automatycznie *oﬄoaduje* (przenosi) część modelu do RAM, by

oszczędzać VRAM karty graﬁcznej. Pozwala to trenować większe modele na kartach o mniejszej

pamięci, kosztem obciążenia RAM i CPU. Jeśli chcesz *wyłączyć oﬄoading*, możesz ustawić **Temp**

**device = cuda** (wtedy wszystko trzymane będzie w VRAM) [<sub>36</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Temp%20device%20%28default%20,cuda)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Temp%20device%20%28default%20,cuda). Więcej o oﬄoadingu w sekcji

Zaawansowane opcje.

*(Screenshot: Przykładowa konﬁguracja zakładki General z ustawionymi ścieżkami i włączonym TensorBoard.)*

**Zakładka Model**

W zakładce **Model** podajesz parametry dotyczące modelu bazowego oraz formatu zapisu rezultatów.

Innymi słowy, tu wskazujesz *na czym trenujemy* i *jak zapisać wytrenowany model*. Opcje dostępne w tej

zakładce to [<sub>37</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Here%20you%20define%20the%20base,to%20both%20LoRA%20and%20Finetune)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Here%20you%20define%20the%20base,to%20both%20LoRA%20and%20Finetune)[38</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=it%20this%20is%20where%20you,SD1.5%20LoRA)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=it%20this%20is%20where%20you,SD1.5%20LoRA):

• **Hugging Face Token:** pole na wpisanie *Tokenu API HuggingFace*. Nie jest to obowiązkowe dla

modeli publicznych, ale jeśli chcesz pobierać modele oznaczone jako *gated* (np. SDXL, Stable

Diﬀusion 3.0, Flux) bezpośrednio przez OneTrainer, musisz posiadać token (ze swojego konta HF)

[<sub>39</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,a%20custom%20VAE%2C%20provide%20a)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,a%20custom%20VAE%2C%20provide%20a). Token zostanie zapisany lokalnie (w pliku secrets.json ) i użyty automatycznie przy

wczytywaniu modeli z HF. *Przykład:* model Flux.1-dev jest gated – mając token wpisany tutaj,

OneTrainer może go pobrać z HuggingFace bez ręcznej interwencji [<sub>40</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Model%20Details%3A)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Model%20Details%3A).

• **Base Model:** wskazanie modelu bazowego do trenowania. Domyślnie pole to zawiera link do

modelu z HuggingFace (może to być np. Stable Diﬀusion XL 1.0 jeśli wybrałeś preset SDXL) [<sub>41</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=secrets,in%20the%20backup%20tab%20and)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=secrets,in%20the%20backup%20tab%20and).

Możesz tu wpisać:

• **Ścieżkę do pliku .safetensors/.ckpt** (np. lokalny checkpoint SD 1.5) lub

• **Ścieżkę do katalogu z modelu Diﬀusers** (dla modeli w formacie diﬀusers, które są katalogami z

plikami model\_index.json , unet , vae , text\_encoder itp.) lub

• **URL/ID modelu na HuggingFace** (np. stabilityai/stable-diffusion-2-1 albo link do

konkretnego repo HF).

OneTrainer obsługuje zarówno formaty checkpoint (ckpt/safetensors) jak i Diﬀusers – nie musisz

nic konwertować [<sub>42</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,switching%20to%20a%20different%20application)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,switching%20to%20a%20different%20application). Jeśli np. chcesz trenować LoRA na SDXL, wskaż tutaj ścieżkę do **SDXL base**

**model** (w formacie diﬀusers lub AIO safetensors). Dla modelu Flux musisz tu podać katalog z

modelem Flux.1 (jeśli go pobrałeś ręcznie z HF – patrz sekcja Flux).

• **VAE Override:** opcjonalnie możesz podać ścieżkę do alternatywnego modelu VAE, który ma

zostać użyty podczas treningu (i generowania próbek) [<sub>43</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=it%20this%20is%20where%20you,and%20the%20optional%20checkpoint%20format)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=it%20this%20is%20where%20you,and%20the%20optional%20checkpoint%20format). Jeśli zostawisz puste, używany będzie

domyślny VAE z modelu bazowego. Override bywa przydatny, np. gdy chcesz użyć ulepszonego

VAE dla SD1.5 (klasycznego) albo gdy trenujesz styl i chcesz określony VAE.

• **Model Output Destination:** docelowa nazwa/ścieżka dla zapisywanego modelu wynikowego

(twojego wytrenowanego LoRA lub checkpointu) [<sub>44</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Hugging%20Face%20link%20or%20a,unless%20you%20have%20a%20reason)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Hugging%20Face%20link%20or%20a,unless%20you%20have%20a%20reason). Możesz podać pełną nazwę pliku (np.

models/moj\_lora.safetensors – wtedy plik z LoRA znajdzie się tam po treningu). Jeśli

podasz istniejący folder, OneTrainer wygeneruje nazwę pliku automatycznie, używając preﬁxu

kopii zapasowej i sygnatury czasu [<sub>44</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Hugging%20Face%20link%20or%20a,unless%20you%20have%20a%20reason)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Hugging%20Face%20link%20or%20a,unless%20you%20have%20a%20reason). **Uwaga:** Dla LoRA nazwa powinna mieć rozszerzenie

.safetensors lub .ckpt (choć zalecane jest safetensors ze względów bezpieczeństwa).

5

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFUDASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBQYECv/EADcQAAECBAMFBgMHBQAAAAAAAAIBAwAEBQYHERMSFyExllJVV5HU1hUicyMkMkFCUbIzNIGxwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmir181+8mJe56nQ7JtyfatyUlbab+EXS7ddJWYStiFR15ltaQ6L8jot6Oc2ompqxpDqdJKYY/d2xHEDFJpQFAJti8EJsSTmiH8PHbXimZbKZ/tGDC9ll0sR3HEcQZXFi82l21UlIB+G5oirx0nOGoCJk5sjmmQpDGxLsNsttA22gtCjaIIIAig/pEU4IiZ8k4QBXuxLxExY6vT0EW7EvETFjq9PQQtaTXYHyi0muwPlAEu7EvETFjq9PQRbsS8RMWOr09BC1pNdgfKLSa7A+UAS7sS8RMWOr09BFuxLxExY6vT0ELWk12B8otJrsD5QBLuxLxExY6vT0Ea5MN22ao0SYh4pzDzRhNOybt3Kcs4y0H4Z9lacgvMPEgsECOIqg4iZpyhr0muwPlGBxoBMERODpKJIvFEQRzRA7PzIhLl+pNrnAF9m3NPT9VvG36mLhT9q1aSlTfpwo2y7KVWnM1imgYkeavStPmpeXcPkZtkSIKLspR5rIk5VzEXGc3GGnDWvWkhGYCRls2XSkRSJUzVURETNfySKA8IVmi4dVOrydWGsS0hXa1Vq4dSapk9VpaZmamsvwbbpLE/NAQaOZarDaEhjkq5KibkcbsN1zRKrWvkVQXOyb5TinPnbaZp+ypmi/kqx3Tv9vS/qtf8AUbhef+B/0kAX77cOO9az0VfHtuLfbhx3rWeir49twnxQBhvtw471rPRV8e24t9uHHetZ6Kvj23CfFAGG+3DjvWs9FXx7bi324cd61noq+PbcJ8UAYb7cOO9az0VfHtuMR41YdETRJVasiC4gptWdegKSmmyn4reTZyVeKlkmXHPLjCpHO1Xm79aX/gEBpLPpJsV29rqZmG5qnXpP0Oo04AZm5eZl2adQZOlODNszkvLm2449LE62giX2RDtbJ5ilCAx/QZ+k3/AYoD//2Q==)![ref4]![ref2]![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAnADsDASIAAhEBAxEB/8QAGgAAAgMBAQAAAAAAAAAAAAAAAAcDBAUGCv/EADcQAAECBAMEBggHAQAAAAAAAAECAwAEBREGEiEHExQxFyJBUZTRFVJUVmFxodMjM1eBkZbVQv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD38RTmW0KUVuALQhtaVIte6V5b6aX1A05Rciq+QCnr5SSkWAupSjfID2FOhuO23MWMAp61UZ/EOKJvB9BxCqh1DDlLpc/ibcS5emXZPEJmxS+BWH2SzMj0ZPbt4he6J0QrNFNGzB0snJtH2vJS+te8E5jLczDaurl4c+jV5G9VEJsb6C4iTC5aXtp2msKaQXmsIbOd9MBFnJhLjmKsiHF3JWlrKrdjTLnV60OZDTbacqEJSm5NgO084BTdGB/Ubav/AG8/58HRgf1F2r/24/58NjcteoPr5wbhr1B9fOAVJwRVaGzNzlFxvi+o1VUq9LyEtjCsmsUUzLoBbW7JiXlTvklNm3Q71AVjKrNF+jymNXKXIrrz2HjWFS6DUTLSh3Bmrfibq7t8nK19YYbzSUtq3QSl1Qytkn/o8hr26fPu1iJUuFKJLaiSb3zEX/aArLr1JbW425OsoW0sIWFKAso305/A/tED1coq7J9JSqVNrCzdxPNAOh/mE/iYtIqtRQ2hsHjBoD8V9nP53vzjFLKkOElLLqHy4lbVzmAAT1rm4INz2a20v2B1r1Tw/gbFtSxfiWqGnyeKKNRZByrvtZaKh6jKn1MMOzoUcj74qKzLNbpWfdunMnKb6vTlsi9/8O+LV9uOpoDKF0WmNhGdpDFi282l2xATlsFaWTrY2PM/ONjgmPZGPBteUAvunLZF7/4d8Wr7cHTlsi9/8O+LV9uGDwTHsjHg2vKDgmPZGPBteUAtJzblsr4ZxUnjOg1CcQnNKSbM0VPTEwPy2mhu9XFE2TG9RMWVqepNPnJnDFTS/MyyHXAls5QpdzpdINrWtcR070m0lKVJlGSUrSohMi2tRSL3CQCnKe5VzbuMWkJWpCSkzSQRolSikgdxSEkA/C8AtKthWpzlSqM2FSw4jlra2p1tp3/SMxWDaoGilS5XKW20aKPMXv8Azf4QQQDYo0o7JyEnLuBF2WQhSkHS4AAsO49vLkI14IIAggggCCCCA//Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZADgDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAFBgIDBAr/xAA2EAACAQIEAwMJCAMAAAAAAAABAgMEBQAGBxESEyEXMZYVQVJVV2GR1NYiJDI0QlGBsXFzwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bomv2eb/AJygp8z3Ox5Jy5XxZcpKXLUfkjNMua7SagXtUuPPqYzaJVnoeTHyd6sq5cwcpeZslJpj93jVdQNUoiihGjgzgGjVh3gP5PXjPUbtwjf9sdGl8MMrajySCQLS6sZziPGSxZF8m7gE9eVJ05iAbScK7jZRhjgp4I4Y4kjjCxKIwFQIqhf0qo6ADfuHTAFfZi3tE1Y8Xj5DF2Yt7RNWPF4+QwtcqL0F+GLlRegvwwBL2Yt7RNWPF4+Qx5ajTRYtw2peqcRnVkCtm8rKzDbhKSLb24NuuxKkdfdhk5UXoL8McTAhZWBdNu8RsVVvc4HRh/nu82AJjl/O9hTLdPljMtRd6GGviS9Q5tkN0uc1AynnzR31WgKvEwQJTG3kTcxmMsfLCvYVTTwxpskUQXmcbBgACx33Y9NuP39/vxYAXS82XTq53ejuy3imoL7ertfHuUVsrrtTVNTczT9I47TBX1SMnJ3bmwRhg67E7EDMrrdpudwLrevsEod8k55HUd/flsbj9iNwfMTjepfy9r/2xf8AWMwe/wDhf6GAL+23Tj1refBWePpvF226cetbz4Kzx9N4T8WAMO23Tj1refBWePpvF226cetbz4Kzx9N4T8WAJ59VrZfJrfbcjQVt/uk9wpxW0ldYMx2WGGzhZBWVgq7za7dRs8Ehp1WAVBmkEjGOJwjlbC0n4h/P9HFgP//Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZACIDASIAAhEBAxEB/8QAGgAAAgMBAQAAAAAAAAAAAAAAAAcEBQYDCv/EADIQAAEDAwMCBAQEBwAAAAAAAAECAwUEBhEAByESEyIxQWEVFjRRFCU3cnN0gbGywcL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A9tzap2+Z+8qenueSg7JtyvatulpbabMPdLt1RJqBNpRI9+pbMO6l+h7TfYzVlKyss9pIc0lJthinaSNwN0mihIQpunvAKbSoeYC/h6e4fuvpHV9tcNr2WXVbjuOBwJpd2LzZwslRUgfDcgZ57TmR3EAEOdKcjCRpxsU7DbLbSG0BDSQ2kJQEJSE8BKUjgADgAcaBTu7Y4QVq3H3VbDfj63Lt6kpI45SKDngka5ItaQtqPnJmJvq8JKpbo3KxCbokzctAGqVCqhxDEcpuM7TjiW+0lzvq7YUSEqx0lxKZbIIA6CfJSD0qHulQ5B99UdxUzSYCed6ep0QcqgOqPU6E/gXzgLPiwSATzyQNBjrcvNU9b0DOqhy2qahouWU3wegyNCxWFGfXpL3Tn20ayu2/6d2Fkkn5LtbJJyT+R0PJJ5JPqT56NBKRMwu3UnL0csmYpqCdmpacXJNRldLU1TUyZp+G24livqkKR2cq7rDYUFpwTggXSd7ttzkCVmvCSk5sm+Ryng+dt8j3GQfQnW5d+ni/4rX/AFq4Pn/RP9hoFed7NvClakSUyvtpK1D5NvVGEAgFWXLeSDgkeEEqOeAQDiO9urZdzUUjDQ1bK1NfXxUgxTtu2vdVE2XXqZxltKn6+EpWU9S3E4UpwJGckgDOmfV/Tu/t/wBjUSg+pR/LK/ya0CksyNuKHs+1IirtyQFVF21BR1SEvxpSKihi6WleCSa3OA40rGfTRp7aNB//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZACIDASIAAhEBAxEB/8QAGgAAAgMBAQAAAAAAAAAAAAAAAAcEBQYDCv/EADIQAAEDAwMCBAQEBwAAAAAAAAECAwUEBhEAByESEyIxQWEVFjRRFCU3cnN0gbGywcL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A9tzap2+Z+8qenueSg7JtyvatulpbabMPdLt1RJqBNpRI9+pbMO6l+h7TfYzVlKyss9pIc0lJthinaSNwN0mihIQpunvAKbSoeYC/h6e4fuvpHV9tcNr2WXVbjuOBwJpd2LzZwslRUgfDcgZ57TmR3EAEOdKcjCRpxsU7DbLbSG0BDSQ2kJQEJSE8BKUjgADgAcaBTu7Y4QVq3H3VbDfj63Lt6kpI45SKDngka5ItaQtqPnJmJvq8JKpbo3KxCbokzctAGqVCqhxDEcpuM7TjiW+0lzvq7YUSEqx0lxKZbIIA6CfJSD0qHulQ5B99UdxUzSYCed6ep0QcqgOqPU6E/gXzgLPiwSATzyQNBjrcvNU9b0DOqhy2qahouWU3wegyNCxWFGfXpL3Tn20ayu2/6d2Fkkn5LtbJJyT+R0PJJ5JPqT56NBKRMwu3UnL0csmYpqCdmpacXJNRldLU1TUyZp+G24livqkKR2cq7rDYUFpwTggXSd7ttzkCVmvCSk5sm+Ryng+dt8j3GQfQnW5d+ni/4rX/AFq4Pn/RP9hoFed7NvClakSUyvtpK1D5NvVGEAgFWXLeSDgkeEEqOeAQDiO9urZdzUUjDQ1bK1NfXxUgxTtu2vdVE2XXqZxltKn6+EpWU9S3E4UpwJGckgDOmfV/Tu/t/wBjUSg+pR/LK/ya0CksyNuKHs+1IirtyQFVF21BR1SEvxpSKihi6WleCSa3OA40rGfTRp7aNB//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAEAAQDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAr/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/AL+AAf/Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAGMDASIAAhEBAxEB/8QAHAABAQEAAQUAAAAAAAAAAAAAAAcGBQECAwQK/8QANBAAAQIEAwYGAQEJAAAAAAAAAgEDAAQFBgcRExIXITFVlhVSV5HU1iJRMjRBQmFzgbHC/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuaKvXzX7yYl7nqdDsm3J9q3JSVtpvwi6XbrpKzCVsQqOvMtrSHRfkdFvRzm1E1NWNIdTSSuGOUu2I4gYpNbAoJAxeCE2JJzRD8PHbX9T2Uz/SPBheyy6WI7jiOIMrixebS7aqSkA+G5oirx0nOGoCJk5sjmmQpFkYl2G2W2gbBBaFGxQQQBFB5CIpwRE5IicICVbsS9RMWO70+BDdiXqJix3enwIrWk15B9oaTXkH2gJLuxL1ExY7vT4EN2JeomLHd6fAitaTXkH2hpNeQfaAku7EvUTFju9PgQ3Yl6iYsd3p8CK1pNeQfaGk15B9oCS7sS9RMWO70+BDdiXqJix3enwIrWk15B9oaTXkH2gI+9hi6mwbeI2KqEBKqC5eSg2akiiiGg009tEVdrZXZ4pzj1xsCt0t2ZdoeIl+uzziDml21Qbgoqo4IircnLiMiUu7mq6bykekaoewWzktqEAFcxFEVeHBMo7dFvaI0BEMkyU0TI+WX7XPlygM1ZVwSV0WxS63IOK9LzKTcurpDsq5M0yfmqXOns5rkhTslMEnFc0VFhGXwZ2d3NEQG22hScuZEBoEbBMrqreaoI5IikuZEv8AMakS8VWEBngrNFw6qdXk6sNYlpCu1qrVw6k1TJ6rS0zM1NZfg23SWJ+aAg0cy1WG0JDHJVyVE5ocbsN1zRKrWvxVRXOyb5TiPBedt8U/qmaL/BVjcu/u9L/utf8AUcwvP/A/6SAl++3DjqtZ7Kvj63Dfbhx1Ws9lXx9binwgJhvtw46rWeyr4+tw324cdVrPZV8fW4p8ICYb7cOOq1nsq+PrcN9uHHVaz2VfH1uKfCAmG+3DjqtZ7Kvj63Dfbhx1Ws9lXx9binwgJhvtw46rWeyr4+tx0XGqwnEVuRm65PTriKEnIt2hd8u5OTRfjLyoTE7QpaTYOYdUGRem5iXlmiNDfeaaEzGoQgMbhpRZ63rKo1KqTaNTrR1SaeaQkJWfE6zUKm2yZCqirjTM4227sEQagnsEQ5EqN1CA/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAIADASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBAUGCv/EADUQAAECAgcHAgUDBQAAAAAAAAECAwAFBAYHERMXlhIhUlVXkdQx1hUiQVFzNLHCJDJCgcH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25pU+rzP65MUes8zkdSauU9qrlEotWm/hFaXa1yk0gTtKJjj0lsyh1L9BwW8G+llKyssYScT0lEsx/p20ptAtSaKEhCm2K4BTaVD1AX8PTtneL1bIv+0YLL2WXVWjuOBwJotrFc2jtkqKkJ+G3gE78JzdiIAuc2U3i5IhjYo7DbLbSG2wlpIbASgISkJ/xSkbgBf6DdAFeWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAD1IszKEAqtHtVbQpQSta647Gykg70ES5Xz33BO4Ded4jK1Iq5SF2rMvkFZaRMKDRqeX60vVteVPJ/S5WoJDTdHmAFDSlaLl7lNG/a+n1WHWkbBCUJAO5RO75bj/ANujTAdBSVrSdhgikgXkKUdnDITddduX6j7QBCicyWzqZzehzZM4o1Ans6m08XMmpZTptRqTSZmaPubblLFPpSFIwb1YrDYUFpuJuIHZTbdZubwJrOvkJQb6k15G8evrVsXj7EXg/QmPdO/p5X+Vr+Udg+v+k/sIAvzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAtctqs7W2somU4XhpLikmp1dGvkTuNxdq+2lRF4+QEqIvISbjdzmrT6DWCYSegVPbps1cpEzS9MVvyGsMobRLGwQtvFnUrlrSnllxGwNspAQq9YFwKhNv0o/Kj9lRuUT+yj/iV/GA//9k=)![ref2]![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAM8DASIAAhEBAxEB/8QAGQABAQEBAQEAAAAAAAAAAAAABwAFBgMK/8QAOBAAAAQEAwcDAQQLAAAAAAAAAAECAwQFBgcTF5YRUlVXkdTWEhUhMRQiNFEjJDNBQnN1gbG0wv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmlT6uZ/WTEPU8zkdE05HtU5CQtNN+0VS7VcpOIKdpRMceJbOUOpfgcFvB2xZpWazYwk4nSQlsf1dtKbgXSaNCSQptisCU2lRfUiX7en1n8ltV6S2/kPC17LLqrjuOE4SYW7FZtH6zNRqQn23aRGfzhOfGIgi2OelO0tiSDGxDsNsttIbbJLSSbIkoJCUkn+FKS+CItv0L4AFeWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCgHpnR9QymnptVcfP4WoER7FKQ0fKURM4hnJVCqmU0cm9QKmSTmS1sKUUOZS6Gw2iaZ+8TfrUtYTW4noCisGmlXMtEhbTbiVO1wkicQSybNNNLWamtv7Na9vpcUnYa0ESD+CAZCJzJbdTObwc2TOIaAns6m08XMmpZHTaGiYmZnD/DbcpYj4pCkYO1WKw2SiWnYZ7DItlN7rbntIprOvuGaD20TXJfJfX602W0vyMtpH+4zHdO/h5X/ADWv+hsH9f7J/wAEAL87bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsZkPNWa+rWj6ikjMY3I6PdqJURHzCDipf7h7zJfsDKYODjGWI9tTL6v0xRkLDbUEa2/Wk0mpiGLL/AMVO/wCoN/6UIA//2Q==)![ref5]![ref3]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]

<a name="br6"></a> 

• **Output Format:** format zapisu – do wyboru safetensors (domyślnie) lub ckpt [<sub>45</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=saved,unless%20you%20have%20a%20reason)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=saved,unless%20you%20have%20a%20reason).

Safetensors są preferowane (bezpieczniejsze, mniejsza szansa uszkodzenia modelu).

• **Data Types:** parametry precyzji treningu. OneTrainer umożliwia wybór formatu danych dla wag i

gradientów, co wpływa na zużycie VRAM i szybkość. Jeśli korzystasz z wbudowanych presetów,

wartości te są już dobrane optymalnie [<sub>46</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,unless%20you%20have%20a%20reason)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,unless%20you%20have%20a%20reason). Zaawansowani użytkownicy mogą tu zmieniać m.in.:

• Typ wag modelu (ﬂoat32, ﬂoat16, bﬂoat16, int8 NP4/NF4 itp.),

• Typ wyjściowego modelu (np. LoRA w 16-bit czy 8-bit).

**Uwaga:** Należy zmieniać te ustawienia tylko jeśli wiesz co robisz – domyślne są zwykle

odpowiednie [<sub>46</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,unless%20you%20have%20a%20reason)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,unless%20you%20have%20a%20reason). Przykładowo, dla dużych modeli jak Flux rekomendowane jest użycie co

najmniej **FP8** precyzji, by uniknąć artefaktów (Flux w niższej precyzji NF4 może dawać siatkowy

wzór na obrazach) [<sub>47</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close).

*(Screenshot: Zakładka Model z wczytanym modelem bazowym SDXL i ustawioną nazwą pliku wyjściowego*

*LoRA.)*

**Zakładka Data (Dane)**

W zakładce **Data** ustawiamy opcje dotyczące przetwarzania danych treningowych, głównie związane z

przyspieszaniem treningu i obsługą różnych rozmiarów obrazów. Znajdują się tu przede wszystkim trzy

przełączniki [<sub>48</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios)[49</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,are%20changed%20during%20a%20restart)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,are%20changed%20during%20a%20restart):

• **Aspect Ratio Bucketing:** (czyli *bucketing proporcji obrazu*) – **must-have** podczas treningu na

obrazach o różnych proporcjach. Po włączeniu tej opcji OneTrainer automatycznie pogrupuje

(przypisze do “bucketów”) obrazy o podobnych proporcjach i dopasuje ich rozmiary tak, by miały

zbliżoną liczbę pikseli [<sub>48</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios). Dzięki temu można jednocześnie trenować na obrazkach 1:1, 16:9, 3:2

itd., bez rozciągania – każdy bucket ma swoją “bazową” rozdzielczość. To potężna funkcja:

umożliwia trenowanie zróżnicowanych zbiorów bez ręcznego przycinania wszystkich do jednego

formatu. **Zaleca się mieć włączone** (domyślnie włączone w presetach).

• **Latent caching:** (*keszowanie latentów*) – po włączeniu OneTrainer będzie zapisywał w folderze

cache wstępnie przetworzone wersje obrazów (ich reprezentacje latentne) [<sub>50</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=ratios)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=ratios). Ponieważ

generowanie latentów z obrazów (przepuszczanie przez encoder VAE) to operacja kosztowna,

keszowanie przyspiesza kolejne epoki treningu – zamiast liczyć to za każdym razem, model

wczyta z dysku wcześniej obliczone wartości. *Uwaga:* Kesz zajmuje miejsce na dysku (w zależności

od datasetu może to być kilka-kilkanaście GB). Warto włączyć, jeśli masz dość miejsca – znacznie

przyspiesza trening, zwłaszcza przy wielu epokach.

• **Clear cache before training:** – czyszczenie cache przed startem treningu [<sub>51</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,images%20and%20saved%20to%20disc)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,images%20and%20saved%20to%20disc). Domyślnie

**włączone**, co oznacza, że przy każdym nowym uruchomieniu treningu OneTrainer usunie stare

pliki cache (z poprzednich konﬁguracji/ustawień) i zbuduje je od nowa. Dzięki temu masz

pewność, że zmiany w obrazach czy parametrach zostaną uwzględnione. Wyłącz tę opcję tylko,

jeżeli **kontynuujesz ten sam trening** i nie zmieniasz nic w danych – inaczej stary cache może

powodować błędy (np. jeśli zmieniono rozdzielczość docelową, stary cache nie pasuje i nastąpi

błąd) [<sub>52</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=images%20and%20saved%20to%20disc)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=images%20and%20saved%20to%20disc).

Dla początkujących zaleca się zostawić wszystkie powyższe opcje **włączone** – co OneTrainer robi

domyślnie w presetach [<sub>53</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=In%20the%20top%20left%2C%20next,one%20you%20want%20to%20train)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=In%20the%20top%20left%2C%20next,one%20you%20want%20to%20train)[54</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=In%20,001.txt)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=In%20,001.txt). Dzięki nim trening będzie efektywniejszy i bardziej stabilny.

Ponadto w zakładce Data (w nowszych wersjach) może pojawić się opcja **Dataloader Threads** – liczba

wątków do wczytywania danych. Jeśli posiadasz mocny CPU, możesz zwiększyć dla szybszego ładowania

batchy (np. posiadacze RTX 4090 często ustawiają 8 wątków) [<sub>55</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Define%20the%20filepath%20for%20the,high%20can%20cause%20VRAM%20issues)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Define%20the%20filepath%20for%20the,high%20can%20cause%20VRAM%20issues). Ale ostrożnie: zbyt wiele wątków może

zająć dodatkowy VRAM, zaleca się testować (domyślnie chyba 1 lub 2).

6

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFwDASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAFBgMECv/EADgQAAECAwUECAQFBQAAAAAAAAECAwAEBQYHERMXEiFSlhUxUVVXkdTWFBYiNSQ0QXOxQnKBssL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25pVetzX7ZMS9p6nQ7E2cn2rOSkrZpvoi1Ltq6SZgVtKKjnzLZpDqX5HJbycZspWVljKTmdJKXY/h20pvAvSaKEhCm2LYBTaVDrAX0enbO8Yq2Rj2R4Lr2WXVXjuOBwJlb2LZtHbJUVIT0biATvynN2YgDBzZTiMEiGNiXYbZbaQ22EtJDYCUBCUhP9KUjcAMeoboAr0xV4iXsc3j0EWmKvES9jm8eghaymuBPlFlNcCfKAJdMVeIl7HN49BFpirxEvY5vHoIWsprgT5RZTXAnygCXTFXiJexzePQRaYq8RL2Obx6CFrKa4E+UWU1wJ8oAl0xV4iXsc3j0EWmKvES9jm8eghaymuBPlFlNcCfKAK5a79VMmWJ/56vJnFSrgdRL1S0vxlPWsJUE/GS4k2y6wCRtpCwSN2Ma1lJa0xp0x89zlDnawKlOCXfpkmuXYVSdpHR4caW64RMBG3nEKIJIwjunWkBO5CMCcFY7sU4EkDtViBgIyhKy76W3XJhYKm04Bf1LCBuSFKJxUoDrUd5/WAKkVmi3dVOrydWTWJaQrtaq1cXUmqZPVaWmZmpmX3Nt0lifmkKRk4qzWGwoLTgTgQNlN9125xAqta+glBxsTbkbx19dmxiOwjEH9CY7p38vS/wB1r/qNg9f+E/wIAv1tu471rPJVuPbcWtt3HetZ5Ktx7bhPigDDW27jvWs8lW49txa23cd61nkq3HtuE+KAMNbbuO9azyVbj23Frbdx3rWeSrce24T4oAw1tu471rPJVuPbcWtt3HetZ5Ktx7bhPigCt6+m7laARU6ypTag4hJsbbdsKUnEAKWuzyEAfVv2lBOOBPbGjQbS1uqSbs8qzbsxKzE5MLpjrZlmCqmEpMnmszT7D7b2wTmJW2CCR1x2lU+3Tn7C/wCI9ehfbJb+wf6pgP/Z)![ref2]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]

<a name="br7"></a> 

*(Więcej informacji o bucketingu i proporcjach znajdziesz w sekcji Proporcje obrazu i bucketing oraz na wiki*

[<i><sub>56</sub></i>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Concept%20page)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Concept%20page)<i>.)</i>

**Zakładka Concepts (Zbiór danych)**

To kluczowa zakładka, gdzie konﬁgurujesz **zbiór treningowy**. W OneTrainer pojęcie *Concepts* oznacza

po prostu zestawy obrazów ze swoimi podpisami, używane do treningu modeli. Możesz mieć wiele

konceptów – np. jeden główny (ze zdjęciami obiektu/osoby, których model ma się nauczyć), drugi z

obrazami regularyzującymi (tzw. negative class/prior), trzeci jako walidacja itd. [<sub>57</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=The%20Concepts%20tab%20configures%20where,want%20to%20use%20during%20training)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=The%20Concepts%20tab%20configures%20where,want%20to%20use%20during%20training)[58</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,using%20the%20currently%20selected%20configuration)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,using%20the%20currently%20selected%20configuration). Zakładka

Concepts umożliwia dodawanie, usuwanie i konﬁgurowanie takich podzbiorów.

Główne elementy UI w tej zakładce to [<sub>59</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=The%20tab%20comprises%20the%20following,elements)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=The%20tab%20comprises%20the%20following,elements)[60</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,concept%20within%20the%20current%20configuration)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,concept%20within%20the%20current%20configuration):

• **Dropdown Menu (Concept Conﬁg):** lista konﬁguracji konceptów. Domyślnie jest jedna

konﬁguracja *concepts*, ale możesz dodać kolejne. OneTrainer trenuje tylko tę konﬁgurację, która

jest aktualnie wybrana na liście [<sub>58</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,using%20the%20currently%20selected%20configuration)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,using%20the%20currently%20selected%20configuration). (Funkcja ta bywa używana, by szybko przełączać się między

różnymi zestawami danych/treningami bez ręcznego przeładowywania wszystkiego).

• **Add Conﬁg / Delete Conﬁg:** przyciski do tworzenia lub usunięcia całej konﬁguracji konceptów

(czyli zestawu konceptów).

• **Add Concept:** przycisk dodający nowy *concept* do aktualnej konﬁguracji [<sub>61</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,create%20a%20new%20concept%20configuration)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,create%20a%20new%20concept%20configuration). Gdy go klikniesz,

pojawi się nowa pozycja na liście z domyślną nazwą – kliknij ją, aby otworzyć okno edycji

szczegółów konceptu (alternatywnie kliknij ikonę *Edit*).

• **Lista Conceptów:** poniżej, każdy concept jest wyświetlany (z nazwą lub ścieżką). Możesz włączać/

wyłączać koncept (toggle **Enable**, niebieski gdy włączony) – co wpływa na to, czy będzie brany

pod uwagę w treningu [<sub>62</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,along%20with%20all%20its%20settings)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,along%20with%20all%20its%20settings). Są też ikony: czerwony X usuwa concept [<sub>63</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,a%20concept%20from%20the%20configuration)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,a%20concept%20from%20the%20configuration), zielony + duplikuje go

(kopiuje ustawienia i pozwala np. podmienić ścieżkę) [<sub>63</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,a%20concept%20from%20the%20configuration)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,a%20concept%20from%20the%20configuration).

Po dodaniu/wybraniu conceptu kliknięcie go otworzy **okno ustawień conceptu**, podzielone na zakładki.

Tam konﬁgurujemy szczegółowo dany zbiór danych. Najważniejsze ustawienia (zakładka *General* w

oknie conceptu) to:

• **Name:** Nazwa konceptu (możesz nazwać np. „moja\_postac” lub zostawić puste – wtedy nazwa

zostanie nadana na podstawie nazwy folderu po zatwierdzeniu) [<sub>64</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Concepts%20Settings%20)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Concepts%20Settings%20).

• **Enabled:** to samo co toggle na liście – czy concept jest aktywny (domyślnie True) [<sub>65</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,provided%20when%20closing%20the%20window)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,provided%20when%20closing%20the%20window).

• **Concept Type:** typ konceptu – *Standard* (zwykłe dane treningowe), *Validation* (dane tylko do

walidacji – zostaną użyte przy obliczaniu straty walidacyjnej, ale nie wpłyną na trening) albo *Prior*

(tzw. prior preservation – używane w DreamBooth do zapobiegania nadpisaniu oryginalnych

cech modelu przez generowanie obrazów „klasy”) [<sub>66</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=OneTrainer%20will%20train%20using%20this,concept)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=OneTrainer%20will%20train%20using%20this,concept). Jeśli twój concept ma pełnić rolę obrazów

regularyzujących (tzw. „negative class images”), wybierz **Prior**. Dla walidacyjnego – **Validation**

(pamiętaj dodać ich włączenie w zakładce General → Validation). Standard to zwykły treningowy

zbiór.

• **Path:** ścieżka do folderu z obrazami dla tego conceptu [<sub>67</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,can%20also%20click%20the)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,can%20also%20click%20the). Tutaj wskazujesz katalog, w którym

znajdują się pliki obrazów (JPEG/PNG) i ewentualnie ich podpisy .txt. Po wybraniu folderu

OneTrainer automatycznie wczyta listę plików. **Uwaga:** Zadbaj o poprawną strukturę – najlepszą

praktyką jest trzymanie obrazów i plików .txt parami o tej samej nazwie (np. 001.jpg i

001\.txt ). Jeśli pliki .txt są w osobnym folderze lub inaczej nazwane – dopasuj to opcjami

*Prompt Source*.

• **Prompt Source:** sposób wczytywania podpisów do obrazów [<sub>68</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,Choose%20one%20of%20three%20options)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,Choose%20one%20of%20three%20options). Możliwe opcje:

• **From text ﬁle per sample** – domyślnie. Każdemu obrazowi odpowiada plik .txt o tej samej

nazwie (np. obraz 001.jpg i tekst 001.txt ) [<sub>69</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=1,Default%3A%20False)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=1,Default%3A%20False). Jeśli w pliku jest wiele linijek, OneTrainer

7

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAEAAQDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAr/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/AL+AAf/Z)![ref4]![ref4]![ref2]![ref4]![ref4]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]

<a name="br8"></a> 

będzie losowo wybierał jedną linijkę jako podpis w danej epoce, co pozwala mieć wiele

wariantów opisu dla jednego obrazu.

• **From single text ﬁle** – wskazujesz jeden plik .txt, którego zawartość będzie używana jako ten

sam podpis dla wszystkich obrazów [<sub>70</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=captions%20,From%20image%20file%20name)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=captions%20,From%20image%20file%20name). Rzadziej używane (może przy stylach).

• **From image ﬁle name** – OneTrainer odczyta podpis z nazwy pliku obrazu (np.

sunset\_beach.png → podpis „sunset beach”) [<sub>71</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=2,Default%3A%20False)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=2,Default%3A%20False). Użyteczne, jeśli Twoje pliki są nazwane

tagami zamiast mieć osobne .txt.

• **Include Subdirectories:** (domyślnie False) – jeśli włączysz, OneTrainer rekurencyjnie weźmie

obrazy również z podfolderów wskazanej ścieżki [<sub>72</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=For%20example%2C%20,single%20concept%20for%20easier%20management)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=For%20example%2C%20,single%20concept%20for%20easier%20management). Przydatne, gdy masz dane podzielone w

podkatalogach, a chcesz traktować je jako jeden concept.

• **Image Variations:** (domyślnie 1) – parametry zaawansowane, związane z augmentation i

caching. Określa ile *wariantów obrazów* będzie keszowanych z uwzględnieniem augmentacji [<sub>73</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,image%20augmentations%20and%20latent%20caching)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,image%20augmentations%20and%20latent%20caching).

Jeśli używasz augmentacji losowych (patrz niżej) oraz latent caching, możesz zwiększyć tę liczbę,

by przechować kilka zróżnicowanych wersji każdego obrazu. Standardowo 1 wystarcza (przy

włączonym caching i augmentacjach musisz ustawić *Image Variations >= 1*).

• **Text Variations:** (domyślnie 1) – analogicznie, ile *wariantów tekstu* (podpisu) będzie keszowanych

na obraz [<sub>74</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,will%20always%20be%20the%20same)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,will%20always%20be%20the%20same). Jeśli nie trenujesz encoderów tekstowych i korzystasz z caching, zaleca się

zwiększyć tę wartość, aby uniknąć sytuacji, że jeden wylosowany podpis zostanie użyty w każdej

epoce (z cache). Generalnie, jeśli masz wiele epok i wiele możliwych podpisów na obraz, daj

większe *Text Variations* by rotacja była większa.

• **Balancing:** (domyślnie *Repeats: 1*) – niezwykle ważna opcja, gdy masz nierówne ilości obrazów w

konceptach. Balancing pozwala zbalansować wkład każdego conceptu w trening [<sub>75</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,There%20are%20two%20modes)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,There%20are%20two%20modes)[76</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,if%20they%20are%20overly%20influential)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,if%20they%20are%20overly%20influential). Dwa

tryby:

• **Repeats:** Podajesz liczbę powtórzeń – oznacza to, że każdy obraz z tego conceptu będzie liczył się

jak *n* obrazów. Np. jeśli concept A ma 100 obrazów, concept B ma 1000 obrazów, możesz ustawić

repeats=10 dla A, by efektywnie zrównać ich wpływ. Domyślne 1 oznacza brak powtórzeń.

• **Samples:** Alternatywny tryb – możesz zamiast powtarzać, określić **dokładną liczbę obrazów z**

**tego conceptu na epokę** (będzie losowo wybierana ta liczba spośród wszystkich). Ten tryb bywa

użyteczny przy bardzo dużych zbiorach regularyzacyjnych – możesz np. ustawić, że w każdej

epoce weź 200 losowych regularyzacyjnych spośród 10k dostępnych, zamiast używać wszystkich.

• **Loss Weight:** (domyślnie 1.0) – waga straty dla tego conceptu [<sub>77</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Uses%20an%20exact%20number%20of,if%20they%20are%20overly%20influential)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Uses%20an%20exact%20number%20of,if%20they%20are%20overly%20influential). Pozwala zmniejszyć wpływ

któregoś zbioru na dostrajanie. Np. jeśli używasz obrazów regularyzacyjnych (prior preservation)

i zauważasz, że zbyt mocno one wpływają hamująco na trening, możesz dać im wagę np. 0.5 –

wówczas gradient z nich będzie mnożony przez 0.5, czyli ich wpływ na parametry będzie

mniejszy. Zazwyczaj zostaw 1, chyba że wiesz co robisz.

Po skonﬁgurowaniu powyższych ustawień kliknij **OK/Zatwierdź** (w GUI to zwykle zamknięcie okna

conceptu zapisuje zmiany). **90% sukcesu treningu zależy od jakości i różnorodności danych oraz**

**dobrych podpisów** – poświęć czas na przygotowanie datasetu, bo to najważniejsza część procesu [<sub>78</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Prepare%20your%20dataset%20with%20images,and%20varied%29%20captions)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Prepare%20your%20dataset%20with%20images,and%20varied%29%20captions).

Zaleca się zgromadzić **wysokiej jakości, zróżnicowane obrazy** oraz stworzyć do nich **dokładne i**

**różnorodne opisy (captions)** – to klucz do dobrego LoRA [<sub>78</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Prepare%20your%20dataset%20with%20images,and%20varied%29%20captions)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Prepare%20your%20dataset%20with%20images,and%20varied%29%20captions).

*(Screenshot: Okno konﬁguracji Concept – ścieżka do obrazów, typ „Standard”, źródło podpisów z plików .txt,*

*repeats ustawione tak, by zbalansować mały zbiór wobec dużego regularization.)*

8

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAIADASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBAUGCv/EADUQAAECAgcHAgUDBQAAAAAAAAECAwAFBAYHERMXlhIhUlVXkdQx1hUiQVFzNLHCJDJCgcH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25pU+rzP65MUes8zkdSauU9qrlEotWm/hFaXa1yk0gTtKJjj0lsyh1L9BwW8G+llKyssYScT0lEsx/p20ptAtSaKEhCm2K4BTaVD1AX8PTtneL1bIv+0YLL2WXVWjuOBwJotrFc2jtkqKkJ+G3gE78JzdiIAuc2U3i5IhjYo7DbLbSG2wlpIbASgISkJ/xSkbgBf6DdAFeWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAD1IszKEAqtHtVbQpQSta647Gykg70ES5Xz33BO4Ded4jK1Iq5SF2rMvkFZaRMKDRqeX60vVteVPJ/S5WoJDTdHmAFDSlaLl7lNG/a+n1WHWkbBCUJAO5RO75bj/ANujTAdBSVrSdhgikgXkKUdnDITddduX6j7QBCicyWzqZzehzZM4o1Ans6m08XMmpZTptRqTSZmaPubblLFPpSFIwb1YrDYUFpuJuIHZTbdZubwJrOvkJQb6k15G8evrVsXj7EXg/QmPdO/p5X+Vr+Udg+v+k/sIAvzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAtctqs7W2somU4XhpLikmp1dGvkTuNxdq+2lRF4+QEqIvISbjdzmrT6DWCYSegVPbps1cpEzS9MVvyGsMobRLGwQtvFnUrlrSnllxGwNspAQq9YFwKhNv0o/Kj9lRuUT+yj/iV/GA//9k=)![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAASABMDASIAAhEBAxEB/8QAGgABAAIDAQAAAAAAAAAAAAAAAAIFBAYICv/EACgQAAIBAwIFBAMBAAAAAAAAAAECAwARIQQFEhMiMUEGI1FxMmHh8f/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD3Hb3vG6aLctdDFueoCrriqqLqAvXZQA+AbY/2q2H1DvDSoJdz1Lq2otys4BewH52N8fzFQ9QLfed1c8905vOgsjWD8RyOmzAXODcfq9qq4ozLymUagzGeJh7bL5Xi7KPPEc9vFhYUHRGmldtPCxR2JjUkm1ySPOaVPSY0sAsR7SYJJPbyTc3+zSgq9XDCZ3JijJxkopPb5IrHeCELCRDECDgiNAR1H4FKUGxqAFUAWFhgfVKUoP/Z)![ref1]

<a name="br9"></a> 

**Zakładki dodatkowe w oknie Concept:** Poza zakładką główną (General), zobaczysz też zakładkę **Image**

**Augmentation** i ewentualnie **Advanced**. Omówmy krótko augmentation, bo to integralna część

przygotowania danych:

• **Image Augmentation:** tutaj możesz ustawić automatyczne augmentacje obrazów, które

zwiększą różnorodność danych [<sub>79</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Image%20Augmentation%20Tab)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Image%20Augmentation%20Tab). Augmentacje są *szczególnie ważne przy małych datasetach*, by

model nie naduczył się konkretnych obrazków [<sub>80</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Image%20Augmentation%20Tab)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Image%20Augmentation%20Tab). Dostępne opcje:

• **Crop Jitter:** (domyślnie On) – jeśli obraz wymaga przycięcia do docelowego wymiaru, włączony

crop jitter przesuwa losowo kadr (nie zawsze centralnie), co dodaje odmianę w kadrowaniu [<sub>81</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,centered%20crop%20to%20add%20variety)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,centered%20crop%20to%20add%20variety).

• **Random Flip:** (On) – losowe odbicie lustrzane obrazu w poziomie [<sub>81</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,centered%20crop%20to%20add%20variety)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,centered%20crop%20to%20add%20variety). Typowa augmentacja

symetryczna – np. zdjęcie lewoskrętne vs prawoskrętne.

• **Random Rotation:** (Oﬀ domyślnie, wartość 0) – losowa rotacja obrazu w pewnym zakresie

stopni. Możesz ustawić np. do 10° losowej rotacji, by urozmaicić perspektywę [<sub>81</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,centered%20crop%20to%20add%20variety)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,centered%20crop%20to%20add%20variety).

• **Random Brightness / Contrast / Saturation / Hue:** (domyślnie Oﬀ, wartości 0) – te ustawienia

pozwalają losowo rozjaśniać/przyciemniać obraz, zmieniać kontrast, nasycenie kolorów i odcień

[<sub>82</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,or%20by%20a%20fixed%20value)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,or%20by%20a%20fixed%20value). Podajesz zakres (np. ±0.1) lub wartość stałą. Dzięki nim model uczy się pewnej odporności

na zmiany oświetlenia, kolorystyki itd. Dobrze jest włączyć drobne losowe zmiany jasności/

kontrastu dla lepszej ogólności. OneTrainer umożliwia też ustawienie tych zmian jako stałe (ﬁxed)

zamiast random – wtedy co epokę to samo przekształcenie. Zwykle jednak dajemy losowe.

• **Update Preview:** przycisk generujący podgląd augmentacji – pozwala zobaczyć jak wygląda

przykładowy obraz po zastosowaniu aktualnie ustawionych transformacji [<sub>83</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=which%20is%20particularly%20important%20for,or%20using%20image%20variations)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=which%20is%20particularly%20important%20for,or%20using%20image%20variations). Dla ustawień

losowych można klikać kilka razy, by zobaczyć różne warianty.

Augmentacje można stosować **losowo** (random) lub **deterministycznie** (stały oﬀset) – OneTrainer daje

wybór. Należy pamiętać, że jeśli włączamy augmentacje losowe *i* używamy latent cache, to aby każda

epoka mogła mieć inne warianty, musimy albo wyłączyć caching co epokę, albo ustawić parametry

*Image/Text Variations > 1*. To już zaawansowana kwestia – generalnie korzystaj z augmentacji z umiarem

i tylko gdy dataset jest mały lub jednorodny.

*(Więcej praktycznych porad dot. przygotowania datasetu – patrz Praktyczne porady. Możesz też skorzystać z*

*narzędzi automatycznego tagowania i maskowania w zakładce Tools zamiast ręcznie pisać opisy, o czym w*

*dalszej części.)*

**Zakładka Training (Trening)**

W zakładce **Training** ustawiamy hiperparametry treningu: m.in. liczebność batchy, ilość epok, learning

rate, wybór optymalizatora, scheduler itp. Jest to najbardziej „techniczna” zakładka, której opanowanie

wymaga zrozumienia ML. Na szczęście, **presety OneTrainer** (wybrane w menu konﬁg na górze)

zawierają zazwyczaj rozsądne domyślne wartości – początkującym poleca się ich trzymać. Tutaj

opiszemy główne parametry:

*(Uwaga: Interfejs mógł ulec zmianie i zawierać więcej sekcji; OneTrainer jest intensywnie rozwijany. Poniższy*

*opis bazuje na dokumentacji z maja 2025 – wszelkie parametry mają dymki pomocy w GUI, co ułatwia*

<i>zrozumienie [<sub>84</sub></i>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Sections)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Sections).)</i>

• **Learning Rate (LR):** podstawowy współczynnik uczenia. Często rozdzielony na LR dla UNet i LR

dla Text Encodera:

• **Base LR (UNet LR):** szybkość uczenia parametrów UNet (głównej sieci generatywnej).

• **Text Encoder LR:** szybkość uczenia parametrów enkodera tekstowego. W SDXL są dwa encodery

(CLIP ViT-L i OpenCLIP ViT-G) – OneTrainer umożliwia sterowanie dwoma LR dla TEnc1 i TEnc2

9

![ref6]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]

<a name="br10"></a> 

[<sub>85</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Train%20Text%20Encoder%20,2)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Train%20Text%20Encoder%20,2). Zwykle LR dla tekstu ustawia się niżej niż UNet (albo w ogóle zamraża encodery tekstowe na

początku, zależnie od strategii).

• Warto wspomnieć: w SDXL panuje opinia, że pierwszy encoder lepiej pracuje z tagami, drugi z

pełnymi opisami – ale to nie twarda reguła [<sub>86</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20text%20encoder%20LR%20overrides,the%20base%20LR%20if%20set)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20text%20encoder%20LR%20overrides,the%20base%20LR%20if%20set). Trenowanie tekst encodera jest trudne i często

pomijane przy LoRA, ale OneTrainer daje taką opcję.

• **Optimizer i Scheduler:** wybór optymalizatora (AdamW, Lion, AdaFactor, DAdaptation itp.) i

harmonogramu LR (cosine, linear, constant etc.). OneTrainer stale dodaje nowe optymalizatory –

jest nawet osobna strona wiki o nich [<sub>87</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Optimizer%20Info)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Optimizer%20Info). Domyślny dla LoRA bywa AdamW lub Prodigy/

dAdaptation (które automatycznie dostosowują LR). Jeśli nie wiesz, zostaw jak w presecie.

Scheduler decyduje jak LR spada w trakcie treningu.

• **Batch Size i Gradient Accumulation:** ile obrazów idzie na raz (batch) i czy gradient jest

akumulowany przez kilka batchy zanim nastąpi krok optymalizatora. Jeśli masz mocną kartę,

możesz zwiększyć batch size dla stabilniejszego treningu. Gradient Accumulation pozwala

efektywnie uzyskać duży *eﬀective batch* dzieląc go na mniejsze paczki – np. batch 2 z accum 4

daje efektywnie batch 8 (2\*4). Ustawienia te zależą od VRAM – w razie błędów OOM zmniejsz

batch.

• **Epochs / Steps:** możesz ustawić liczbę *epochs* (przejść przez cały zbiór) lub konkretną liczbę *steps*

treningowych. OneTrainer pozwala też ustawić limit czasu treningu. Presety zwykle deﬁniują np.

10 epoch przy repeats=..., co skutkuje ~ określoną liczbą kroków.

• **Save frequency (Backup):** co ile kroków/epok zapisywać kopie zapasowe modelu. OneTrainer

automatycznie wykonuje regularne backupy, zapisywane w workspace/<run>/checkpoints

z preﬁxem i timestamp [<sub>88</sub>](https://github.com/Nerogar/OneTrainer#:~:text=%2A%20Training%20methods%3A%20Full%20fine,model%20on%20multiple%20different%20prompts)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=%2A%20Training%20methods%3A%20Full%20fine,model%20on%20multiple%20different%20prompts)[89</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,training%20using%20ClipSeg%20or%20Rembg)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,training%20using%20ClipSeg%20or%20Rembg). W zakładce Training (lub Backup) możesz ustawić np. *save every*

*1000 steps* albo *every epoch*. Dzięki temu nie stracisz postępów jak coś przerwie trening. (Jest też

opcja *keep only last N backups* aby nie zapełnić dysku).

• **EMA (Exponential Moving Average):** OneTrainer obsługuje też utrzymanie średniej

wykładniczej wag podczas treningu [<sub>89</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,training%20using%20ClipSeg%20or%20Rembg)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,training%20using%20ClipSeg%20or%20Rembg). EMA potraﬁ poprawić jakość modelu generatywnego.

Włączenie EMA zwiększy jednak zużycie VRAM (OneTrainer ma opcję trzymania EMA wag na CPU

by zmniejszyć VRAM użycie). Opcja ta może być włączana w Training tab. Przy SD1.5 często nie

używana, dla SDXL potraﬁ pomóc (ale wydłuża czasy).

• **Masked training:** (szkolenie z maskami) – OneTrainer wspiera trenowanie modeli tylko na

określonych fragmentach obrazów. W Training zakładce możesz włączyć *Use Masks* i ustawić

parametry:

• **Unmasked probability** (domyślnie 0.1) – ułamek kroków treningu, w których *nie* używa się maski

(czyli cały obraz jest trenowany) [<sub>90</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20options%20available%20for%20mask,1)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20options%20available%20for%20mask,1). Np. 0.1 oznacza, że 10% kroków ignoruje maskę (dla

stabilizacji treningu).

• **Unmasked weight** (domyślnie 0.1) – jeśli maska jest wyłączona na danym kroku, możesz tu

ustawić jak bardzo te kroki wpływają (waga strat z obszaru maski) [<sub>90</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20options%20available%20for%20mask,1)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20options%20available%20for%20mask,1).

• **Normalize Masked Area Loss** – opcja normalizacji straty dla obszaru maski [<sub>91</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Normalize%20Masked%20Area%20Loss%3A%20a,of%20the%20image)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Normalize%20Masked%20Area%20Loss%3A%20a,of%20the%20image). Zaleca się

*włączać, gdy maska zajmuje duży obszar obrazu* (np. maseczka na całej twarzy), aby strata była

prawidłowo skalowana; dla małych masek nie włączaj (może zwiększyć loss niepotrzebnie) [<sub>92</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Normalize%20Masked%20Area%20Loss%3A%20a,of%20the%20image)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Normalize%20Masked%20Area%20Loss%3A%20a,of%20the%20image).

Maski to czarno-białe obrazy towarzyszące obrazom treningowym, gdzie białe obszary oznaczają region

ważny (model ma *skupić się* na nim), a czarne – mniej istotny [<sub>93</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Masked%20Training)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Masked%20Training). Pliki masek muszą mieć taką samą

nazwę co obraz + suﬃx -masklabel.png i być w formacie PNG [<sub>94</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=training%20images,nothing%20where%20the%20mask%20is)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=training%20images,nothing%20where%20the%20mask%20is). OneTrainer w zakładce Tools

potraﬁ automatycznie generować maski (o czym niżej). Maski przydają się np. gdy trenujesz LoRA na

konkretny obiekt na obrazach i chcesz, by model mniej uczył się tła [<sub>93</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Masked%20Training)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Masked%20Training). - **Validation settings:** Jeśli

włączyłeś walidację w General tab, to w Training możesz ustawić np. **Validation interval** (co ile kroków/

epok liczyć walidację, domyślnie to samo co sample interval zazwyczaj) [<sub>32</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Quick%20steps%20to%20enable%20it%3A)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Quick%20steps%20to%20enable%20it%3A). Walidacja działa tak, że w

trakcie treningu co zadany interwał model sprawdza się na obrazach walidacyjnych (Concept Type:

Validation) i liczy średni loss – obserwując wykres tego lossu w TensorBoard możesz wykryć moment,

10

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAM8DASIAAhEBAxEB/8QAGQABAQEBAQEAAAAAAAAAAAAABwAFBgMK/8QAOBAAAAQEAwcDAQQLAAAAAAAAAAECAwQFBgcTF5YRUlVXkdTWEhUhMRQiNFEjJDNBQnN1gbG0wv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmlT6uZ/WTEPU8zkdE05HtU5CQtNN+0VS7VcpOIKdpRMceJbOUOpfgcFvB2xZpWazYwk4nSQlsf1dtKbgXSaNCSQptisCU2lRfUiX7en1n8ltV6S2/kPC17LLqrjuOE4SYW7FZtH6zNRqQn23aRGfzhOfGIgi2OelO0tiSDGxDsNsttIbbJLSSbIkoJCUkn+FKS+CItv0L4AFeWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCgHpnR9QymnptVcfP4WoER7FKQ0fKURM4hnJVCqmU0cm9QKmSTmS1sKUUOZS6Gw2iaZ+8TfrUtYTW4noCisGmlXMtEhbTbiVO1wkicQSybNNNLWamtv7Na9vpcUnYa0ESD+CAZCJzJbdTObwc2TOIaAns6m08XMmpZHTaGiYmZnD/DbcpYj4pCkYO1WKw2SiWnYZ7DItlN7rbntIprOvuGaD20TXJfJfX602W0vyMtpH+4zHdO/h5X/ADWv+hsH9f7J/wAEAL87bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsZkPNWa+rWj6ikjMY3I6PdqJURHzCDipf7h7zJfsDKYODjGWI9tTL6v0xRkLDbUEa2/Wk0mpiGLL/AMVO/wCoN/6UIA//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAHEDASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAGBQMICv/EAD0QAAADBQQIAQcNAQAAAAAAAAECAwAEBQYHERMXlhIhUlVXkdTWFRQWIjFRobEyNDZBU1Rhc3SBk8LS0//EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bkjR6eY/OSDvM8Tgcky4/pS46OstJ+ETSrNcJF4CNlJEb95TGEKlXcblO5texKcTihdFvNI6Uwsd0ihUCqSQkKBDJu84AZMpg9YAfw8t4PtPohpexvBS9FFU1R1FAUArrVic0h0xEwmIXw20AEdd0pqvCAFimiW0LCgzGg7oJoppETIBEigmUCkAhSgXUBSlDUAAGoADUwFeGJuIlWM3h0DWGJuIlWM3h0DLV0lsF5NXSWwXkwEuGJuIlWM3h0DWGJuIlWM3h0DLV0lsF5NXSWwXkwEuGJuIlWM3h0DWGJuIlWM3h0DLV0lsF5NXSWwXkwEuGJuIlWM3h0DWGJuIlWM3h0DLV0lsF5NXSWwXkwEuGJuIlWM3h0DWGJuIlWM3h0DLV0lsF5NXSWwXkwEuGJuIlWM3h0DZGaYdG6aQx6m9wm+Ox6Dw57c1pucZye/HXgsquigrRgZf0fJQTivkh1rlJTRI9KAkmdRApbwfYi6S2C8mGq5eSOVIanLouxdIsoTMusZEgJmvvDDAoYxgANJRRMpCXloiIEALbA1B2vPCCfbv/u/20xxfH21vf/tpg0hIzBadROLucWLGHZwjsai0cPEkoY/RZ2eXmJi76k04Sg/vRDEubTXqCYGA5bBGwQDtFrdTcbQCKxr0REo2yTPIay6h9ct6w/ELQH6hFtyr83hf5qX9m7A+v9i/AGAvxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttszM83ytUuCx+RoMaMRLzmgz1DFSEgUZgx0CPiSiKzwdePQ+FomICZgsKmqop6IgBPkgLq2Ze/pG4/pzfE7BjfMJL7y/fzof9mmQGmD/2Q==)![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]

<a name="br11"></a> 

gdy model zaczyna przeuczać (loss walidacyjny rośnie, podczas gdy treningowy spada) [<sub>28</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Validation)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Validation)[95</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept). Wtedy

warto przerwać trening lub zastosować early stopping.

OneTrainer posiada *tooltips (dymki pomocy)* dla każdej opcji – nie bój się najechać kursorem, by zobaczyć

wyjaśnienia w UI [<sub>84</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Sections)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Sections). Jeśli dopiero zaczynasz, **nie zmieniaj zbyt wiele** – użyj ustawień z presetu. Twórcy

OneTrainer zaznaczają, że interfejs jest stale ulepszany, więc screenshoty w wiki mogą być nieaktualne –

ufaj opisom/dymkom [<sub>84</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Sections)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Sections).

*(Screenshot: Zakładka Training z ustawieniami: batch size 2, 10 epok, optimizer AdamW, LR 1e-4, mask*

*training on z parametrami.)*

**Zakładka LoRA**

Ta zakładka pojawia się **tylko jeśli w ogólnych ustawieniach wybrałeś tryb LoRA** (górny pasek,

dropdown obok logo OneTrainer: Training Mode = LoRA ) [<sub>96</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=LoRA%20Options%20Tab)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=LoRA%20Options%20Tab)[97</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=This%20tab%20is%20only%20visible,top%20right%20dropdown)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=This%20tab%20is%20only%20visible,top%20right%20dropdown). Dotyczy ona specyﬁcznych

parametrów trenowania LoRA – czyli niskowymiarowych adapterów. Omówmy dostępne opcje:

• **Type:** rodzaj algorytmu LoRA – do wyboru **LoRA (klasyczna)** lub **LoHa [<sub>98</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Image%3A%20image)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Image%3A%20image)**. *LoHa* (Low-rank

adaptation with Hadamard product) to wariant wprowadzony przez projekt LyCORIS, który

potraﬁ uchwycić więcej informacji niż klasyczna LoRA kosztem większej złożoności [<sub>99</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=LoHa)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=LoHa). Jeśli

chcesz trenować LoHa, wybierz tę opcję. (OneTrainer od kwietnia 2024 obsługuje LoHa tak samo

jak LoRA [<sub>99</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=LoHa)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=LoHa).)

• **LoRA base model:** pozwala wczytać istniejącą LoRA jako punkt startowy do dalszego trenowania

(resume) [<sub>100</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Lycoris%20project%29.%20,data%20that%20can%20be%20stored)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Lycoris%20project%29.%20,data%20that%20can%20be%20stored). Jeśli np. masz LoRA, którą chcesz podtrenować, możesz wskazać plik .safetensors

tutaj. Alternatywnie można też wznowić z *katalogu backupu treningu* (OneTrainer backup), ale

wtedy pewne rzeczy nie mogą być zmienione (np. architektura). Zwykle to pole zostawiasz puste,

chyba że wznawiasz trening LoRA.

• **LoRA rank:** domyślnie 16 (dla SD1.5), zalecane 8 lub 16 dla SDXL [<sub>101</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Next%20click%20on%20the%20,tab)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Next%20click%20on%20the%20,tab). Parametr ten określa

„rzutowanie” wag – im wyższy rank, tym więcej parametrów w LoRA i potencjalnie większa jego

pojemność, ale też łatwiej o przeuczenie i większe zużycie VRAM [<sub>102</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=warned%20that%20when%20loading%20a,Adaptive)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=warned%20that%20when%20loading%20a,Adaptive). Praktycznie:

• Dla modeli 1.5 standardowo rank 16 to dobry wybór.

• Dla SDXL niektórzy stosują rank 8, bo SDXL ma ogromne UNet i LoRA rank 16 to już bardzo dużo

parametrów (stąd podatność na przeuczenie) [<sub>101</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Next%20click%20on%20the%20,tab)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Next%20click%20on%20the%20,tab).

• Wyższe ranki (>16) zazwyczaj nie poprawiają jakości, a mogą ją pogorszyć (przeuczenie), chyba że

masz *bardzo* zróżnicowany i duży dataset.

• **LoRA alpha:** domyślnie 1.0. To hiperparametr skalujący – w implementacji LoRA końcowe wagi

są mnożone przez (alpha/rank) [<sub>103</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can). Jeśli zostawisz 1.0 przy rank 16, to efektywnie mnożnik LR

wynosi 1/16 = 0.0625 [<sub>103</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can). Często tak jest OK. Jeżeli zmieniasz alpha, pamiętaj by odpowiednio

dostosować learning rate (bo alpha wpływa na siłę uczenia) [<sub>103</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can). Ogólna zasada: **nie musisz**

**zmieniać alpha**, chyba że wiesz po co. Niektórzy zmniejszają alpha przy wysokich rankach lub

przy użyciu określonych optymalizatorów, by “osłabić” uczenie LoRA.

• **Decompose Weights:** (DoRA) – *mocno zaawansowana opcja.* Po włączeniu OneTrainer zastosuje

dekompozycję wag LoRA na **magnitudę i kierunek** (Magnitude/Direction decomposition) [<sub>104</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=optimizers%20,to%20help%20with%20overfitting%20by)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=optimizers%20,to%20help%20with%20overfitting%20by).

Jest to technika znana jako **DoRA** (Weight Decomposition for LoRA) – polega na rozbiciu uczenia

na dwa składowe tory. Badania pokazują, że DoRA potraﬁ **znacznie poprawić jakość uczenia** i

szybciej konwergować, często dorównując pełnemu ﬁne-tuningowi modeli [<sub>105</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA)[106</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA%20is%20a%20variation%20on,gap%20between%20those%20two%20behaviors)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA%20is%20a%20variation%20on,gap%20between%20those%20two%20behaviors). W praktyce,

jeśli włączysz tę opcję, **koniecznie zmniejsz dropout** (nawet do 10x mniejszego niż normalnie)

[<sub>107</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,you%20want%20to%20learn%20more)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,you%20want%20to%20learn%20more), bo DoRA silniej oddziałuje na parametry. DoRA to świetna opcja dla zaawansowanych –

warto spróbować, jeśli normalna LoRA nie daje satysfakcjonujących wyników, ale wymaga to

dopracowania innych hiperparametrów.

11

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAKgDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwABAgMFBgr/xAA2EAAABAMFCAECAwkAAAAAAAAAAQIDBAUHBhETF5YSMVJVV5HU1iEVIjRBUSQyQnN0gbGzwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmlT63M/tkxD2nmcjsTZyPas5CQtmm/pFqXbVyk4gp2lExx4ls5Q6l+BwW8G+LNKzWbGEnE9JCUx/Z20pqBVJo0JJCm2LYEptKi3kS/p6ds/kr1bJX/oOCl7LLqqjuOE4SYWrFs2j2zNRqQn6beRGfzhOfGIgiuc2U3lckgxsQ7DbLbSG2yS0kmyJKCQlJJ/hSkvgiK/cXwAK8sVdRKsavLwBZYq6iVY1eXgBawmuBPYWE1wJ7ACXLFXUSrGry8AWWKuolWNXl4AWsJrgT2FhNcCewAlyxV1Eqxq8vAFlirqJVjV5eAFrCa4E9hYTXAnsAJcsVdRKsavLwBZYq6iVY1eXgBawmuBPYWE1wJ7ACXLFXUSrGry8AWWKuolWNXl4AWsJrgT2FhNcCewAlyxV1Eqxq8vAFlirqJVjV5eAFrCa4E9hYTXAnsAJcsVdRKsavLwBZYq6iVY1eXgBawmuBPYWE1wJ7ACXLFXUSrGry8AWWKuolWNXl4AWsJrgT2FhNcCewAlyxV1Eqxq8vAHE/TTDZdcXUSquyhtalYlr7kXJSZntmUvUZJ+PuMkmZFuIwv4TXAnsMKZQZHspSlV32q2SPZP8ju+L7j/ACvAByYaLptES+MjLaTqc2amE5gZQcHPIRM7tE7O7ROw8sl6oe0CouCwJeh5cPttHL3FJSThkajWSShvWNtt2z9mULxXUNVPp2W07etSsK08A6TqVKO8lIUo9le9OyRF+6RlAMonMlp1M5vBzZM4hoCezqbTxcyalkdNoaJiZmcP8NtyliPikKRg3qxWGyUS03GdxkXcprdTc7yKazr7DNB32JtyXyW/fZsry/QyvI/yMx7p38PK/wCa1/0O4Pf/AGT/AIIAX52045rOdFW49bFnbTjms50Vbj1sJ4gBhnbTjms50Vbj1sWdtOOaznRVuPWwniAGGdtOOaznRVuPWxZ2045rOdFW49bCeIAYZ2045rOdFW49bFnbTjms50Vbj1sJ4gBhnbTjms50Vbj1sWdtOOaznRVuPWwniAGGdtOOaznRVuPWxZ2045rOdFW49bCeIAYZ2045rOdFW49bFnbTjms50Vbj1sJ4gBhnbTjms50Vbj1sWdtOOaznRVuPWwniAGGdtOOaznRVuPWxqut1OkoUpMynTiiIzJCbFW3JSzLckjVZwk3nuK8yK/eYURABKNtJZuqDsos/JjnUYUDN5TP4iKckk4k0PBqlEc3HoQ6qdQMuW6t02cNBQyXrl7zTvEGZj8Uv+mb/ANzwgH//2Q==)![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]

<a name="br12"></a> 

• **Dropout probability:** (domyślnie 0.0) – prawdopodobieństwo dropout w warstwach LoRA [<sub>108</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=techniques,loading%20the%20LoRA%20into%20memory)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=techniques,loading%20the%20LoRA%20into%20memory).

Dropout to technika regularyzacji – losowo dezaktywuje część neuronów w trakcie treningu, by

model się nie przyzwyczajał. Jeśli obserwujesz przeuczenie LoRA, rozważ wprowadzenie dropout

np. 0.1–0.3. Zwłaszcza przy DoRA, jak wyżej wspomniano, dropout 0.1–0.5 bywa zalecany [<sub>109</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=result%20in%20much%20better%20learning,What%20precision%20is%20used%20when)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=result%20in%20much%20better%20learning,What%20precision%20is%20used%20when).

Bez DoRA zazwyczaj LoRA 0.1 dropout jest bezpieczne podejście by poprawić generalizację.

• **LoRA weight data type:** typ danych dla wag LoRA w trakcie wczytywania [<sub>110</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=%2A%20Dropout%20probability%20%28default%20,you%20train%20additional%20embeddings%2C%20this)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=%2A%20Dropout%20probability%20%28default%20,you%20train%20additional%20embeddings%2C%20this). Domyślnie ﬂoat32

(pełna precyzja). Można zmniejszyć np. do ﬂoat16, żeby oszczędzić VRAM podczas **wczytywania**

LoRA. Nie wpływa to na końcowy zapis – to tylko kwestia pamięci operacyjnej. Raczej nie ruszaj,

jeśli VRAM nie jest krytyczny.

• **Bundle Embeddings:** (domyślnie ON) – opcja dołączania ewentualnie trenowanych jednocześnie

embeddingów (tekstowych) do pliku LoRA [<sub>111</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,custom)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,custom). OneTrainer pozwala trenować jednocześnie LoRA

i textual inversion (embedding) – jeśli to robisz i ta opcja jest ON, to wynikowy plik LoRA będzie

zawierał także wytrenowane embeddingi. Taki „spakowany” plik działa w Auto1111 i SD.Next bez

problemu (czytają one te dodatkowe tensorzyki), natomiast np. ComfyUI tego nie obsłuży [<sub>111</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,custom)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,custom).

Jeśli trenujesz tylko LoRA, ta opcja nic nie zmienia (ale nie szkodzi, może zostać włączona).

• **Layer Preset:** wybór, które warstwy modelu będą objęte LoRA [<sub>112</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP). Historycznie LoRA trenowała

tylko *bloki uwagi (attention layers)* modelu Stable Diﬀusion. W OneTrainer teraz możesz wybierać:

• **Attention** – tylko warstwy typu Attention (najbezpieczniej, mniejsza szansa artefaktów).

• **Attention + MLP** – warstwy Attention oraz dodatkowo warstwy pełne (feed-forward, MLP) [<sub>113</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=OneTrainer%20now%20has%20the%20ability,want%20in%20the%20text%20field)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=OneTrainer%20now%20has%20the%20ability,want%20in%20the%20text%20field).

To ustawienie domyślne w narzędziach Kohya.

• **All** – LoRA na wszystkich warstwach modelu (U-Net), co zbliża się do pełnego ﬁne-tune –

zazwyczaj nie zalecane bez powodu.

• **Custom** – możesz ręcznie wpisać listę warstw do trenowania (zaawansowane; OneTrainer

pozwala np. wpisać indeksy bloków/warstw do objęcia LoRA) [<sub>114</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=Layer%20)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=Layer%20)[112</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP).

Warstwy wybierzesz z listy presetów lub własnoręcznie – **zaleca się użyć gotowych (attention lub**

**attn+MLP)**, chyba że wiesz, które parametry chcesz edytować. Dodanie MLP warstw może pomóc LoRA

nauczyć się więcej aspektów, ale też zwiększa ryzyko, że LoRA będzie mniej przenośna między modelami

i może np. powodować nasycenie kolorów (MLP kontrolują pewne statystyki). Jednak wiele LoR

dostrojonych do stylów używa attn+MLP dla lepszego efektu. Możliwość wyboru warstw to przydatna

nowość OneTrainer, zwiększająca elastyczność treningu [<sub>114</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=Layer%20)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=Layer%20).

*(Screenshot: Zakładka LoRA – tryb LoRA, typ LoRA wybrany na LoHa, rank 8, alpha 1, dropout 0.1, DoRA*

*włączone, layers = attn+MLP.)*

**Zakładka Sampling i Backup**

OneTrainer posiada również zakładki pozwalające na generowanie podglądowych obrazów podczas

treningu (**Sampling**) oraz zarządzanie kopiami zapasowymi/wynikami (**Backup/Save**). W niektórych

wersjach GUI mogą to być osobne zakładki, w innych razem w sekcji Training/Sampling. Opisujemy je

razem, bo są związane z monitorowaniem postępów:

• **Sampling (Sample images):** Umożliwia ustawienie automatycznego generowania obrazów

próbnych w trakcie treningu. Możesz określić:

• Co ile kroków lub epok ma być wygenerowana próbka (**Sample after n steps/epochs**).

• Liczbę próbek i ewentualne parametry generowania (domyślnie wykorzystuje generowanie

wewnątrz OneTrainer – model podczas treningu produkuje obraz przy zadanym promptcie, byś

mógł ocenić czy już nauczył się koncepcji).

• Prompt(y) do próbek – często można wpisać kilka stałych promptów, które model ma generować

przy kolejnych próbkach.

• Dodatkowe opcje jak seed, czy zapisywać do osobnego folderu.

12

![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]

<a name="br13"></a> 

Generowanie próbek jest **opcjonalne, ale bardzo przydatne** – możesz **wizualnie śledzić postępy**

modelu [<sub>115</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=6)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=6). Jeśli dopiero zaczynasz, możesz nie wiedzieć jak interpretować takie próbki, ale warto to

robić – z czasem zobaczysz np. że obrazki zaczynają wyglądać sensownie, a po pewnym czasie może

zaczynają być zbyt „sztywne” (sygnał do zakończenia treningu) [<sub>115</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=6)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=6). Próbki zapisują się w workspace/

<run>/samples/… i także są widoczne w TensorBoard (jako obrazy w zakładce Images, o ile

TensorBoard jest włączony). *Pro tip:* Ustaw prompt próbek tak, by odzwierciedlał docelowe użycie

modelu (np. zawrzyj token/kontrolne słowo unikalne, jeśli trenujesz konkretny obiekt). - **Backup/Save:**

Ta część pozwala ustawić szczegóły zapisu modeli: - Preﬁx dla nazw kopii zapasowych (np. MyLora –

wtedy pliki będą MyLora\_epoch\_1.safetensors itp.). - Czy zapisywać tylko LoRA czy także pełny

model (przy LoRA zwykle tylko LoRA). - Ile kopii trzymać (przy długim treningu można trzymać np. tylko

2 ostatnie, by oszczędzić miejsce). - Ewentualnie czy automatycznie zapisać ﬁnalny model po

zakończeniu.

OneTrainer robi pełne backupy zawierające **wszystkie informacje potrzebne do wznowienia treningu**

(stan optymalizatora, itp.) [<sub>88</sub>](https://github.com/Nerogar/OneTrainer#:~:text=%2A%20Training%20methods%3A%20Full%20fine,model%20on%20multiple%20different%20prompts)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=%2A%20Training%20methods%3A%20Full%20fine,model%20on%20multiple%20different%20prompts)[116</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,and%20Sample%20Steps%20are%20Flawed)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,and%20Sample%20Steps%20are%20Flawed). Dzięki temu nawet jeśli przerwiesz proces, możesz później wybrać

*Continue from last backup* w General i ruszyć dalej bez utraty postępów [<sub>20</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=runtime%20to%20store%20your%20cached,This%20means)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=runtime%20to%20store%20your%20cached,This%20means). Kopie te są jednak spore

(zawierają model, optymizer, EMA itp.). Możesz ręcznie usuwać stare, gdy niepotrzebne.

Zarówno próbki jak i backupy są *opcjonalne* – można trenować bez nich. Ale dla realnych projektów

zaleca się korzystać z obu: backupy chronią przed stratą czasu w razie awarii, a sample pomogą ocenić

jakość modelu w trakcie.

*(Screenshot: Zakładka Sampling – ustawione co 1 epoch generuj 2 obrazki z zadanym promptem; Zakładka*

*Backup – preﬁx ustawiony, zachowaj ostatnie 3 kopie, zapisuj co 1 epoch.)*

**Zakładka Tools (Narzędzia)**

Zakładka Tools zawiera **przydatne narzędzia dodatkowe**, które upraszczają przygotowanie danych i

rozszerzają możliwości OneTrainer. W szczególności znajdują się tu:

• **Dataset Tools (Caption & Mask):** interfejs do automatycznego generowania opisów (captioning)

dla obrazów oraz masek dla masked training [<sub>117</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Dataset%20Tools)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Dataset%20Tools)[118</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=If%20you%20set%20an%20initial,or)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=If%20you%20set%20an%20initial,or). Jeśli Twój zbiór obrazów nie ma jeszcze

plików .txt z podpisami, możesz skorzystać z wbudowanych algorytmów:

• *BLIP/BLIP2* – modele generujące opisy sceny (pełne zdania) na podstawie zawartości obrazu.

• *WD14 Tagger* – klasyﬁkator tagów (przeszkolony na Danbooru), generuje listę tagów opisujących

obraz.

Narzędzie pozwala wybrać model captionujący, dodać ewentualny preﬁx/suﬃx do generowanych

podpisów (np. stałą frazę) [<sub>119</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=A%20tool%20that%20help%20to,BLIP%20and%20BLIP2%20only)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=A%20tool%20that%20help%20to,BLIP%20and%20BLIP2%20only)[118</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=If%20you%20set%20an%20initial,or)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=If%20you%20set%20an%20initial,or), a także skorzystać z istniejących wstępnych podpisów (jeśli

np. część obrazów jest już opisana). Po konﬁguracji możesz uruchomić generowanie –

OneTrainer przejdzie po obrazach i stworzy dla nich pliki .txt. *Wskazówka:* WD14 wymaga czasem

doinstalowania dodatkowego modelu; upewnij się, że masz połączenie internetowe lub pobierz

model taggera.

Co do masek: Tools oferuje *Batch Mask Generation* – możesz automatycznie wygenerować maski dla

obrazów za pomocą: - **ClipSeg** – model segmentacji z wykorzystaniem promptu tekstowego (np.

wpisujesz „a woman’s face”, a ClipSeg spróbuje zamaskować twarz kobiety na zdjęciu) [<sub>120</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Mask%20Generation)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Mask%20Generation). - **Rembg /**

**Rembg-human** – modele do usuwania tła (separowania obiektu od tła). Świetne do generowania masek

np. osób, produktów itp. - **Hex Color** – narzędzie do maskowania według zadanego koloru (np.

wszystkie zielone piksele zamaskuj).

13

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFADASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAEBQEDBgr/xAA6EAAAAwUECAMDDQAAAAAAAAABAgMABAUGBxETF5YhMVJVV5HU1hIVQRRRsSIjJDQ1QmJxcnOBwvH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25I0enmPzkg7zPE4HJMuP6UuOjrLSflE0qzXCReAjZSRG/eUxhCpV3G5TubXsSnE4oXRbz0jpTH6OmUtQKpJCQoEMmhOAGTKYNYAfy8vjHSFpvCFvubopeiiqao6igKAV1qxOaQ+MRMJiF8ttABHTdKaLwgBYp4S2hYUGY0HdBNFNIiaYFSKCYAUgEKUC/dKUNAAFuoNDAV4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNkQ6nisMiSMQJPM/xMUbQK4RqY/anUbQ1mKDmTSIgFn56R9GUrpLYLybm7JZ4QAAD3Bo1/wCMAgSMwWnUTi7nFixh2cI7GotHDxJKGP0Wdnl5iYu+hNOEoP70QxLm016gmBgOWwRsEA3Ja3U3G0Aisa+QIkG2SZ5DSGvXLYWh7hC0B9BFvdK/V4X+6l/ZtwOv+C/AGAvxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttsyF1ckaNRFKFw2IRRd7W0gRaV5qcSAH4lohBHVELfT5xkNtIf7bR/QHwKwf/2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAHQDASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAEBgIDCv/EADYQAAECAgYJAgUDBQAAAAAAAAECAwAEBQYHEReWEhMhUlVXkdTWIjEUIzRBURVzwRZCcXKx/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APufpGzddIzT82a+2i0ap8AGXoys+qlhokkFKfglD73aJNw/Jvj1YX6KUJTaFamkJQlPya2BCVEX3qUn4E+s/wBxv2wtpbQhIShIQkG8JTsHT8fmItNkklCSTtJIgCTDFXMS1jN47CLDFXMS1jN47CFrVNbiekWqa3E9IAlwxVzEtYzeOwiwxVzEtYzeOwha1TW4npFqmtxPSAJcMVcxLWM3jsIsMVcxLWM3jsIWtU1uJ6RaprcT0gCXDFXMS1jN47CLDFXMS1jN47CFrVNbiekWqa3E9IAlwxVzEtYzeOwiwxVzEtYzeOwha1TW4npFqmtxPSAJcMVcxLWM3jsI8GLO5qRpJieRX20GbTKtOmXlqbrB+oUS8+U3hukpASrX6gybitKS9L6ooAvVfC7qmtxPSMjrS9cC2oNtalaFJCinScUpspNw2G5AWm/3F9wvvIgD2Rdr29LpVOS1GPugqQibkqxPyTE6ynY1OCSNEvfBrmU/NXKh98MFWrDzgTpGjuX5SYU4VMpl0oIGxbQUq/73m72v9rtgHtFAcRSVsNQ6Im3pKkKQpZl9kAkN1UrbNIVeSPS7KUE+0brjedO72uP4z412eBKC5SVMtlaQtKf6Nrq56VX3Elury0gm4+knSH3AjuZ/6l79lv8A6qN8t9O1/oIA3xts44rTOSq8eNxY22ccVpnJVePG4T4oAwxts44rTOSq8eNxY22ccVpnJVePG4T4oAwxts44rTOSq8eNxY22ccVpnJVePG4T4oAwxts44rTOSq8eNxY22ccVpnJVePG4T4oAwxts44rTOSq8eNxY22ccVpnJVePG4T4oAwxts44rTOSq8eNxletps9dmJSXZpGmXHph0FlJqbXZpDikkNhC3XavIZavU4k3urbTohStLZCzGSe+nT+6n+IDmKFpStc43SKpmi5aX1FM0pKSwecWkvyctMqblZlAQF/KfaAW3p6LuifmISrZFHbo9j/n+BFAf/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZADgDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAFBgIDBAr/xAA2EAACAQIEAwMJCAMAAAAAAAABAgMEBQAGBxESEyEXMZYVQVJVV2GR1NYiJDI0QlGBsXFzwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bomv2eb/AJygp8z3Ox5Jy5XxZcpKXLUfkjNMua7SagXtUuPPqYzaJVnoeTHyd6sq5cwcpeZslJpj93jVdQNUoiihGjgzgGjVh3gP5PXjPUbtwjf9sdGl8MMrajySCQLS6sZziPGSxZF8m7gE9eVJ05iAbScK7jZRhjgp4I4Y4kjjCxKIwFQIqhf0qo6ADfuHTAFfZi3tE1Y8Xj5DF2Yt7RNWPF4+QwtcqL0F+GLlRegvwwBL2Yt7RNWPF4+Qx5ajTRYtw2peqcRnVkCtm8rKzDbhKSLb24NuuxKkdfdhk5UXoL8McTAhZWBdNu8RsVVvc4HRh/nu82AJjl/O9hTLdPljMtRd6GGviS9Q5tkN0uc1AynnzR31WgKvEwQJTG3kTcxmMsfLCvYVTTwxpskUQXmcbBgACx33Y9NuP39/vxYAXS82XTq53ejuy3imoL7ertfHuUVsrrtTVNTczT9I47TBX1SMnJ3bmwRhg67E7EDMrrdpudwLrevsEod8k55HUd/flsbj9iNwfMTjepfy9r/2xf8AWMwe/wDhf6GAL+23Tj1refBWePpvF226cetbz4Kzx9N4T8WAMO23Tj1refBWePpvF226cetbz4Kzx9N4T8WAJ59VrZfJrfbcjQVt/uk9wpxW0ldYMx2WGGzhZBWVgq7za7dRs8Ehp1WAVBmkEjGOJwjlbC0n4h/P9HFgP//Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAMgDASIAAhEBAxEB/8QAGgABAQACAwAAAAAAAAAAAAAABwAFBgEDCv/EADkQAAAEAwUHAgMFCQAAAAAAAAABAgMFBgcEERMXliFSVVeR1NYSMRQVQSI0UYGxFiRCZnFyc6HC/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APbc0qPTzH5yYs8zxOByTLlvalyyWWWm/lE0uzXCTtBRtKIjj2ls4Q6l+w4LeDfazSs1mxhJxNkslMf3dtKagVSaNCSQpticCU2lRe5Ev5en1ntK9XpK/wDAdFL2WXVVHccJwk2WrE5tH6zNRqQn5beRGe3Cc2YiCK5z0pvK5JBjYs7DbLbSG2yS0kmyJKCQlJJ/hSkthEV/sWwAV5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVFtzEqxs/m4j/wBfA7f6BawmtxPQRtN3HchN/wBNgAmKBTVAXJebl+YbXaIWqNOuzGqZzOIRS0We1+lSjbtCFtJJaDaMk+pF32z2/QQRnFkbLylKNomnHkraavLFJBpJRkorjJV/soiMy/MQAkRGYLTqJxexxZMYs1gjsai0cXEmoZbotZrTaYmdn2Ntwli32pCkYN6sVhslEtNxncZFmU1upud5FFY19gzQd8kzyW0vf3lsry/AyvI/oZjenfu8L/ytf9DMH7/kn9CAF+dtOOKxnRU8eNiztpxxWM6KnjxsJ4gBhnbTjisZ0VPHjYs7accVjOip48bCeIAYZ2044rGdFTx42LO2nHFYzoqePGwniAGGdtOOKxnRU8eNiztpxxWM6KnjxsJ4gBhnbTjisZ0VPHjYs7accVjOip48bCeIAYZ2044rGdFTx42LO2nHFYzoqePGwniAGGdtOOKxnRU8eNiztpxxWM6KnjxsJ4gBhnbTjisZ0VPHjYs7accVjOip48bCeIAYZ2044rGdFTx42LO2nHFYzoqePGwniAGGdtOOKxnRU8eNiztpxxWM6KnjxsJ4gBhnbTjisZ0VPHjY4OttObjuisZM7juL9ip497tnvLl3v+IUBABuz1VhketsGhkqM2yJW+129k4q1a5dmKFIYsBkv41fxEXhVgspuG4bJJSh5SjL1Gf0EFtP3xn+y0fq0IB//9k=)![ref7]![ref7]![ref1]![ref7]![ref1]![ref7]![ref7]![ref7]![ref7]![ref7]

<a name="br14"></a> 

Możesz wybrać narzędzie i uruchomić – OneTrainer wygeneruje pliki \*-masklabel.png dla każdego

obrazu. Dostępne są też funkcje manualne: malowanie własnej maski i użycie *ﬁll* (wypełnienie reszty)

[<sub>121</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=With%20ClipSeg%2C%20you%20can%20use,of%20the%20areas%20you%20specify)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=With%20ClipSeg%2C%20you%20can%20use,of%20the%20areas%20you%20specify). Po zakończeniu edycji maski *pamiętaj nacisnąć Enter, żeby zapisać zmiany [<sub>122</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=With%20the%20manual%20paint%20features%2C,trying%20to%20use%20a%20brush)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=With%20the%20manual%20paint%20features%2C,trying%20to%20use%20a%20brush)*.

**Dataset Tools** są niezwykle wygodne – dzięki nim cały pipeline (tagowanie obrazów, maskowanie)

można zrobić wewnątrz OneTrainer, bez potrzeby używania osobnych skryptów. Jest to szczególnie

przydatne dla przygotowania DreamBooth (gdzie generujemy obrazy klasy/regularyzacyjne i tagujemy

je jednym słowem) czy innych LoRA (np. stylu – tagger WD14 szybko opisze style). - **Video Tools:**

OneTrainer potraﬁ także pomóc w pozyskiwaniu danych z wideo [<sub>123</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Video%20Tools)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Video%20Tools)[124</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=chunks)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=chunks). Zakładka Tools ma sekcję do

wyciągania klatek z ﬁlmów: - Możesz wskazać plik wideo (lub folder z wieloma) i folder wyjściowy,

ustawić interwał co ile klatek/sekund wyciągnąć obraz. - Opcja “Output to Subdirectories” pozwala

tworzyć osobne podfoldery dla każdego ﬁlmu [<sub>125</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=necessary%20to%20install%20ffmpeg%20for,some%20video%20formats)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=necessary%20to%20install%20ffmpeg%20for,some%20video%20formats). - Narzędzie może też pociąć długie wideo na krótsze

klipy przed wyciąganiem klatek (zalecane ręcznie pociąć, bo one i tak lecą równolegle).

**Uwaga:** do obsługi różnych formatów wideo może być wymagany ﬀmpeg – jeśli video tools nie działa

dla jakiegoś pliku, zainstaluj ﬀmpeg w systemie [<sub>123</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Video%20Tools)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Video%20Tools).

Video tools są przydatne, gdy tworzysz dataset np. z nagrań (np. chcesz model który generuje klatki z

ﬁlmu – możesz wyciągnąć klatki i je trenować). - **Model Tools (Convert):** (może być osobna zakładka lub

w Tools) – OneTrainer ma także narzędzia do konwersji modeli między formatami [<sub>126</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,training%20without%20switching%20to%20a)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,training%20without%20switching%20to%20a). Np. możesz

załadować checkpoint .ckpt i zapisać go jako diﬀusers, albo połączyć LoRA z modelem bazowym (tzw.

merge LoRA do checkpointa). W UI jest to zwykle prosty kreator.

Ogółem zakładka Tools jest zbiorem „dodatków”, które czynią OneTrainer prawdziwie **jednym**

**narzędziem do wszystkiego** – od przygotowania danych, przez trening, po konwersje modeli.

*(Screenshot: Zakładka Tools – zaznaczone opcje BLIP2 i WD14 do tagowania datasetu oraz ClipSeg do*

*automatycznego maskowania obrazów.)*

**Przygotowanie danych do treningu**

Przygotowanie datasetu to najważniejszy etap trenowania modelu (zwłaszcza LoRA). Tutaj

podsumujemy najlepsze praktyki w kontekście OneTrainer:

**Obrazy i podpisy (.txt)**

Zbiór treningowy powinien składać się z obrazów powiązanych z tematem/obiektem, którego model ma

się nauczyć. Do każdego obrazu **rekomenduje się przygotować opis tekstowy** (tzw. *caption*) [<sub>78</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Prepare%20your%20dataset%20with%20images,and%20varied%29%20captions)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Prepare%20your%20dataset%20with%20images,and%20varied%29%20captions). Choć

OneTrainer formalnie pozwala trenować *bez podpisów* (model wtedy próbuje nauczyć się wzmocnienia

cech czysto z obrazów, co bywa nieprzewidywalne), **dobry opis do każdego obrazka zdecydowanie**

**poprawia efekt**. Kilka wskazówek:

• **Format plików:** używaj powszechnych formatów graﬁcznych (JPEG, PNG). Rozdzielczości –

najlepiej powyżej 512px w obu wymiarach (im większe, tym lepiej, ale też dłużej się trenuje i

więcej VRAM zużywa; typowo 512–1024px). OneTrainer i tak będzie skalował obrazy do

wybranych bucketów rozdzielczości, np. 512x512, 640x360, 1024x576 etc., więc nie musisz ich

ręcznie skalować – ważne by były wystarczająco duże i ostre.

• **Parowanie z .txt:** nazwy plików tekstowych powinny dokładnie odpowiadać nazwom obrazów.

Jeśli masz photo123.jpg , stwórz photo123.txt z opisem. Gdy obraz jest .png , nazwa .txt

również .png.txt lub .txt (zależy od OS, zwykle .png i .txt to różne rozszerzenia, więc

14

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAHkDASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwACAwUGCv/EADgQAAAEAwUIAgABDQEAAAAAAAECAwUABAcGERMXliExUlVXkdTWEhVRIiQ0QUJUcXOBk7HBwtP/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25Iz9bl/tkhL2nc2OxNnJ9KzkpK2aT+otSratpGYB7KRxx5lMWhUq8jgp4N82JTicUMIuJ6SUpj+bplLUCqSQkKBDJoWwAyZTBvAD/Xl+Y7QvN8Qv8AwjRS9FFU1R1FAUAsrVi2aQ/MRMJiF+tvABHbhKbMQgBcp8S3hcUIY0JdBNFNIiaYFSKCYAUgEKUC/slKGwAC/cGyAK8sTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIwVpaJ8IwVFqkkJAMAnC1YYp7zCIAocJG8QC8AKF24AAN0LuElwF7RkBClC4ofG8bx+OyAD35JxpixS7zKvz+/Sks7tiDkW0LoLivMS7u4S7WQEwBBECGTmZ5I4CIm+QEEBABHYr/ZJ/uUz/aL/AOkHNc0E1KeT94CUxn+xF5yCJT3FtqwHAPkG268oXhuELwELhhhgA0jyy06c3eTdivEtIPr07Ph3JJsnnaWmZlzGX2JptKE/NEMTBvNioJgYDluEbhAOyWt1NxvAHV6/IESDfYm3IbQ377NheH4CF4D+oRj3Sv6O1/zUv+o7A7/6F/wEAX52045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAPPryw1eYXCy1k3Rb7BKbs+7qndWC0zPLElWm0TW4rACzmzShFVVSSpkkkkRUPiHKY5SpAdQrTGom8f4f7CNsB//2Q==)![](data:image/jpeg;base64,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)![ref5]![ref2]![ref2]![ref2]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref1]

<a name="br15"></a> 

dokładnie photo.png i photo.png.txt nie będą uważane za parę – unikaj kropek w nazwie

poza rozszerzeniem).

• **Treść podpisów:** staraj się, by były **opisowe i zawierały istotne szczegóły**. Reguła: *zamieść w*

*opisie wszystko, co może się zmieniać między obrazami, a pomiń to, co jest wspólne*. Np. trenując

LoRA konkretnej postaci – w opisach zawrzyj jej ubiór, pozę, scenerię, ale **nie powtarzaj** jej

imienia w każdym (to nauczy model, że imię=ta postać, co jest ok, ale jeśli LoRA ma być

wywoływana unikalnym tokenem to lepiej dodać go raz w każdym podpisie). Unikaj też zbyt

technicznych tagów, jeśli nie są potrzebne. **Jakość ponad ilość** – lepiej mniej tagów, ale trafnych.

Według niektórych źródeł, 5-15 słów kluczowych to optimum dla jednego obrazka.

• **Konsystencja nazw:** Jeżeli trenujesz koncept (np. nową osobę czy styl), często stosuje się

*unikalny token* – np. słowo typu XYZperson w każdym podpisie, by model nauczył się kojarzyć

to słowo z celem. W DreamBooth np. każdy podpis zawiera frazę „person XYZ” obok reszty opisu.

W LoRA też można tak robić (zwłaszcza styl LoRA – często w embeddingach/LoRA stylu stosuje się

unikalny token).

• **Jakość i różnorodność obrazów:** Obrazy powinny pokazywać temat w różnych ujęciach,

oświetleniu, tle itp. Unikaj duplikatów i prawie identycznych ujęć – nie wnoszą nowej informacji a

mogą spowodować przeuczenie. Lepiej mieć 50 zróżnicowanych zdjęć niż 200 bardzo podobnych.

• **Ile obrazów?** To zależy od złożoności konceptu. LoRA potraﬁ nauczyć się prostej koncepcji (np.

stylu rysunkowego) nawet z ~20–30 obrazków. Dla osoby/postaci realistycznej lepiej mieć 50–100.

Ogólnie 100–200 to często górna granica sensowności (powyżej tego model 1.5 raczej już

zapamięta dość, a LoRA staje się cięższa). Dla SDXL można dać więcej, bo model jest większy – np.

200–500 obrazów różnych może być OK, ale to też wydłuża trening.

• **Walidacja:** Przygotuj kilka obrazów (nawet 5–10) **spoza treningu** do walidacji, z analogicznymi

podpisami. To powinny być obrazki reprezentatywne dla koncepcji, ale **nieużywane w treningu**

– wtedy walidacja pokaże na nich loss. Jeśli loss walidacyjny zaczyna rosnąć, wiesz że model

zaczyna przeuczać oryginalne dane kosztem generalizacji [<sub>28</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Validation)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Validation)[95</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept). Nie jest to obowiązkowe, ale

warto, zwłaszcza przy większych projektach.

Powyższe można streścić: *dobre dane = dobry LoRA*. OneTrainer udostępnia narzędzia, by Ci to ułatwić

(auto-caption, tagger w Tools). Skorzystaj z nich, ale zawsze **zweryﬁkuj automatycznie wygenerowane**

**opisy** – np. WD14 może dodać tagi, które nie pasują (usuń je), BLIP może opisać scenę za bardzo

ogólnie (doprecyzuj ręcznie). Zainwestowany czas przed treningiem zaoszczędzi Ci frustracji po.

**Augmentacje obrazów**

Augmentacje to sposób na sztuczne powiększenie różnorodności datasetu. OneTrainer, jak opisano w

zakładce Concepts → Image Augmentation, pozwala włączać różne losowe transformacje: odbicia,

rotacje, przycięcia, zmiany jasności, kontrastu itp. Zalecenia:

• **Używaj augmentacji, gdy masz mało danych.** Jeśli masz <50 obrazów i widzisz, że np. wszystkie

są w podobnym otoczeniu, augmentacje mogą pomóc modelowi nie przywiązywać się do

specyﬁki tła czy kolorystyki. Np. dodaj losową zmianę jasności ±10%, losowy ﬂip.

• **Nie przekombinuj.** Zbyt agresywne augmentacje (np. obrót o 90°, duże zmiany hue) mogą

utrudnić modelowi nauczenie się właściwego konceptu, bo wprowadzą sprzeczne informacje.

Chcesz raczej drobnych losowych wahań – tak by model nauczył się, że to nieistotne dla

koncepcji.

• **Crop jitter jest przydatny zawsze,** gdy Twoje obrazy nie mają identycznych wymiarów. Model

dostanie różne wykadrowania – to dobrze.

• **Wyłącz augmentation, gdy nie potrzeba.** Jeśli Twój zbiór jest spory i różnorodny, augmentacje

mogą nie być konieczne, a wydłużą trening (każdy obraz co epokę jest trochę inny – niby dobrze,

15

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAE0DASIAAhEBAxEB/8QAHAABAQACAgMAAAAAAAAAAAAABwAFBgIDBAgK/8QANRAAAQIEAwUHAwIHAAAAAAAAAQIDAAQFBgcRExIXITGWFVJVV5HU1iIyUYGxFDRBQ2Fzwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bm1V2+a/eTEvc9Todk25PtW3KSttN9j3Q7ddKMwmuAVHWmm1UZxExI6TeiFTSkqWtTOikObJKYYZS7SRiBik0UJCFNy94BTaVDmAvs9OofyvZG1+I6ML2WXVYjuOBwJlcWLzZIWSoqQOzQRx/suZjUQAQvZQSPpEMbEuw2y20htAQ0kNpCUBCUhPAJSkcAAOAA4QBXuxV5iYsdXj2EW7FXmJix1ePYQtaTXcT6RaTXcT6QBLuxV5iYsdXj2EW7FXmJix1ePYQtaTXcT6RaTXcT6QBLuxV5iYsdXj2EcV4XrUhaRiLiykqSoBQvAJKSQRmFdnq2SOeYBI5gEwuaTXcT6RaTY5IT6QAucNJlsy76cRsV1PtuFLCUXWJuTJGzsLqLC5Jj+JbCsytIWjaSCnMc48C3bvnKdWLls69KmuoVmiO0+sSM7IsqlW37auFE3LUkvtKW9sTQnbfrAdQHFADYWFHUIS8Labc2dRCV7JzTtAHI/kZ8jHq7czjYxmvRrTUFJsXDdZdHArDlVxGAb2uZDWmSlJ4J1Dl9xgNzRWaJh1UqxJ1YViVkK9WqrXVVJqmT1WlpmaqSpY5Nt0hioTSFoDBKtVlsKC05EkEDNJxuw3OYFVrX0kpOdk3yOKeB523xH+RmD/AEJjeXf5el/7Wv8AqMwef6J/YQBfvtw48VrPRV8fG4t9uHHitZ6Kvj43CfFAGG+3DjxWs9FXx8bi324ceK1noq+PjcJ8UAYb7cOPFaz0VfHxuLfbhx4rWeir4+NwnxQBhvtw48VrPRV8fG4xNMoshetdrd6ykrVmZWqSdHpMnMzrKpE1GSoztXmGpuXk5gtT8swXaw+2luoSspMbaFq0dhSVqZY7kfaP1/cwH//Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAGoDASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAFBgIDCv/EAD4QAAAEAwUFBgIFDQAAAAAAAAECAwUABAYHERMXliExUlXWEhVBV5HUFFEiJDVCYSYyMzRxcnN0gbGys8L/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25Iz9XL/WSEvU7mx0TTk+lTkpK00n3RVKtVtIzAPZSOOPMpi0KlXkcFPBvmxKcTihhFxOklLMfq6ZS2gWpJCQoEMmhWAGTKYN4Afu8vbHaF5uyF/wAo9Fl6KKprR1FAUAsraxWaQ9sRMJiF7tvABHbhKbMQgBcp2S3hcUIY0JdBNFNIiaYFSKCYAUgEKUC/dKUNgAF+4NkAV5Ym8xLWNXh7CLLE3mJaxq8PYQtYSXAX0iwkuAvpAEuWJvMS1jV4ewiyxN5iWsavD2ELWElwF9IsJLgL6QBLlibzEtY1eHsIssTeYlrGrw9hC1hJcBfSLCS4C+kAS5Ym8xLWNXh7CLLE3mJaxq8PYQtYSXAX0iwkuAvpAEuWJvMS1jV4ewjxNZgIlNfaJauAdkbxGr9gBd43SG75wuYSXAX0iwU+AofiAXCH7B8BgAxOlpummx5emasKyfpmWklAlkqsfTPDSieUL8RNqy8p8JKiVVNGXXlSHFS4MbxDYO9TlcSz7TzE+JSc8km8szW6ppFEvZTI4yKE2RMu380hVgKH4AEdrUKRO4KiLdeCbI5gAjtEwHkJgTgcfvAYdpr94774HbOJCSy8oP6qgH5GUvuSIAfYcj4XbIDUI8stnTm7ybsV4lpB9enZ8O5JNk87S0zMuYy+xNNpQn5ohiYN5sVBMDActwjcIBsltus3G8AdXr6AiQb6JrkNob99NheHyELwHwEY7pX9Xa/4qX/UbA7/AOhf7BAF+dtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edFVx03CfFAGGdtnHNXnRVcdNxZ22cc1edE1z03CfFAEhrUqNqaXnGVnnHRdxfZRwbpBCZpmqG0p1hkpkgGPMObNJy6aZhD6JlFSX3h84z6PbKgZqSpZomWCeNMtVOMjbMGTXb+wZeRbJWVVEl84A9gVEjCW8AG668AGE16+02T+YV/0qRtp/o0/3C/4hAf/2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAE0DASIAAhEBAxEB/8QAHAABAQACAgMAAAAAAAAAAAAABwAFBgIDBAgK/8QANRAAAQIEAwUHAwIHAAAAAAAAAQIDAAQFBgcRExIXITGWFVJVV5HU1iIyUYGxFDRBQ2Fzwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bm1V2+a/eTEvc9Todk25PtW3KSttN9j3Q7ddKMwmuAVHWmm1UZxExI6TeiFTSkqWtTOikObJKYYZS7SRiBik0UJCFNy94BTaVDmAvs9OofyvZG1+I6ML2WXVYjuOBwJlcWLzZIWSoqQOzQRx/suZjUQAQvZQSPpEMbEuw2y20htAQ0kNpCUBCUhPAJSkcAAOAA4QBXuxV5iYsdXj2EW7FXmJix1ePYQtaTXcT6RaTXcT6QBLuxV5iYsdXj2EW7FXmJix1ePYQtaTXcT6RaTXcT6QBLuxV5iYsdXj2EcV4XrUhaRiLiykqSoBQvAJKSQRmFdnq2SOeYBI5gEwuaTXcT6RaTY5IT6QAucNJlsy76cRsV1PtuFLCUXWJuTJGzsLqLC5Jj+JbCsytIWjaSCnMc48C3bvnKdWLls69KmuoVmiO0+sSM7IsqlW37auFE3LUkvtKW9sTQnbfrAdQHFADYWFHUIS8Labc2dRCV7JzTtAHI/kZ8jHq7czjYxmvRrTUFJsXDdZdHArDlVxGAb2uZDWmSlJ4J1Dl9xgNzRWaJh1UqxJ1YViVkK9WqrXVVJqmT1WlpmaqSpY5Nt0hioTSFoDBKtVlsKC05EkEDNJxuw3OYFVrX0kpOdk3yOKeB523xH+RmD/AEJjeXf5el/7Wv8AqMwef6J/YQBfvtw48VrPRV8fG4t9uHHitZ6Kvj43CfFAGG+3DjxWs9FXx8bi324ceK1noq+PjcJ8UAYb7cOPFaz0VfHxuLfbhx4rWeir4+NwnxQBhvtw48VrPRV8fG4xNMoshetdrd6ykrVmZWqSdHpMnMzrKpE1GSoztXmGpuXk5gtT8swXaw+2luoSspMbaFq0dhSVqZY7kfaP1/cwH//Z)![ref6]![ref1]![ref1]

<a name="br16"></a> 

ale może utrudniać konwergencję). Czasem lepiej trenować więcej epok na czystych danych niż

mniej epok z augmentacjami – zależy od przypadku.

Przykład: trenujesz LoRA stylu malarskiego i masz tylko 10 obrazów – warto włączyć ﬂips, rotacje ±5°,

drobny color jitter (±0.05 hue, ±0.1 saturacji). Dzięki temu model nie nadmiernie dopasuje się np. do

dominującego koloru oświetlenia na tych 10 obrazach.

Jeszcze uwaga: augmentacje w OneTrainer mogą być *deterministyczne* lub *losowe* co epokę. Domyślnie

są losowe (i tak jest ok). Gdy są losowe, pamiętaj o interakcji z cache (Image/Text Variations ustaw jak w

Concepts wyżej).

**Proporcje obrazu i bucketing (Aspect Ratio Buckets)**

Trening generatywny preferuje obrazy kwadratowe (512x512, 768x768, itp.), bo takie były oryginalne

dane SD1.x. Jednak świat nie jest kwadratowy – Twoje dane mogą mieć różne proporcje. **Aspect Ratio**

**Bucketing** to rozwiązanie tego problemu, które OneTrainer wdraża automatycznie (gdy włączone). Jak

to działa i co warto wiedzieć:

• Gdy AR Buckets są włączone, musisz ustawić **listę docelowych rozdzielczości** (bucket

resolutions). W presetach OneTrainer ma to ustawione rozsądnie. Np. dla SD1.5 LoRA możesz

zobaczyć listę: 512x512, 512x640, 640x512, 512x768, 768x512 itd. – pokrywającą typowe

proporcje (1:1, 4:3, 3:4, 2:3, 3:2, 16:9...).

• OneTrainer przy wczytywaniu datasetu zmierzy wymiary każdego obrazu i przypisze obraz do

najbliższego “wiaderka” (bucket) spośród zadanych, tak aby liczba pikseli mniej więcej się

zgadzała [<sub>48</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios). Następnie podczas treningu obrazy będą skalowane do wymiarów bucketu (z

zachowaniem aspektu, reszta jest docinana z włączonym jitter jeśli zaznaczyłeś).

• Dzięki temu, np. panoramy 16:9 będą trenowane na bucketach szerokich (np. 1024x576), a

portrety 3:4 na bucketach pionowych (np. 512x682) – model uczy się obu proporcji. To ogromna

przewaga nad starszym podejściem, gdzie musiałbyś albo przyciąć wszystko do kwadratu, albo

dodać czarne paski.

W praktyce: - **Dodawaj wszystkie sensowne buckety** – OneTrainer chyba generuje listę bucketów

automatycznie na podstawie datasetu (można to modyﬁkować). Upewnij się, że skrajne proporcje są

objęte, bo jak nie znajdzie bliskiego bucketu, to i tak przypisze do najbliższego (co może oznaczać

większe przycięcie niż byś chciał). - **Docelowa rozdzielczość:** Wybierz maksymalny wymiar bucketów

adekwatny do modelu i VRAM. Dla SD1.5 typowo używa się 512 lub 640 px jako podstawy. Dla SDXL –

1024 px. Model SDXL jest trenowany do generowania 1024x1024, więc LoRA na SDXL warto trenować w

rozdziałce zbliżonej (np. bucketi 1024 i mniejsze). To wymaga ~12GB VRAM na batch=1, rank=8, więc

posiadacze 8GB mogą zejść do 768px – ale to kompromis, LoRA trenowana na niższym rozmiarze może

działać trochę gorzej na wyższych. - **Przy bucketingu loss liczone jest per bucket.** Możesz w

TensorBoard zobaczyć stratę w zależności od bucketu (to dla dociekliwych). Jeśli jakiś bucket ma

wyraźnie większy loss, może to znaczyć, że model ma trudność z tą proporcją. Często jednak to po

prostu powód: mniej danych w tym formacie. - **Nie musisz nic specjalnego robić oprócz włączenia AR**

**Buckets** – OneTrainer zajmie się resztą.

Podsumowując: bucketing to przyjaciel, zostaw go włączonym chyba że masz **wszystkie** obrazy o

identycznej wielkości. Dzięki bucketom model LoRA będzie funkcjonował dobrze dla różnych

rozdzielczości generacji (np. zarówno portret 9:16, jak i pejzaż 16:9), co jest bardzo pożądane.

<i>(Dodatkowe szczegóły można znaleźć na wiki OneTrainer: stronę Aspect Ratio Bucketing [<sub>48</sub></i>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios)[</i></sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios)[49</i></sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,are%20changed%20during%20a%20restart)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,are%20changed%20during%20a%20restart)).</i>

16

![ref6]![ref1]![ref1]![ref1]

<a name="br17"></a> 

**Trenowanie modelu LoRA – przykłady**

Mając przygotowane dane i skonﬁgurowany OneTrainer, przechodzimy do właściwego treningu. Poniżej

przedstawiamy dwa scenariusze: trenowanie LoRA na bazie modelu **Stable Diﬀusion XL** (SDXL) oraz

trenowanie LoRA na bazie modelu **Flux** (specyﬁczna architektura typu DiT).

**LoRA na bazie SDXL**

Załóżmy, że chcesz stworzyć LoRA, która pozwoli generować obrazy stylizowane na określone dzieła

sztuki, albo przedstawiające konkretną osobę – a bazą ma być nowoczesny model **SDXL 1.0**. Wykonaj

następujące kroki:

1\. **Przygotuj dane i konﬁgurację:** Zgromadź dataset (obrazy + podpisy) zgodnie z poradami

powyżej. Następnie w GUI OneTrainer **wybierz preset SDXL LoRA**. W lewym górnym rogu, na

liście ‘conﬁgs’, powinien być dostępny np. szablon „SDXL LoRA” – wybierz go [<sub>18</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=1)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=1). Spowoduje to

automatyczne ustawienie wielu parametrów pod SDXL (np. odpowiednia architektura modelu,

parametry optymalizatora i buckety 1024px). Jeśli nie ma takiego presetu domyślnie, możesz

skorzystać z publicznie dostępnych – niektórzy udostępniają conﬁgi OneTrainer (np. Furkan G. na

swoim GitHub/Gumroad [<sub>127</sub>](https://www.linkedin.com/pulse/next-level-sd-15-based-models-training-took-me-70-find-g%C3%B6z%C3%BCkara-v5ubf#:~:text=Next%20Level%20SD%201,size%20click%20here%20to%20read)[</sub> ](https://www.linkedin.com/pulse/next-level-sd-15-based-models-training-took-me-70-find-g%C3%B6z%C3%BCkara-v5ubf#:~:text=Next%20Level%20SD%201,size%20click%20here%20to%20read)).

Upewnij się, że w zakładce **General** ustawiłeś *Workspace Directory* (np. workspace/

SDXL\_loRA\_01 ) – tam traﬁą wyniki. Możesz zwiększyć *dataloader threads* jeśli masz mocny CPU

(SDXL dość wolno ładuje dane, bo obrazki duże, wątkowanie pomaga).

2\. **Model bazowy SDXL:** W zakładce **Model** wskaż *Base Model* na **SDXL base**. Masz kilka opcji:

3\. Podaj link do modelu diﬀusers SDXL na HuggingFace (wymaga zalogowania lub tokenu bo to

gated). Np. stabilityai/stable-diffusion-xl-base-1.0 (SDXL Base) lub wersję *Reﬁner*

jeśli wolisz. *Uwaga:* SDXL Base to model 2.6B, potrzebuje sporo VRAM.

4\. Jeśli pobrałeś wcześniej plik SDXL (tzw. All-in-One safetensors z civitai czy huggingface) – wskaż

do niego ścieżkę pliku .safetensors [<sub>40</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Model%20Details%3A)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Model%20Details%3A). AIO oznacza, że zawiera UNet + VAE + encodery w

jednym, OneTrainer to obsłuży.

5\. Pamiętaj o **HuggingFace Token** – SDXL jest gated, więc wpisz swój token w polu HF Token w

zakładce Model [<sub>39</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,a%20custom%20VAE%2C%20provide%20a)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,a%20custom%20VAE%2C%20provide%20a), inaczej OneTrainer nie pobierze modelu (chyba że wskazujesz lokalny plik).

6\. **Zakładka LoRA:** Sprawdź ustawienia:

7\. **Rank:** SDXL LoRA zwykle rank 8 lub 16. Na start proponuję rank **8** (mniej VRAM, mniejsze ryzyko

przeuczenia, a wciąż daje zauważalny efekt) [<sub>101</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Next%20click%20on%20the%20,tab)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Next%20click%20on%20the%20,tab).

8\. **Alpha:** zostaw 1.0 (OneTrainer i tak mnoży 1/8 = 0.125 w LR).

9\. **LoRA Type:** LoRA (klasyczna). Jeśli czujesz się na siłach, możesz spróbować LoHa, ale to bym

zostawił na później.

10\. **Layers:** wybierz *Attn+MLP* (OneTrainer może mieć to domyślnie dla SDXL LoRA). To pozwoli LoRA

modyﬁkować również warstwy MLP, co bywa potrzebne przy stylach/kolorach w SDXL.

11\. **Dropout:** zacznij od 0 (brak dropout). Jeśli zobaczysz w trakcie, że LoRA mocno przeucza,

przerwiesz i ustawisz np. 0.1.

12\. **LoRA base model (resume):** puste, bo trenujemy od zera LoRA.

13\. **Reszta** – weight dtype zostaw ﬂoat32.

14\. **Ustaw hyperparametry Training:** Preset SDXL LoRA zapewne ma optymalizator AdamW i jakiś

LR rzędu 1e-4 lub adaptacyjny optymalizator.

15\. **Batch size:** jeśli masz GPU 24GB, możesz dać batch 2 lub 4 dla 1024px. Na 12GB pewnie tylko 1.

Dostosuj tak, by VRAM usage ~90%.

16\. **Epochs:** Zależy od liczby obrazów. Załóżmy masz 100 obrazów. LoRA często potrzebuje 10-20

epok by dobrze nauczyć koncept (SDXL model jest „świeży”, może wymagać mniej bo jest

potężniejszy). Ustaw np. 10 epok, po 10 epokach zobaczysz czy już efekt OK.

17\. **Save every epoch** – tak będzie bezpiecznie.

17

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFADASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAEBQEDBgr/xAA6EAAAAwUECAMDDQAAAAAAAAABAgMABAUGBxETF5YhMVJVV5HU1hIVQRRRsSIjJDQ1QmJxcnOBwvH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25I0enmPzkg7zPE4HJMuP6UuOjrLSflE0qzXCReAjZSRG/eUxhCpV3G5TubXsSnE4oXRbz0jpTH6OmUtQKpJCQoEMmhOAGTKYNYAfy8vjHSFpvCFvubopeiiqao6igKAV1qxOaQ+MRMJiF8ttABHTdKaLwgBYp4S2hYUGY0HdBNFNIiaYFSKCYAUgEKUC/dKUNAAFuoNDAV4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNkQ6nisMiSMQJPM/xMUbQK4RqY/anUbQ1mKDmTSIgFn56R9GUrpLYLybm7JZ4QAAD3Bo1/wCMAgSMwWnUTi7nFixh2cI7GotHDxJKGP0Wdnl5iYu+hNOEoP70QxLm016gmBgOWwRsEA3Ja3U3G0Aisa+QIkG2SZ5DSGvXLYWh7hC0B9BFvdK/V4X+6l/ZtwOv+C/AGAvxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttsyF1ckaNRFKFw2IRRd7W0gRaV5qcSAH4lohBHVELfT5xkNtIf7bR/QHwKwf/2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAF4DASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAEAwUGCv/EADcQAAIAAwUECQIEBwAAAAAAAAECAAMEBQYHERcSE5GWFCEiMVJVV9TWI1EVFjRBMkJxcnOxwf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7n7Rw3e0aqfVm/uItmtPABp7MvPuqYbJJBVehMP3y2Sch9znHLS/ZVFXELFNQqKv0b2BFYjPNmXoJ7Z/mOfXC2stEUKihFBzCr1Dh9vvEZUskkopJ6ySIAk0xb1ExY5vHsItMW9RMWObx7CFrdSvAvCLdSvAvCAJdMW9RMWObx7CLTFvUTFjm8ewha3UrwLwi3UrwLwgCXTFvUTFjm8ewi0xb1ExY5vHsIWt1K8C8It1K8C8IAl0xb1ExY5vHsItMW9RMWObx7CFrdSvAvCLdSvAvCAGqzDGYEUjEPFd5Ycb2U151qBMVgVQlWpZYVZc0pNY5klUKgdeY0Ult11BfJrjzayqtVJV1aW3KOvkN0erlyaOfS2NUyq+cS4q59ZVs9c04CWNpyNg/xFWqaeQ8lleUjo2yGlsoZHG2vU6kEMAQGAPcwB7xBE9FTHGymSZKWcqYVVglicBM3am99GRLTaB2ZaA7KIMgqgKOoCA8zaWMNw7Iq51FaFoWtJnyQCRLupe2qRsyR2ZtJYU+UcsjmdvLuyP2z614eBUMy0rZll1Dqv5NvrM7LZ5EmXd51BOR7JO0P3Aj3mv/AFM7/DL/ANtG+m/Tyv7BAG+tuHHmts8lX4+Nxa24cea2zyVfj43CfFAGGtuHHmts8lX4+Nxa24cea2zyVfj43CfFAGGtuHHmts8lX4+Nxa24cea2zyVfj43CfFAGGtuHHmts8lX4+Nxa24cea2zyVfj43CfFAFc7G3DfZCfittbTsqqBci/RzYENl1XbOWeWWbZKDlmY1WLIprx34lX7sqtE2y1uZOu50epoLVs+uNTNtyntRajc2hQ0uVOJMoyyCRN3pH0ymbBNTvP9P+iOsB//2Q==)![](data:image/jpeg;base64,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)![ref1]![ref7]![ref1]![ref1]![ref7]

<a name="br18"></a> 

18\. **Learning rate:** jeśli używasz adaptacyjnego optymalizatora (dAdaptation, Prodigy), nie musisz

dużo zmieniać (one się dostosują). Jeśli AdamW – ustaw np. 1e-4 start i scheduler Cosine

decaying do 1e-6.

19\. **Text Encoder training:** w SDXL raczej nie ruszaj encodera, chyba że Twój koncept to coś mocno

tekstowego (jak nowe słowo, ale to raczej embedding). Możesz w OneTrainer zostawić Train

Text Encoder = False (domyślnie LoRA preset chyba i tak nie trenuje go).

20\. **Validation:** jeżeli przygotowałeś walidacyjny concept, włącz Validation (General tab) i ustaw np.

Validate after 1 epoch, by co epokę liczył loss walidacyjny.

21\. **Sampling:** ustaw sobie kilka promptów do testu z tokenem Twojej LoRA, co 1 epoch generuj np.

2 obrazy (to zajmuje trochę czasu, ale warto).

22\. **Rozpocznij trening:** Kliknij **Start Training** (duży przycisk w UI). OneTrainer zacznie proces – w

konsoli (dolny panel) zobaczysz logi. Powinno się pojawić info o wczytywaniu modelu bazowego

(może chwilę zająć, SDXL jest duży). Następnie tworzenie cache (jeśli włączony latent caching) –

pierwszy epoch może być wolniejszy przez to. Potem iteracje treningowe.

23\. **Monitoruj:** Obserwuj *loss* w konsoli lub w TensorBoard (kliknij *TensorBoard*). Loss powinien

spadać stopniowo. Oglądaj też generowane *sample images* – to najlepszy wskaźnik. Początkowo

(epoch 1-2) będą losowe bzdury, ale z epoki na epokę powinny coraz bardziej przypominać

oczekiwany rezultat. Gdy uznasz, że wygląd jest satysfakcjonujący, **możesz przerwać trening**

**wcześniej** – nie trzeba wyciskać wszystkich epok, jeśli np. po 8 epokach model już ładnie

generuje to, co chcesz. Z drugiej strony, jeśli po zadanej liczbie epok wynik jest zbyt słaby lub

wciąż się poprawia – możesz dołożyć kolejnych epok (wystarczy zwiększyć wartość i trening

poleci dalej, lub przerwij i wznów z Continue backup).

24\. **Zakończenie:** Po zakończeniu OneTrainer zapisze ﬁnalny plik LoRA (zgodnie z *Model Output*).

Znajdziesz go w określonym miejscu (np. models/mojaLora.safetensors ). Teraz

najważniejsze – **przetestuj LoRę**! Wgraj ją do ulubionego narzędzia generatywnego (np.

Automatic1111, ComfyUI). W promptach użyj tokenów/deskryptorów, jakich uczyłeś i sprawdź czy

efekt jest zgodny z oczekiwaniami.

*(Przykład: Wytrenowaliśmy LoRę stylu malarskiego VanGogh. Ładujemy ją w Auto1111, prompt: „portrait of a*

*man, in <wynikowy styl> style”, weight 0.8 – i otrzymujemy obrazy przypominające Van Gogha.)*

OneTrainer ułatwia cały powyższy proces – wystarczy poprawnie ustawić opcje. W razie wątpliwości

zawsze zerknij do dokumentacji wiki lub do społeczności na Discordzie OneTrainer (link w repo).

**Tip:** Trenowanie LoRA na SDXL wymaga sporo VRAM. Jeśli masz tylko 8 GB, rozważ użycie *oﬄoading*

(Temp device = CPU) i ewentualnie obniżenie precision do bfloat16 lub int8 – to pozwoli zmieścić

SDXL trening, ale będzie wolniej. Alternatywnie możesz trenować SDXL LoRA w chmurze (RunPod, Colab

etc.) – OneTrainer ma nawet poradniki jak to skonﬁgurować [<sub>128</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Getting%20Started)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Getting%20Started)[129</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Sampling%20and%20Backup)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Sampling%20and%20Backup).

**LoRA na bazie modelu Flux**

Model **Flux** (dokładnie Flux.1) to dość eksperymentalna architektura od Black Forest Labs – *Flow*

*Matching Diﬀusion*. Ma duży potencjał, ale jest znacznie większy i wolniejszy od SD1.x/SDXL [<sub>130</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Flux%20is%20a%20DiT%20Transformer,slow%20model%20to%20work%20with)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Flux%20is%20a%20DiT%20Transformer,slow%20model%20to%20work%20with).

Załóżmy, że chcesz wytrenować LoRA na modelu Flux, np. żeby generować rzadki typ obrazów (Flux

potraﬁ generować emotikony, bo był trenowany m.in. na proste graﬁki). Wyzwanie: oﬁcjalnie OneTrainer

wspiera Flux, ale dokumentacja jest szczątkowa [<sub>131</sub>](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=So%20you%20got%20no%20answer,further%2C%20here%20is%20the%20answer)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=So%20you%20got%20no%20answer,further%2C%20here%20is%20the%20answer)[132</sub>](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=At%20least%20I%20got%20it,it%20first%2C%20see%20results%20etc)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=At%20least%20I%20got%20it,it%20first%2C%20see%20results%20etc). Oto kroki:

1\. **Przygotuj model Flux localnie:** Model Flux.1-dev jest udostępniony na HuggingFace (black-

forest-labs/FLUX.1-dev). Jednak aby użyć go w OneTrainer, najlepiej mieć go w formacie diﬀusers.

Sposób:

18

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZADMDASIAAhEBAxEB/8QAGgAAAgMBAQAAAAAAAAAAAAAAAAcDBQYCCv/EADoQAAECBAIECgcJAAAAAAAAAAECAwAEBREGBxITFyEUIjEyQVJVV5GWFTNRYXPU1jRCcYGCobGzwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD23NqrmOa9jNiXxPU6JgvDlQZw3JyuGkeh8UO4qpXCU10Co66abNHcTMSGpb1AVNKSta1MahId0krlgQw2kZg5pNlCQhTcvjDSaQpIAUlKzT06yx+/op0uW0QZXssuqzHccDgTLZsYzYIWSoqQPRoIBO8MuXGsQBouaKCeYDDkZlmGmm2kNoCGkhtISgISkIFglKRuSBawA3DogFVsxV3iZsebx8hBsxV3iZsebx8hDa1TXUT4QaprqJ8IBS7MVd4mbHm8fIRC9laVBJVmRm4gBWkODYuDa1b+R4mQIc/bi2FumHBqmuonwjgy7KucgLF7hKhdKfwB3CAzUnSFyMqxKCrVuZDCA3widqpdm3bXOnMOCWSFuG/GUALwRqwAAABYDkHsggEe3WqJl1U6vJ1YViWkK7WqrXVVJqmT9WlpqaqSpY2bRSJeoTKFoDBKtcy2FBY0SopIFyM7stze1VrXFUUm+CccjeDY8uGxce8XB6DG5d+z0v4rX+ouV84/l/AgFdtty47VrPkrHH03Btty47VrPkrHH03DPggFhtty47VrPkrHH03EbueWWzISXarWkhatFGjgnHTpJ96WsNrUj9YT7eSxLTiCU9dN/FH9bcBXSWKKNUJRidln5lUvMth1pTlMqjCygkgFTMxJNPNk25rjaFDpSII0EEB//9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAJgDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwACBAMFBgr/xAA2EAABAgIHBgQEBgMAAAAAAAABAAIDBQQGBxETF5ZSVVeR1NYSISIxFDRRsRUWI0FyczNCcf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7n5jZu+Y0qPSzX20WWujgA0eWVnwqMPCSQWt+CcP3u8JNw+pvXFlf4Wsa20K1Noaxrf0a2BjXEX3uc34E+s/7G/zS22GxjQ1jQxoN4a3yHL6fVRhQySSxpJ8ySEBJli7iJaxq8dArLF3ES1jV46BLWFC2G8lYULYbyQEuWLuIlrGrx0CssXcRLWNXjoEtYULYbyVhQthvJAS5Yu4iWsavHQKyxdxEtY1eOgS1hQthvJWFC2G8kBLli7iJaxq8dArLF3ES1jV46BLWFC2G8lYULYbyQEuWLuIlrGrx0CssXcRLWNXjoEtYULYbyVhQthvJAS5Yu4iWsavHQKyxdxEtY1eOgS1hQthvJWFC2G8kBLli7iJaxq8dArLF3ES1jV46BLWFC2G8lYULYbyQEuWLuIlrGrx0C1KTZm2GC11pdqcI0hpYGmtxbEc4XAFsRsueG3C/3abwUy4ULYbyWJgMLg4F7LvdrHFrX/zaPJ13ndf9SgNaHJazVfEnosrnVMrFKw11Hp8CssX8QmnqaHfGOnzXQi5sJ0PD+F/D/wBXGDzFZheF8kfBhwGhsFrIbS4ueAQwOJ8y43e5JN5J9z7qQHMythqHKKXGoUwmE2gx4IBIh1UrbSmOvJHpi0SRR4RuuN58d3tcfpr512eBrDEmU5hl7Q9rfybXWJ6XX3EmHV57QTcfST4h+4C9zT/mY39MP7uW/Rvl4X8AgN87bON6znRVeO21Z22cb1nOiq8dtpPUgMM7bON6znRVeO21Z22cb1nOiq8dtpPUgMM7bON6znRVeO21Z22cb1nOiq8dtpPUgMM7bON6znRVeO21Z22cb1nOiq8dtpPUgMM7bON6znRVeO21Z22cb1nOiq8dtpPUgMM7bON6znRVeO21Z22cb1nOiq8dtpPUgMM7bON6znRVeO21Z22cb1nOiq8dtpPUgMM7bON6znRVeO21jEtus7hiG58ynIhxS4Mifk2uh82kAgsFXjEb7+RLADd5FKK6ynf5oH/HfcIPCRLRWVggS59RqBSZ86JN4VFmUOnyybSdsCWmDSXRqYwzihS/xlkeFR4YY3xPIikhtzSRJGlvy7v7ov3CkH//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAM8DASIAAhEBAxEB/8QAGQABAQEBAQEAAAAAAAAAAAAABwAFBgMK/8QAOBAAAAQEAwcDAQQLAAAAAAAAAAECAwQFBgcTF5YRUlVXkdTWEhUhMRQiNFEjJDNBQnN1gbG0wv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmlT6uZ/WTEPU8zkdE05HtU5CQtNN+0VS7VcpOIKdpRMceJbOUOpfgcFvB2xZpWazYwk4nSQlsf1dtKbgXSaNCSQptisCU2lRfUiX7en1n8ltV6S2/kPC17LLqrjuOE4SYW7FZtH6zNRqQn23aRGfzhOfGIgi2OelO0tiSDGxDsNsttIbbJLSSbIkoJCUkn+FKS+CItv0L4AFeWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCyxVzEuxq8uwC1hNbiegsJrcT0AEuWKuYl2NXl2AssVcxLsavLsAtYTW4noLCa3E9ABLlirmJdjV5dgLLFXMS7Gry7ALWE1uJ6CwmtxPQAS5Yq5iXY1eXYCgHpnR9QymnptVcfP4WoER7FKQ0fKURM4hnJVCqmU0cm9QKmSTmS1sKUUOZS6Gw2iaZ+8TfrUtYTW4noCisGmlXMtEhbTbiVO1wkicQSybNNNLWamtv7Na9vpcUnYa0ESD+CAZCJzJbdTObwc2TOIaAns6m08XMmpZHTaGiYmZnD/DbcpYj4pCkYO1WKw2SiWnYZ7DItlN7rbntIprOvuGaD20TXJfJfX602W0vyMtpH+4zHdO/h5X/ADWv+hsH9f7J/wAEAL87bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsWdtuOKznRVceNhPEAMM7bccVnOiq48bFnbbjis50VXHjYTxADDO23HFZzoquPGxZ2244rOdFVx42E8QAwzttxxWc6KrjxsZkPNWa+rWj6ikjMY3I6PdqJURHzCDipf7h7zJfsDKYODjGWI9tTL6v0xRkLDbUEa2/Wk0mpiGLL/AMVO/wCoN/6UIA//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAEYDASIAAhEBAxEB/8QAHAABAQABBQEAAAAAAAAAAAAABwAEAQIDBQYK/8QAOhAAAQIEAwMIBgsBAAAAAAAAAQIDAAQFBgcRExchlhIxUlVXkdTWFRYiNFHCJCYzQUJxcnN0gbGy/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuaVXr5r95MS9z1Oh2Tbk+1bkpK2036Iul266SZgVtKKjrzLZpDqX5HRb0c5spWVljSTqeklMMfo7aU4gYpNFCQhTbF4BTaVDnAX6PTyzvGauSM/hHBheyy6rEdxwOBMrixebR5ZKipCfRuYBO/Sc3aiAMnOSnMZJEMbEuw2y20htsJaSGwEoCEpCfwpSNwAz5hugCvZirtExY4vHgItmKu0TFji8eAha0mugnui0mugnugCXZirtExY4vHgItmKu0TFji8eAha0mugnui0mugnugCXZirtExY4vHgI0VhieSc8Q8WCMjmPW4HMZbxkZHI582Rhb0mugnui0Wjztp7hACguGdo94ydlzMy7UJNy0F1ilzz7uhWZdqkzlLpU1LVWaIdTPvzb1RRMreShkBbJ9hXLzFGBddPk3sY7fD7Db4bwzuZLYeSlwISq6bVUUoChklIyASBkANwigMxFZouHVTq8nVk1iWkK7WqtXF1JqmT1WlpmZqZl9zbdJYn5pCkaOatVhsKC05E5EDuU43YbnMCq1r2CUHOyb5G8c/PbYzHwIzB+4mPdO+70v8Ada+aO4PP/Sf8EAX7bcOOtazwVfHluLbbhx1rWeCr48twnxQBhttw461rPBV8eW4ttuHHWtZ4Kvjy3CfFAGG23DjrWs8FXx5biONuHABJqtZyG8/Uq+PLcJ8bHPs3P0K/5MAJF83dfdDvKgy83N0H1Hr9JEy9JzVOcM29cNAmWkmVqbMnNoDjMo84krYTmB+WdDHJe7yv8ZPyxQH/2Q==)![ref2]![ref7]![ref7]![ref7]![ref7]![ref7]

<a name="br19"></a> 

2\. Zaloguj się na HuggingFace i uzyskaj **User Access Token** (w Proﬁl -> Settings -> Access Tokens).

Wklej go w OneTrainer zakładce Model (HF Token).

3\. W OneTrainer, zakładka Model: jako Base Model wpisz **HF link do Flux**: black-forest-labs/

FLUX.1-dev . Jeśli token jest poprawny i masz dostęp (Flux.1-dev raczej wymaga akceptacji

warunków?), OneTrainer powinien spróbować pobrać model. **UWAGA:** Ten model to ~19GB

danych! Lepiej pobrać go ręcznie:

Wejdź na huggingface link i pobierz *wszystkie pliki i foldery*, szczególnie foldery:

◦ 

scheduler , text\_encoder , text\_encoder\_2 , tokenizer , tokenizer\_2 ,

transformer , vae oraz plik model\_index.json [133](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=%2A%20Go%20to%20https%3A%2F%2Fhuggingface.co%2Fblack)[ ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=%2A%20Go%20to%20https%3A%2F%2Fhuggingface.co%2Fblack)[<sub>134</sub>](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=%2A%20go%20to%20the%20%22model%22,base%20model)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=%2A%20go%20to%20the%20%22model%22,base%20model). (Nie potrzebujesz pliku

flux1-dev.safetensors z głównego katalogu – on jest łączony z powyższymi i tak).

Umieść to w lokalnym folderze, np. models/FLUX.1-dev/ tak, by wewnątrz były te

podfoldery i model\_index.json [<sub>135</sub>](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,dev)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,dev).

◦ 

◦ 

W OneTrainer Base Model wskaż ten folder.

4\. Alternatywnie, BFL (autorzy Flux) udostępniali też All-in-One safetensors

(helheimFlux\_v10FP16AIO.safetensors itp.) [<sub>136</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,the%20repo%20must%20be%20in)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,the%20repo%20must%20be%20in). OneTrainer powinien je obsłużyć (przy Base

Model wskaż plik .safetensors). Upewnij się tylko, że to wersja *AIO z text encoderami*. Format NF4

AIO nie jest wspierany [<sub>137</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,work%20and%20are%20likely%20not)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,work%20and%20are%20likely%20not), Turbo wersji ﬂux też nie użyjesz (inny format), FLEX (inna arch.

pokrewna Flux) również nieobsługiwane [<sub>138</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,Flux%20Gym%2C%20AI%20Toolkit)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,Flux%20Gym%2C%20AI%20Toolkit). Zalecany jest oryginalny Flux.1 dev FP16 AIO lub

diﬀusers format.

5\. **Konﬁguracja OneTrainer dla Flux:** Wybierz preset **FluxDev + LoRA**. OneTrainer od wersji ~0.4

miał takie presety (na górnym pasku, kombinuje „FluxDev” i tryb LoRA) [<sub>139</sub>](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,https%3A%2F%2Fgithub.com%2FNerogar%2FOneTrainer)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,https%3A%2F%2Fgithub.com%2FNerogar%2FOneTrainer). Po wybraniu upewnij

się:

6\. W General → **Train device** = cuda, **Temp device** = cpu. Flux jest ogromny, więc domyślnie

OneTrainer włączy oﬄoad na CPU (inaczej raczej VRAM nie starczy). Możesz spróbować upchnąć

wszystko w VRAM, ale autorzy sugerują, że 12GB VRAM jest minimalne, 8GB to już z trudem

nawet z oﬄoadem [<sub>140</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,quite%20a%20bit%20of%20VRAM)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,quite%20a%20bit%20of%20VRAM).

7\. W Model → Base Model powinien być już wskazany (jeśli preset to zrobił). Jeśli nie, podaj jak

wyżej (folder).

8\. **HF Token** wpisany jeśli model wymaga.

9\. *Model Output* daj nazwę pliku np. flux\_lora.safetensors .

10\. Data → AR Buckets: Flux natywnie generuje 512x512 (o ile wiem), ale może wspiera wyższe?

Bezpiecznie daj bucket 512 i ewentualnie parę innych (chyba w presecie jest).

11\. Concepts → dodaj swój dataset (podobnie jak dla SDXL, podpisy itd.). Flux to inny model

tekstowy (T5 XXL encoder), ale podpisy w formie tagów czy zdań – jedno i drugie działa. Z

doświadczeń: TEnc2 (OpenCLIP G) nie istnieje w Flux; ﬂux ma T5 XXL. Więc raczej nastaw się, że

*embeddingi tekstowe oryginalnego SDXL tu nie mają analogu* – generowanie tekstu jest inne. Mimo

to, opisy tekstowe w dataset do LoRA oczywiście daj jak zwykle.

12\. LoRA tab:

**Rank:** Flux LoRA zalecany jest rank 16 (mimo że model duży). Mniejsze rank pewnie też

◦ 

zadziała, ale społeczność najczęściej rank 16 używała.

<sub>◦</sub> **Precision:** tu ważne – **Flux wymaga wysokiej precyzji.** BFL zaleca FP8 co najmniej [<sub>141</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%2C%20but%20it%20should%20be)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%2C%20but%20it%20should%20be).

OneTrainer obsługuje FP8 i NF4 – możesz w Model tab > Data Types wybrać weight dtype

= FP8 (lub NF4). NF4 (4-bit) umożliwi trenowanie na niższym VRAM, ale daje artefakty (grid

pattern) [<sub>142</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close). FP8 jest lepsze jakościowo, ale 8-bit wagi to wciąż duży model. Jeśli masz

8GB VRAM, pewnie musisz NF4 + oﬄoad sporo.

**Optimizer:** preset pewnie ustawi AdaFactor lub AdamW8bit – Adafactor jest wskazany dla

◦ 

dużych modeli (bo oszczędza pamięć).

**DoRA:** Nie wiemy, pewnie można spróbować, ale to ryzykowne – ﬂux i tak trudny. Zostaw

◦ 

oﬀ.

13\. Training tab:

**Batch size:** ﬂux jest ogromny i wolny. Batch 1 to najpewniej max, nawet na 24GB.

◦ 

19

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAIkDASIAAhEBAxEB/8QAGwABAQADAAMAAAAAAAAAAAAABwADBQYBBAr/xAA8EAAABAIGCAIIBAcAAAAAAAAAAQIDBQcEBhETF5YhMVJVV5HU1hIVFiQ0QVFxgbEUIpWhQkdTc5LC0f/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmlR6vMfrkxR6zxOB1Jq5T2quUSi1ab8orS7WuEnSCjaURG/pLZwh1L9BuW7m2lmlZrNi6TedJRJY+rtpTMCaTRoSSFNsVwJTaVFrIl+Xp8Z6StV4St+AwSvZZdVMdxwnCTRZsVzaPxmajUhPltpEZ6bpzReIIrHPCm0rEkGNijsNsttIbbJLSSbIkoJCUkn+FKS0ERW6i0ACvDFXESbGby6AWGKuIk2M3l0AWrprYTyFdNbCeQAlwxVxEmxm8ugFhiriJNjN5dAFq6a2E8hXTWwnkAJcMVcRJsZvLoBYYq4iTYzeXQBaumthPIV01sJ5ACXDFXESbGby6AWGKuIk2M3l0AWrprYTyFdNbCeQAlwxVxEmxm8ugFhiriJNjN5dAFq6a2E8hXTWwnkAJcMVcRJsZvLoBYYq4iTYzeXQBaumthPIV01sJ5ACXDFXESbGby6AWGCj/mJNj61uKz6+oBaumthPIV03sJ5EAIm5Ym1SmX1TEmu6psyMqOdbCKHuWGR2PMfgbVJMyO0vFpIzHb+Vr3nFv1Q+lHSFR2SUSjQSllqWoiNf+Wv5fAZPAn4fuf/AEAHojMFl1E4vQ4smMUagR2NRaOLiTUMp0Wo1JpMTOj6G24SxT6UhSLm1V6w2SiWmwzsMi3KZ3S3O0iisa/IZoO2pNeS0lr11bK0vgZWkfuMx3Tvs8L/ALrX+w3B6/on7EAL8bZcb1jOSq8dtixtlxvWM5Krx22E8QAwxtlxvWM5Krx22LG2XG9YzkqvHbYTxADDG2XG9YzkqvHbYsbZcb1jOSq8dthPEAMMbZcb1jOSq8dtixtlxvWM5Krx22E8QAwxtlxvWM5Krx22LG2XG9YzkqvHbYTxADDG2XG9YzkqvHbYsbZcb1jOSq8dthPEAMMbZcb1jOSq8dtixtlx7orGclV4L9/RzQE8eFaj+R/YAYNztl07SmqE3E4yqlPmSW2/Quu5NmZmRER0k6uFRka9JreSkveZERjuvSSFf1aR+nxHoxsYf7K38i+xD3QH/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFADASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAEBQIDBgr/xAA3EAAAAwUEBwYEBwAAAAAAAAABAgMABAUGBxETF5YSUlVXkdTWFBUhIjFRNEFCchYjNWFzsbT/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+5+I03PEXpd7Gfaiw0y4AAu8Mme6dg0REQEpexGD52aIjYHuNrdWF+iUhS1CqmUCkKX8mbAIUwhbaYxewj5x+obfFlsqZCFApCgQoDaBS+AcPb3aFJMRERIURHxERBgJMMTbxKsZvDkGsMTbxKsZvDkGWrpLULwauktQvBgJcMTbxKsZvDkGsMTbxKsZvDkGWrpLULwauktQvBgJcMTbxKsZvDkGsMTbxKsZvDkGWrpLULwauktQvBgJcMTbxKsZvDkG4Pz6+0/fJIhve0YjUPmGOrS6Z6mF+7xiYxGIIPMQdTKPN0kBkUEIe8kSLoBoFOAWiy7dJaheDENVEE1InSdIxbCjVCFGCwbBKYIBMgAYo/SP7h4sGziVYZDhD2s5RCIRZFdEAEQTlSbXohrREPKq6QJdIbLBtHTs9LB9sfGungFIKkSjKYnKByl/Bs6qeU1tgiKcvHKAjYPlEdIPmAN7l/8AiVv4U/7M2e7fDpfYDAb42042rGclTx021jbTjasZyVPHTbJ7TAYY2042rGclTx021jbTjasZyVPHTbJ7TAYY2042rGclTx021jbTjasZyVPHTbJ7TAYY2042rGclTx022jjUacaivsivkoA+RN3lif4XE4yZeGxGDndXPuaPIXooRt1hq6pbxdMtqKSvrb6M1tpIZ+vTF9kG/wAzwwf/2Q==)![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFwDASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAFBgMECv/EADgQAAECAwUECAQFBQAAAAAAAAECAwAEBQYHERMXEiFSlhUxUVVXkdTWFBYiNSQ0QXOxQnKBssL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25pVetzX7ZMS9p6nQ7E2cn2rOSkrZpvoi1Ltq6SZgVtKKjnzLZpDqX5HJbycZspWVljKTmdJKXY/h20pvAvSaKEhCm2LYBTaVDrAX0enbO8Yq2Rj2R4Lr2WXVXjuOBwJlb2LZtHbJUVIT0biATvynN2YgDBzZTiMEiGNiXYbZbaQ22EtJDYCUBCUhP9KUjcAMeoboAr0xV4iXsc3j0EWmKvES9jm8eghaymuBPlFlNcCfKAJdMVeIl7HN49BFpirxEvY5vHoIWsprgT5RZTXAnygCXTFXiJexzePQRaYq8RL2Obx6CFrKa4E+UWU1wJ8oAl0xV4iXsc3j0EWmKvES9jm8eghaymuBPlFlNcCfKAK5a79VMmWJ/56vJnFSrgdRL1S0vxlPWsJUE/GS4k2y6wCRtpCwSN2Ma1lJa0xp0x89zlDnawKlOCXfpkmuXYVSdpHR4caW64RMBG3nEKIJIwjunWkBO5CMCcFY7sU4EkDtViBgIyhKy76W3XJhYKm04Bf1LCBuSFKJxUoDrUd5/WAKkVmi3dVOrydWTWJaQrtaq1cXUmqZPVaWmZmpmX3Nt0lifmkKRk4qzWGwoLTgTgQNlN9125xAqta+glBxsTbkbx19dmxiOwjEH9CY7p38vS/wB1r/qNg9f+E/wIAv1tu471rPJVuPbcWtt3HetZ5Ktx7bhPigDDW27jvWs8lW49txa23cd61nkq3HtuE+KAMNbbuO9azyVbj23Frbdx3rWeSrce24T4oAw1tu471rPJVuPbcWtt3HetZ5Ktx7bhPigCt6+m7laARU6ypTag4hJsbbdsKUnEAKWuzyEAfVv2lBOOBPbGjQbS1uqSbs8qzbsxKzE5MLpjrZlmCqmEpMnmszT7D7b2wTmJW2CCR1x2lU+3Tn7C/wCI9ehfbJb+wf6pgP/Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAI4DASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwADBgEEBQr/xAA4EAAAAwUECQMCBAcAAAAAAAABAgMABAUGBxETF5YSITFSVVeR1NYUFUEigRYkNFFCYXN0sbPC/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuSNHp5j85IO8zxOByTLj+lLjo6y0n7RNKs1wkXgI2UkRv3lMYQqVdxuU7m17EpxOKF0W82R0pj+XTKWoFUkhIUCGTQnADJlMG0AP7eXTHWFptELf2bBS9FFU1R1FAUArrVic0h0xEwmIX220AEdd0pqvCAFimiW0LCgzGg7oJoppETTAqRQTACkAhSgX+EpQ1AAW7A1MBXhibmJVjN4dg1hibmJVjN4dgy1dJbhejV0luF6MBLhibmJVjN4dg1hibmJVjN4dgy1dJbhejV0luF6MBLhibmJVjN4dg1hibmJVjN4dgy1dJbhejV0luF6MBLhibmJVjN4dg1hibmJVjN4dgy1dJbhejV0luF6MBLhibmJVjN4dg1hibmJVjN4dgy1dJbhejV0luF6MBLhibmJVjN4dg1hibmJVjN4dgy1dJbhejV0luF6MBLhibmJVjN4dg3IUxNaFtQ6riFoWgabgEo/yEPQawH5D5Blm6S3C9GrpLcL0YCA1KxvDmColTylOcD+nCabEBsG3R0PRay27bR+1rX4jfpXnFKUntR8irm+y0vHHBZ6eBfXxL219hsNeirLaKWneqxApwHQLZogFg6xZh0Q2a7LBCy3VYNvx92CpmQTLWeXzk0iWUwmguiQwlIOnNkqGMYSbBNaUPq2gAiHyLBlJGYLTqJxdzixYw7OEdjUWjh4klDH6LOzy8xMXfUmnCUH96IYlzaa9QTAwHLYI2CAeyWt1NxtAIrGvoESDbJM8hrDbtlsLQ/YQtAfgRbelf08L/AKqX/TewO37F/wAAwF+NtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtY2044rGclTx42ye0wGGNtOOKxnJU8eNtraz2SbJ+gc3y8i+P8EJI8xQYXhZxfYUr608xwBfQF0i7u4PZCgV0WADHQKU9gGTE5PqZzbrj+rJ/bq/7EWD/2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAKQDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwADBgECBQr/xAA6EAAABAMFBwICBwkAAAAAAAAAAQIDBAUHBhETF5YSUlVXkdTWITEVURQWIkFzgbIjJDM0NUJyscL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25pU+tzP7ZMQ9p5nI7E2cj2rOQkLZpv4Ral21cpOIKdpRMceJbOUOpfgcFvBvizSs1mxhJxNkhKY/u7aU1Aqk0aEkhTbFsCU2lRe5Ev4enbP1K9WyV/yGCl7LLqqjuOE4SYWrFs2j2zNRqQn4beRGfrhOemIgiuc2U3lckgxsQ7DbLbSG2yS0kmyJKCQlJJ/tSkvQiK/wBi9ABXlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEp0v2krSqoVU1EpCk/trWE4lJnd9pKfoJfbL2Sf3XmMkBTd2XRDcW3b2oUycZQtKGJtaXHhCUq641t/QkkoiMiI0bREory2iCuTTZGRkhJGXqRkQloStKkrIll6ncoryvu+R/L7gBvZFNsXJfGN2nmkriJjCTaPg234WXLbbdg2FoTDLUlUSo8RRGrbMjMj9LjP3ENydTM1Gk4R5BM7CbsRO0oz9bzMzIz+Rfl7CAEyJzJadTObwc2TOIaAns6m08XMmpZHTaGiYmZnD+jbcpYj4pCkYN6sVhslEtNxncZF7Ka3U3O8ims6+wZoO+xNuS9S9/ezZXl8jK8j+4zG9O/y8r/Fa/6HsH7/AJJ/0QAvztpxxWc6Ktx42LO2nHFZzoq3HjYTxADDO2nHFZzoq3HjYs7accVnOirceNhPEAMM7accVnOirceNiztpxxWc6Ktx42E8QAwztpxxWc6Ktx42LO2nHFZzoq3HjYTxADDO2nHFZzoq3HjYs7accVnOirceNhPEAMM7accVnOirceNiztpxxWc6Ktx42E8QAwztpxxWc6Ktx42LO2nHFZzoq3HjYTxADDO2nHFZzoq3HjYs7accVnOirceNhPEAMM7accVnOirceNjhVbacmR7M0nKlXHsp+pdt07R3eidpVnUpK8/S9RkRe5mReoUB0c/huf4K/SYA/szaW0kzgH49yRLTDxUfFuy5Li0NuolqlJOES6hThbLpIv2yK8iP2MxDcrP/ANHgfwG/0kIB/9k=)![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]

<a name="br20"></a> 

**Steps/Epochs:** ﬂux uczy się powoli. Niestety brak tu szerokich doświadczeń – zacznij od

np. 1000 steps i zobacz. W logach ﬂux bywa ~1.5x wolniejszy od SDXL. Może 1000 steps

starczy, może potrzeba 3000 – zależy od danych.

**LR:** Najczęściej używano tu Adafactor z relative decay – to optymalizator bez sztywnego

LR. Jeśli używasz Adam, spróbuj bardzo mały LR (1e-5?) bo ﬂux może eksplodować zbyt

dużym LR.

◦ 

◦ 

**Mask/No mask:** raczej normalne treningi, maski działają tak samo jak w SDXL.

**Validation**: ﬂux raczej nie, bo i tak wolno trenuje – szkoda czasu. Skup się na ﬁnalnym

wyniku.

◦ 

◦ 

14\. **Sample images:** Uwaga – ﬂux generuje inne latenty? Nie, ma VAE więc powinien generować. Ale

generowanie z ﬂux w trakcie treningu może być bardzo wolne (ﬂux transformera jest heavy).

Możesz to wyłączyć by nie przedłużać. Ewentualnie wygeneruj 1 obraz co 1 epoch.

15\. **Trening:** Start Training. Bądź cierpliwy – ładowanie ﬂux to sporo (transformer ~5GB model).

Możliwe, że OneTrainer trochę dłużej będzie inicjalizował. Jeśli wybrałeś precision NF4 lub FP8, i

masz cuda+cpu oﬄoad, monitoruj RAM (może zużywać dziesiątki GB).

16\. Loss ﬂuxa może być wyższy niż w SD (inny zakres). Nie zrażaj się, ważne by spadał.

17\. OneTrainer dev-corner wspomina, że LoRA to jedyny rekomendowany sposób trenowania Flux

(pełny ﬁnetune jest niepraktyczny, bo wymaga też destylacji modelu) [<sub>143</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Current%20Information%3A)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Current%20Information%3A).

18\. Ponadto ﬂux LoRA **będzie działać tylko w ComfyUI lub w OneTrainer obecnie**, bo format LoRA

dla ﬂux jest inny niż standard SD LoRA (inne klucze tensorów). ComfyUI obsługuje LoRA ﬂuxowe

(ale np. Auto1111 pewnie nie, dopóki nie zaimplementują) [<sub>144</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,to%20produce%20a%20purple%20output)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,to%20produce%20a%20purple%20output). Więc po treningu testuj wynik w

ComfyUI z loaderem LoRA – developer wspominał, że standardowy loader LoRA w ComfyUI

obsłuży ﬂux LoRA [<sub>142</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close).

19\. **Zakończenie:** Po treningu otrzymasz plik .safetensors. Przetestuj go. Flux generuje nieco inne

style niż SD – upewnij się, że to co chciałeś wyszło. Być może okaże się, że trzeba było dać rank 32

– ﬂux ma *bardzo robust architecture*, LoRA 512 czy 768 może generować 1024 z minimalną stratą

jakości [<sub>145</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=noted%20that%20a%20grid%20pattern,quite%20a%20bit%20of%20VRAM)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=noted%20that%20a%20grid%20pattern,quite%20a%20bit%20of%20VRAM). To znaczy ﬂux LoRA jest potencjalnie dość generalna.

20\. Jeżeli masz problem, że Twój ﬂux LoRA nie działa w innym oprogramowaniu – to normalne,

dopóki tamto nie wspiera. Możesz użyć narzędzia convert (OneTrainer convert\_model.py) by

spróbować przekonwertować LoRA ﬂux na format kompatybilny, ale raczej to kwestia czasu aż

integracje powstaną.

Trening na ﬂux to **zaawansowany temat**. Zaleca się do niego podejść dopiero mając doświadczenie z

normalnymi LoRA. Niemniej, OneTrainer czyni to możliwym. Wsparcie community jest ograniczone (Flux

to nowość z 2025), więc posiłkuj się wątkiem na Reddit [<sub>131</sub>](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=So%20you%20got%20no%20answer,further%2C%20here%20is%20the%20answer)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=So%20you%20got%20no%20answer,further%2C%20here%20is%20the%20answer)[132</sub>](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=At%20least%20I%20got%20it,it%20first%2C%20see%20results%20etc)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=At%20least%20I%20got%20it,it%20first%2C%20see%20results%20etc)i wiki ﬂux [<sub>130</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Flux%20is%20a%20DiT%20Transformer,slow%20model%20to%20work%20with)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Flux%20is%20a%20DiT%20Transformer,slow%20model%20to%20work%20with)[136</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,the%20repo%20must%20be%20in)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,the%20repo%20must%20be%20in).

*(Pro-tip: do eksperymentów z ﬂux można użyć akceleratora z dużą VRAM na chwilę w chmurze – przyspieszy to*

*próby. Potem LoRę możesz używać lokalnie do generacji, bo generować ﬂuxem da się na 8GB przy 512x512*

*jednym kroku.)*

**Zastosowanie wytrenowanych modeli w innych narzędziach**

Wytrenowane za pomocą OneTrainer modele można z powodzeniem wykorzystywać w popularnych

narzędziach do generowania obrazów AI, takich jak **Automatic1111 (Stable Diﬀusion WebUI)**,

**InvokeAI**, **Fooocus**, **ComfyUI** i inne. OneTrainer zapisuje modele w standardowych formatach

( .safetensors lub .ckpt ), dzięki czemu integracja jest prosta:

• **LoRA w WebUI (Auto1111):** Po ukończeniu treningu LoRA umieść plik .safetensors w

folderze stable-diffusion-webui/models/Lora . W interfejsie WebUI możesz potem w

promptach używać swej LoRA za pomocą słowa kluczowego <lora:nazwa:wagę> . Np. jeśli

LoRA nazywa się mystyle.safetensors , użyj '<lora:mystyle:0.8>' w prompt.

20

![ref5]![ref3]![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCABQAb4DASIAAhEBAxEB/8QAHQABAQABBQEBAAAAAAAAAAAAAAcEAQIFBggDCv/EAE4QAAECAwQGBgcEBgcGBwAAAAECAwAEBgUHERIXIVJWltUTMVGXodYVIkFVk9HSFCORkhYyV2FxlTM3Z4GCttMlJkJydLMnNHZ3sbLx/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/AP38QjHLqhicCrDEZGwFKxwOB1ke3rH/AORsQ+cD0hKTmOCVoyKA9gIClA4duOvsgMuEY/Tp2k+MOnTtJ8YDIhGP06dpPjDp07SfGAyIRj9OnaT4w6dO0nxgMiEY/Tp2k+MOnTtJ8YDIhGP06dpPjDp07SfGAyIRj9OnaT4w6dO0nxgMiEY/Tp2k+MOnTtJ8YDIhGP06dpPjDp07SfGAyIRj9OnaT4w6dO0nxgMiEY/Tp2k+MOnTtJ8YDIhGP06dpPjDp07SfGAyIRj9OnaT4w6dO0nxgMiEY/Tp2k+MOnTtJ8YDIhGP06dpPjDp07SfGAyIRjh7EgApOPWerKO3XqwxwH98bgtYJBxViRgsAZAD7Ccf7uo64D7QhCAQhCAQhCAQhCAQhCAxpoEoGCnAQtPqoOGYKUEkKHtSAcSOyJtWTVXTLlPyFMT8pZDVqWjNStuTCpdS51FnNS0wsuWe+HW/s84UtpSw6UOBtZDmVeUJNQUkK6x1dR9oPaP3xsLKSCCpevD2jVhh1avbh63bie2Ak+jA/tFvX4uPL4aMD+0W9fi48vis9E1sJ/CHRNbCfwgJNowP7Rb1+Ljy+GjA/tFvX4uPL4rPRNbCfwh0TWwn8ICTaMD+0W9fi48vhowP7Rb1+Ljy+Kz0TWwn8IdE1sJ/CAk2jA/tFvX4uPL4aMD+0W9fi48vis9E1sJ/CHRNbCfwgJNowP7Rb1+Ljy+GjA/tFvX4uPL4rPRNbCfwh0TWwn8ICNTl14WEsqvHvVSXUP5Sav8AX+7aU4UpR6O+9StKSl1vMjM2VDMMY5ClJ+0rLtieo+obeNu2wizZaoZJ2zLGNllqwXHjZEqi0XlWhOGdtD7TJPF58IYC0lJCBhhFPfaTkGQqaPSNkqaORRAWklJOvFKv1VD2pJHtiTJlm1X3zawVocF1Fmo6RCsrhR+mNsKCFKwxKQokgewwG+2K/tldSTtIUZTPpm3bPkWZ2btW1ZkWXTKFPqdH2I2lKtWlNidbLZ6Vk2bkQFIIcViRGxq2L8VICjRN3aFHWtIrm2jgr2jE0cMT26ox7sFJU5eQtxSk5716ukypRUHMG/R/2ZlCgCUtN53MoxCRmOHXFilSS0cyQlzOrpQOouasxHaDq1+2AlPpa/Hcu7zji2vJ8PS1+O5d3nHFteT4r8ICQelr8dy7vOOLa8nw9LX47l3eccW15PivwgJB6Wvx3Lu844tryfD0tfjuXd5xxbXk+K/CAkHpa/Hcu7zji2vJ8PS1+O5d3nHFteT4r8ICQelr8dy7vOOLa8nw9LX47l3eccW15PivwgJB6Wvx3Lu844tryfD0tfjuXd5xxbXk+K/CAkHpa/Hcu7zji2vJ8PS1+O5d3nHFteT4r8ICQelr8dy7vOOLa8nw9LX47l3eccW15PivwgJB6Wvx3Lu844tryfD0tfjuXd5xxbXk+K/CAkHpa/Hcu7zji2vJ8PS1+O5d3nHFteT4r8ICQelr8dy7vOOLa8nw9LX47l3eccW15PivwgJB6Wvx3Lu844tryfD0tfjuXd5xxbXk+K/CAkHpa/Hcu7zji2vJ8PS1+O5d3nHFteT4r8ICQelr8dy7vOOLa8nw9LX47l3eccW15PivwgI27al968iV0Vd2pJVrBre2j7MdX+54HXhr/CONmq6vApVr7bXNF2aixVzLEqhdF21NW3OMqfebbS9MM2hZVhoRLt4lby0vLKUAkJUTgbookYHUB/xEnDAf3mOtVUEimajClpUlVhWstOOBAKJCYWhQ6/1VpCgfYoAj2QHOtTbL7fTNKzslLK23kkFt1DyUqQttQJxSQoayB+7VGSCSNYwidXaLwu5oJLq1Opcoal5t11RJWp52ybOcJUrWcVKWVa9Zxx/hRUkKSlQ6lAEfwIxgNYQhAIRpiO0dvX7O2NYBCEIBCEIDYtYRhqJKjglI6zqxOH8BrjrNR1ZIUxLtzloS0+5JqUlL81KMJeakwTgpcwOkQ4ENjFSujbcVlHqpJ1R2GYGZKRiUYnDpE9bePtGGvX+rq7ezHHCU30iejfZSrKpBQ2U5w7kIUl4hXqhaVALGOBChjAT3TjdXvdLfy+2eXQ043V73S38vtnl0Uv7zZc/In6ofebLn5E/VATTTjdXvdLfy+2eXQ043V73S38vtnl0Uv7zZc/In6ofebLn5E/VATTTjdXvdLfy+2eXQ043V73S38vtnl0Uv7zZc/In6ofebLn5E/VATTTjdXvdLfy+2eXQ043V73S38vtnl0Uv7zZc/In6ofebLn5E/VATTTjdXvdLfy+2eXQ043V73S38vtnl0UrMvsX+VP1Rris9SXD/gT9UBLnr8brfUSKrYIUsEqFnWxlRl9b1v9nYjNhgnAHX14dcfGlZlqra8nq7sfpHKd/Q6UpeXmXmnGHJyelrcnbUcfl2XEhRk+gm0NBxzo3C+26josiUrVUXmnnchQHApslaQXFMNqUB6ocLeYrSVYAgg4dYBjagLAS6wXRiCkpQkLZBCiV5UOKbwPSFQz5QpQGGGAEBNLv7Pn7OnK4ZmQwDPV/VlrhhuYDj6ZS0TZ/2BxyXUrAB37O+E5wEgpIRj62FPZLqkA+qVY4LC1gLSsdaVJTmSkjVilJIBMdZqO76nKnlZ2VnkWlIqtFUoqcn7Ati0qetV77CHxLpVatjTMnP5E/aXcyBMZHCQVhWUR04XE0WkAJtO8BOrXlvIrZJUfatZFtgrcV/xLVitWrEnAQFcwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFbwe7GviH6YYPdjXxD9MSTQVRnvW8LvKrjnkNBVGe9bwu8quOeQFYWhak4KCMPYlKswVqwwUkjAgA5sCDiQMBHVqlzKp23JZTqFmasu05Rl97opNlDr0q8wzLJOZKipbq0NpABC9eJ16+n6CaMxB9K3hYpOI/8AEuuOvq9+fvjNs+5Wi5C0WrTL9W2k6ypCkStuVrVFuWZnbIUharLtW1JuQW4hSQpK1MFSVDMCDrgOdoGzZyzqKoyzbSR9lnJKkKds6bl0/qtzUhZkgy4nVq9RTCkHqHWBqjvLSlrSStGQ5lgDHHFIUQlX+JOCv741DaQCNZxJOJOJGYknAnWOvVh1asOqNwAAAHUAAP4DVAaxtXiULwOByqwIAJBwOBwOo/wOo+2N0IDqdr29ZdisOP2raDcu0xJh55QE0t9KBMNMFYlpFp5wpzuBv7tClhZAy5cVDpjV9d2hTg3Us0lKCW8FU1VCjmbORWJXYmY+sk69YPWCQcYy7Bml2vXN48hPIl3Zenn6akrKwl2W3mJe0rDkram21voQl17pLQPTJLq1lAwbRggZYp6EAoSSTipIUdeOtQxOGOOAxOodQ6hASnTXdvvPM8M1NySGmu7feeZ4ZqbkkVjIO0+HyhkHafD5QEn013b7zzPDNTckhpru33nmeGam5JFYyDtPh8oZB2nw+UBJ9Nd2+88zwzU3JIaa7t955nhmpuSRWMg7T4fKGQdp8PlASfTXdvvPM8M1NySGmu7feeZ4ZqbkkVjIO0+HyhkHafD5QEn013b7zzPDNTckhpru33nmeGam5JFYyDtPh8oZB2nw+UBJ9Nd2+88zwzU3JIaa7t955nhmpuSRWMg7T4fKGQdp8PlASfTXdvvPM8M1NySNqr7LtkpUpVTTJSlJKgKZqbEgAk9ViY9XZr7IrWQdp8PlAtpIIxOvVqOB/Eax/Ea4Do9gVjTdRhp2xLUTNMrecbSH2rTk3isS5mSlMvaMrLLUpKSFkFOVLesEq9WO6S+PRDMSo5lHEpSgkFRI9VOoaiACOsazrJiT3ozr1O09K2/ZaZdu1f0spKSEy9LMzRTL21UVl2FaCUpmEOJSt6zJp5hLiQFtqUHWyl1IUK8kAJSBqASAB2ADVAawhCAQhCAQhCARiPTYaWWktuOvdGXEtpSUhQSUggOrAZSfW1BTiScD2RlxxFqLW0y9MdEt9uWYdfUw250brzjaMyEoWVJbSAkLzBw5VEpxxwgORbfQ6taE4koSlROBynPjhlVhlV1HHKThqxAxEfaIPYlN2NerTli1Nbk5UU3LWm07bFkMN2zadOO2bZ1rdG7L2es0xNWWxO/ZktZOlmenfRtjpFZs7QZQWzVXH9deYIC1QiK6DKC2aq4/rrzBDQZQWzVXH9deYIC1QiK6DKC2aq4/rrzBDQZQWzVXH9deYIC1QiK6DKC2aq4/rrzBDQZQWzVXH9deYIC1QiK6DKC2aq4/rrzBDQZQWzVXH9deYIC1QiK6DKC2aq4/rrzBDQZQWzVXH9deYIC1QiK6DKC2aq4/rrzBDQZQWzVXH9deYIC1QiK6DKC2aq4/rrzBDQZQWzVXH9deYIC1RoSQCQMSASAOskDqGOrX1RFtBlBbNVcf115gj6M3I0Mw60+0mqA4y4h1srryt3EhbagtBU25b6m3EhQGZC0qQsYpUkpJBCuNzSVqCQggltSyApCsqkEBbaikkZ0qOBAJGIOuMhKsyQrAjEY4HrH7j++J7TVrMqt6rqXQt5yfsCalJ16ZcSvIpuo23bTZZSspCD0LYyZQcQB7AIoSCVJBOGJGvDq/ugN0aKISkqPUkEnAEnADE4Aaz/AazGsaK/VV/A//ABAYwm0E4ZVgFtLqFKGQLQcoJ9bDIUlQBS5lXidSdRwyErCxinHDEjWMOrs7R2Eaj1gkRJ3/ALJWNu1VSj8xasvI08zZkpa8lLPqlhairelGrXaeZtFlSLRkzLIGXLLTbBGBThlxA4pm4mhG0ZCmqMApQRlvArw/d4/d4ldQklWTDMQcM2OXVhAW+ERXQZQWzVXH9deYIaDKC2aq4/rrzBAWqERXQZQWzVXH9deYIaDKC2aq4/rrzBAWqB1AnsiK6DKC2aq4/rrzBDQbQQ1lNV4DWcK/ronAazgP0gOJ/dgceyA+tITA0jXv5U5kOT9HKbXmQkrU1Skiw6hLaiHFFtQUVKCCnBJGbNgDXmXQW06lDAZRiMMQnVmwOBAOGIx9kecJ+4CnW5qbtSnnLXZtNyR+ztsT1VVgJKcmXJhhbMxPvs2smdUWLODkuktuhaVFIjrrFw9Xtt5Sqlx6y1Afp1fKrUpRUMSupicdesA5QdScE4AB61zjsPh84Zx2Hw+ceT9BdXbdMccXx+ZYaC6u26Y44vj8ywHrDOOw+HzhnHYfD5x5P0F1dt0xxxfH5lhoLq7bpjji+PzLAesM47D4fOGcdh8PnHk/QXV23THHF8fmWGgurtumOOL4/MsB6wzjsPh84Zx2Hw+ceT9BdXbdMccXx+ZYaC6u26Y44vj8ywHqt6ZbYQXHMQ2kKUtWyAMQABipSlHBKUpBUpRAAJMfBVoMJDRUHAHigNgNuKUekQFgrQhClNAA+sXQgAjDr1R5WeuOq5CFBSqaLKm3ekCazvcdVmS2pTCsr9RL1ImA2tYbAdUgKCPWIjJpBi9mkqkNAyc1Rc4hVPpqyV9IP1bPy8nKOTwsp6RRPWjNP2zMuuz6nbQP2+ZeDLazLMdG2hppIerc6NpP5h84Z0bSfzD5xKsL5/7LPgVX/rQwvn/ss+BVf+tAVXOjaT+YfONC4gAnMDgCcAQScBjgB7SfYIleF8/9lnwKr/1o0Um+dSVJxus1pI/oasHWMOsPAj+III6xrgOFvsfSqiZRCUk/77UEsnEBQbZrOxXnHA2rBxSUpSoEoQSCCSMozRb2lpcQlaSSkpBBIIxBAIOBwOBBxGIETaTsirJ4yztXOWGpUpNKUJCx5EzVnTTSpYNyrq1Wu1MTaHpWeKZpCkuIKVNJUdWMUZjHokgkkgZSSnIcU+qcE4AAYg4YADDDAYYQH2hCEAhCEAhCEAjj7R/8jaP/AEM1/wBhcchHF2ggrbdQpx9LTzamnAygOKAW2pBASELVlUFErOBIKU4EDHME9uN/qhu8/wDS9mf9gRVogFO1A7dNTllUxUdl25PyVlzFpWRYL9NWJadRTL9gWYqWasmetWXsmXm3GZydadWpw5JdpKmyAyjqHL6dKV3dvM7s6y5TAWiERfTpSu7t5ndnWXKYadKV3dvM7s6y5TAWiERfTpSu7t5ndnWXKYadKV3dvM7s6y5TAWiERfTpSu7t5ndnWXKYadKV3dvM7s6y5TAWiERfTpSu7t5ndnWXKYadKV3dvM7s6y5TAWiERfTpSu7t5ndnWXKYadKV3dvM7s6y5TAWiERfTpSu7t5ndnWXKYadKV3dvM7s6y5TAWiERfTpSu7t5ndnWXKYadKV3dvM7s6y5TAWiERfTpSu7t5ndnWXKY+jN99LvvNMIp+8hK3nENJU7dvWDTSVOKCEqcdXZQQ22CQVuLIShIKlEAEwH3pT+sy93+FB/wCXpmKy1/RI/wCURLKNs20mLbrW3bYQmVtGoraaljKyq0vttWVYaZmRp+a9UuFtdo2YUzE0lxRyvKwQlr9WKkySUHVlyqUkD9yTgD/A9cB9YQjRWoEj2A/v9nZASKkf6yr4P+oob/KqYrTX9Ej/AJRErmg1SFq1XVKJK17Sl7aYkZ22ZiRQicmJZ6ymGrJlJSTsiWl12hMq6B3pQGkOqyNEqxAJjhJG/WmDLpDlgXmOKQpbefRfWjRWlCilKilVk6yoAKK0gIXjmQAkgQFzhEX06Uru7eZ3Z1lymGnSld3bzO7OsuUwFohEX06Uru7eZ3Z1lymGnSld3bzO7OsuUwFohEX06Uru7eZ3Z1lymGnSld3bzO7OsuUwFohEX06Uru7eZ3Z1lymGnSld3bzO7OsuUwFohEX06Uru7eZ3Z1lymGnSld3bzO7OsuUwFohEX06Uru7eZ3Z1lymGnSld3bzO7OsuUwFohEX06Uru7eZ3Z1lymGnSld3bzO7OsuUwFohEX06Uru7eZ3Z1lymGnSld3bzO7OsuUwFif/o/8Sf/ALCJUn+u8f8AtYP83Rxj9+FLvI6NFgXmNnHPmN21Xtp+7+8yqdcsgttpXlKFLXgAFHWDrHN2VZVp2lXT1aBBk5R2j5CxrPamsvSuMTNoy9tvOPSwyTDD7Ycclih0J6NaBmTiCCFThCEAhCEAhCEAhCEB/9k=)![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]

<a name="br21"></a> 

Auto1111 obsługuje zarówno LoRA typowe, LoHa, jak i embedowane textual inversions (jeśli

Bundle Embeddings było włączone) – zostaną one odczytane [<sub>111</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,custom)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,custom). *Uwaga:* w przypadku LoRA

typu DoRA może być potrzebna najnowsza wersja WebUI lub skryptu dodatkowego, bo DoRA to

nowość (ale generalnie powinna działać, to tylko inna zawartość wag).

• **InvokeAI/Fooocus:** Te narzędzia również wspierają LoRA (format Diﬀusers). Możesz

zaimportować LoRA plik do ich interfejsu. InvokeAI ma możliwość wczytania LoRA i stosowania

jej podczas generacji. Fooocus – jeśli obsługuje LoRA, to zapewne także poprzez wczytanie pliku

(ew. trzeba spakować do format .pt Diﬀusers?). Sprawdź dokumentację konkretnego

narzędzia, ale z reguły .safetensors LoRA z OneTrainer będzie kompatybilny.

• **ComfyUI:** ComfyUI obsługuje LoRA poprzez nod *Load LoRA*. Plik z OneTrainer wczytasz tam i

podłączysz do modelu. Co więcej, ComfyUI już obsługuje *różne formaty LoRA OneTrainer* (w tym

LoHa i DoRA) oraz nawet LoRA do Flux [<sub>142</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close). Tak więc Comfy to świetne środowisko do testowania

zaawansowanych LoRA.

• **Wytrenowane pełne modele (ﬁne-tune):** OneTrainer potraﬁ trenować pełne checkpointy (choć

tu nie skupialiśmy się na tym). Jeśli użyjesz trybu *Full ﬁnetune* i zapiszesz model jako safetensors/

ckpt, to taki plik możesz bezpośrednio umieścić w models/Stable-diffusion w Auto1111

lub odpowiadającym folderze w InvokeAI i używać jak normalny model. Np. możesz wytrenować

*DreamBooth* model w OneTrainer (to właściwie full ﬁne-tune z prior, podobnie jak kohya) i użyć go

do generacji portretów w WebUI.

• **Kontenery (OMI)**: W przyszłości może pojawić się format OMI (One Model Integration) do

przenoszenia embeddingów z Flux do innych – na razie to ciekawostka [<sub>144</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,to%20produce%20a%20purple%20output)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,to%20produce%20a%20purple%20output).

Krótko mówiąc, **OneTrainer jest kompatybilny z ekosystemem Stable Diﬀusion**. Jego zaletą jest

uniﬁkacja formatu – trenujesz w nim, a potem korzystasz tam, gdzie wygodnie. Twórcy LoRA często

używają kohya SS; OneTrainer daje alternatywę, a wyniki (pliki) są **wymienne** między tymi narzędziami.

Możesz też porównać jakość: np. LoRA stworzona w OneTrainer vs LoRA stworzona w kohya – wczytaj

obie do WebUI i porównaj na tych samych promptach. Wielu użytkowników zauważa, że OneTrainer

potraﬁ dać równie dobre,

optymalizatorów) [<sub>146</sub>](https://lemmy.world/post/1615233#:~:text=OneTrainer%20was%20built%20from%20the,few%20different%20goals%20in%20mind)[</sub> ](https://lemmy.world/post/1615233#:~:text=OneTrainer%20was%20built%20from%20the,few%20different%20goals%20in%20mind)[147</sub>](https://lemmy.world/post/1615233#:~:text=settings%20if%20you%20know%20what,you%20are%20doing)[</sub> ](https://lemmy.world/post/1615233#:~:text=settings%20if%20you%20know%20what,you%20are%20doing).

a

czasem lepsze rezultaty (lepsza obsługa maskowania, dropout,

Na koniec: nie zapomnij się **podzielić swoim modelem** jeśli jest ciekawy! Format safetensors jest

bezpieczny – możesz go opublikować na CivitAI czy HuggingFace, opisując jak trenowałeś (tu możesz

wspomnieć, że użyłeś OneTrainer – to pokaże, że masz praktyczne doświadczenie z nowoczesnymi

narzędziami ML).

**Tryb CLI – skrypty i ich zastosowania**

OneTrainer

w

trybie konsolowym oferuje bogaty zestaw skryptów Python, które pozwalają

automatyzować i rozszerzać działania, które normalnie wykonujesz przez GUI [<sub>14</sub>](https://github.com/Nerogar/OneTrainer#:~:text=All%20functionality%20is%20split%20into,directory.%20This%20currently%20includes)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=All%20functionality%20is%20split%20into,directory.%20This%20currently%20includes). Oto najważniejsze

skrypty dostępne w folderze scripts/ oraz przykłady ich użycia:

• train.py **:** Główny skrypt treningowy. Pozwala uruchomić trening bez GUI – wszelkie

parametry podajesz jako argumenty. Jest szczególnie przydatny na serwerach (gdzie nie masz

ekranu) lub do pisania własnych procedur. Przykład użycia:

python scripts/train.py --config configs/SDXL\_LoRA.json

(zakładając, że zapisaliśmy konﬁgurację z GUI do pliku JSON) lub:

21

![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZALIDASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBQYECv/EADcQAAAEAwUHAwIDCQAAAAAAAAABAgMEBQYHERMXliFSVVeR1NYSFTEiNEFRcxQkQnSBsbK0wv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmlT6uZ/WTEPU8zkdE05HtU5CQtNN+0VS7VcpOIKdpRMceJbOUOpfgcFvBvizSs1mxhJxOkhLMf3dtKbQLUmjQkkKbYrAlNpUXyRL9vT6z2ler0lf+QwWXssuqtHccJwkwtrFZtH6zNRqQn228iM9uE5sxEEVznpTeVySDGxDsNsttIbbJLSSbIkoJCUkn+FKS2ERX/BbABXlirmJaxq8uwFlirmJaxq8uwC1hNbiegsJrcT0AEuWKuYlrGry7AWWKuYlrGry7ALWE1uJ6CwmtxPQAS5Yq5iWsavLsBZYq5iWsavLsAtYTW4noLCa3E9ABLlirmJaxq8uwFlirmJaxq8uwC1hNbiegsJrcT0AEuWKuYlrGry7AWWKuYlrGry7ALWE1uJ6CwmtxPQAS5Yq5iWsavLsBZYq5iWsavLsAtYTW4noLCa3E9ABLlirmJaxq8uwFlirmJaxq8uwC1hNbiegsJrcT0AEuWKuYlrGry7AWWKuYlrGry7ALWE1uJ6CwmtxPQAS5Yq5iWsavLsBZYq5iWsavLsAtYTW4noLCa3E9ABLlirmJaxq8uwGBdLzKlYWezeW1lWk0iYaVOYcPVk293lyVoW1Fqeh20tw6m3cCHdhzWd5EcQZ3KK8MOE1uJ6DQVFDMpkdQOoThuezzFalN/Qbhol0SlJOmW1xKSPYlV5Ed35AOJkdUTCeySTztKSh0zmVy+aph/2xJ4CZhCMxZM3m2RnhE8SLzIj+n4IQ46z2Cgl0DQ61wcMta6QppS1qZQpSlKksEalKMyvNSjMzMz2mZmZiAbhE5ktnUzm8HNkziGgJ7OptPFzJqWR02homJmZw+xtuUsR8UhSMG9WKw2SiWm4zuMi3KbbrNzvIprOvoM0HfRNcltL5+abK8vyMryP8DMd079vK/1Wv+huD+f6J/sQAvzts44rOdFVx42LO2zjis50VXHjYTxADDO2zjis50VXHjYs7bOOKznRVceNhPEAMM7bOOKznRVceNizts44rOdFVx42E8QAwzts44rOdFVx42LO2zjis50VXHjYTxADDO2zjis50VXHjYs7bOOKznRVceNhPEAMM7bOOKznRVceNizts44rOdFVx42E8QAwzts44rOdFVx42LO2zjis50VXHjYTxADDO2zjis50VXHjYs7bOOKznRVceNhPEAMM7bOOKznRVceNizts44rOdFVx42E8QAwzts44rOdFVx42PNEWqUbUjUbT0ki5rGTSbS6YwsIy9TNTyxo3Fy+J9Pri5tJ4GDTeZEkiVEEd6i/AjMlgc/OvuZT/ADTv+q+AN6Ik83l1F0jL4uXPNRUDS8gg4lo3YZRtxENKoRl5s1JfUlRocQpN6VGk7ryMyuMQSof7dj9Fr/BIgH//2Q==)![ref8]![ref8]![ref7]![ref7]![ref7]![ref7]![ref7]![ref1]

<a name="br22"></a> 

python scripts/train.py --base\_model "stabilityai/stable-diffusion-2-1"

--train\_data\_dir "data/images" --output\_dir "models/output" --lora\_rank

8 [inne opcje...]

Parametrów jest dużo – aby je poznać, uruchom python scripts/train.py -h [<sub>148</sub>](https://github.com/Nerogar/OneTrainer#:~:text=in%20your%20dataset)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=in%20your%20dataset). Warto

podkreślić, że **GUI OneTrainer jest nakładką** na ten skrypt – konﬁgurując w UI i klikając Start,

tak naprawdę uruchamiany jest train.py z odpowiednimi argumentami. Dlatego przejście na

CLI jest naturalne, gdy np. chcesz wykorzystać klaster HPC do treningu.

• train\_ui.py **:** Alternatywny skrypt uruchamiający mini-UI w przeglądarce do monitorowania

treningu w trybie CLI. Można odpalić OneTrainer na serwerze bez X11, a w przeglądarce na PC

otworzyć port i mieć podgląd.

• create\_train\_files.py **:** Pomocnik do generowania plików konﬁguracyjnych i struktur

folderów gdy chcesz trenować z CLI bez interakcji. Może utworzyć szablony .json z konﬁguracją

trenowania, które potem edytujesz.

• generate\_captions.py **:** Skrypt do automatycznego tagowania obrazów (captioning) [<sub>149</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,create%20masks%20for%20your%20dataset)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,create%20masks%20for%20your%20dataset). To

odpowiednik funkcji w Tools GUI, ale z poziomu konsoli. Obsługuje BLIP, BLIP2, WD14 –

parametry pozwalają wybrać model, ścieżkę do obrazów, preﬁxy itd. Przykład:

python scripts/generate\_captions.py --image\_dir "data/mydataset" --

caption\_model "blip2" --device cuda

Spowoduje wygenerowanie plików .txt dla obrazów w katalogu, używając BLIP2 (który zostanie

pobrany przy pierwszym użyciu). Możesz też skorzystać z WD14 tagger:

python scripts/generate\_captions.py --image\_dir "data/mydataset" --

caption\_model "wd14-convnextv2" --append\_tags --tag\_threshold 0.35

To wygeneruje tagi Danbooru dla obrazków, dołączając je (append) do istniejących podpisów, z

progiem pewności 0.35. Skrypt jest bardzo elastyczny – użyteczny gdy masz wiele folderów do

otagowania. (Zwróć uwagę na ewentualną konieczność pobrania modelu WD14 – log powie co

robić).

• generate\_masks.py **:** Podobnie jak wyżej, ale do automatycznego tworzenia masek [<sub>150</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,create%20masks%20for%20your%20dataset)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,create%20masks%20for%20your%20dataset).

Pozwala wybrać metodę (clipseg, rembg) i przetworzyć cały folder obrazów generując maski. Np.:

python scripts/generate\_masks.py --image\_dir "data/mydataset" --method

"rembg"

lub z użyciem ClipSeg z promptem:

python scripts/generate\_masks.py --image\_dir "data/mydataset" --method

"clipseg" --prompt "object in center"

Skrypt ten oszczędza czas, gdy chcesz przygotować maski do masked training hurtowo.

• sample.py **:** Narzędzie do generowania obrazów (inference) z dowolnego modelu, bez

potrzeby użycia osobnego UI [<sub>151</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,automatically%20create%20captions%20for%20your)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,automatically%20create%20captions%20for%20your). Możesz np. wygenerować serię obrazów z modelem (będącym

wynikiem treningu) w ramach ewaluacji. Przykład:

22

![](data:image/jpeg;base64,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)![ref9]![ref9]![ref9]![ref9]![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAMgDASIAAhEBAxEB/8QAGgABAQACAwAAAAAAAAAAAAAABwAFBgEDCv/EADkQAAAEAwUHAgMFCQAAAAAAAAABAgMFBgcEERMXliFSVVeR1NYSMRQVQSI0UYGxFiRCZnFyc6HC/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APbc0qPTzH5yYs8zxOByTLlvalyyWWWm/lE0uzXCTtBRtKIjj2ls4Q6l+w4LeDfazSs1mxhJxNkslMf3dtKagVSaNCSQpticCU2lRe5Ev5en1ntK9XpK/wDAdFL2WXVVHccJwk2WrE5tH6zNRqQn5beRGe3Cc2YiCK5z0pvK5JBjYs7DbLbSG2yS0kmyJKCQlJJ/hSkthEV/sWwAV5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVFtzEqxs/m4j/wBfA7f6BawmtxPQRtN3HchN/wBNgAmKBTVAXJebl+YbXaIWqNOuzGqZzOIRS0We1+lSjbtCFtJJaDaMk+pF32z2/QQRnFkbLylKNomnHkraavLFJBpJRkorjJV/soiMy/MQAkRGYLTqJxexxZMYs1gjsai0cXEmoZbotZrTaYmdn2Ntwli32pCkYN6sVhslEtNxncZFmU1upud5FFY19gzQd8kzyW0vf3lsry/AyvI/oZjenfu8L/ytf9DMH7/kn9CAF+dtOOKxnRU8eNiztpxxWM6KnjxsJ4gBhnbTjisZ0VPHjYs7accVjOip48bCeIAYZ2044rGdFTx42LO2nHFYzoqePGwniAGGdtOOKxnRU8eNiztpxxWM6KnjxsJ4gBhnbTjisZ0VPHjYs7accVjOip48bCeIAYZ2044rGdFTx42LO2nHFYzoqePGwniAGGdtOOKxnRU8eNiztpxxWM6KnjxsJ4gBhnbTjisZ0VPHjYs7accVjOip48bCeIAYZ2044rGdFTx42LO2nHFYzoqePGwniAGGdtOOKxnRU8eNiztpxxWM6KnjxsJ4gBhnbTjisZ0VPHjY4OttObjuisZM7juL9ip497tnvLl3v+IUBABuz1VhketsGhkqM2yJW+129k4q1a5dmKFIYsBkv41fxEXhVgspuG4bJJSh5SjL1Gf0EFtP3xn+y0fq0IB//9k=)![ref8]![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFwDASIAAhEBAxEB/8QAGgABAQEBAAMAAAAAAAAAAAAABwAFBgMECv/EADgQAAECAwUECAQFBQAAAAAAAAECAwAEBQYHERMXEiFSlhUxUVVXkdTWFBYiNSQ0QXOxQnKBssL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25pVetzX7ZMS9p6nQ7E2cn2rOSkrZpvoi1Ltq6SZgVtKKjnzLZpDqX5HJbycZspWVljKTmdJKXY/h20pvAvSaKEhCm2LYBTaVDrAX0enbO8Yq2Rj2R4Lr2WXVXjuOBwJlb2LZtHbJUVIT0biATvynN2YgDBzZTiMEiGNiXYbZbaQ22EtJDYCUBCUhP9KUjcAMeoboAr0xV4iXsc3j0EWmKvES9jm8eghaymuBPlFlNcCfKAJdMVeIl7HN49BFpirxEvY5vHoIWsprgT5RZTXAnygCXTFXiJexzePQRaYq8RL2Obx6CFrKa4E+UWU1wJ8oAl0xV4iXsc3j0EWmKvES9jm8eghaymuBPlFlNcCfKAK5a79VMmWJ/56vJnFSrgdRL1S0vxlPWsJUE/GS4k2y6wCRtpCwSN2Ma1lJa0xp0x89zlDnawKlOCXfpkmuXYVSdpHR4caW64RMBG3nEKIJIwjunWkBO5CMCcFY7sU4EkDtViBgIyhKy76W3XJhYKm04Bf1LCBuSFKJxUoDrUd5/WAKkVmi3dVOrydWTWJaQrtaq1cXUmqZPVaWmZmpmX3Nt0lifmkKRk4qzWGwoLTgTgQNlN9125xAqta+glBxsTbkbx19dmxiOwjEH9CY7p38vS/wB1r/qNg9f+E/wIAv1tu471rPJVuPbcWtt3HetZ5Ktx7bhPigDDW27jvWs8lW49txa23cd61nkq3HtuE+KAMNbbuO9azyVbj23Frbdx3rWeSrce24T4oAw1tu471rPJVuPbcWtt3HetZ5Ktx7bhPigCt6+m7laARU6ypTag4hJsbbdsKUnEAKWuzyEAfVv2lBOOBPbGjQbS1uqSbs8qzbsxKzE5MLpjrZlmCqmEpMnmszT7D7b2wTmJW2CCR1x2lU+3Tn7C/wCI9ehfbJb+wf6pgP/Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAKQDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwADBgECBQr/xAA6EAAABAMFBwICBwkAAAAAAAAAAQIDBAUHBhETF5YSUlVXkdTWITEVURQWIkFzgbIjJDM0NUJyscL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25pU+tzP7ZMQ9p5nI7E2cj2rOQkLZpv4Ral21cpOIKdpRMceJbOUOpfgcFvBvizSs1mxhJxNkhKY/u7aU1Aqk0aEkhTbFsCU2lRe5Ev4enbP1K9WyV/yGCl7LLqqjuOE4SYWrFs2j2zNRqQn4beRGfrhOemIgiuc2U3lckgxsQ7DbLbSG2yS0kmyJKCQlJJ/tSkvQiK/wBi9ABXlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEuWKuYlWNXl2AssVcxKsavLsAtYTW4noLCa3E9ABLlirmJVjV5dgLLFXMSrGry7ALWE1uJ6CwmtxPQAS5Yq5iVY1eXYCyxVzEqxq8uwC1hNbiegsJrcT0AEp0v2krSqoVU1EpCk/trWE4lJnd9pKfoJfbL2Sf3XmMkBTd2XRDcW3b2oUycZQtKGJtaXHhCUq641t/QkkoiMiI0bREory2iCuTTZGRkhJGXqRkQloStKkrIll6ncoryvu+R/L7gBvZFNsXJfGN2nmkriJjCTaPg234WXLbbdg2FoTDLUlUSo8RRGrbMjMj9LjP3ENydTM1Gk4R5BM7CbsRO0oz9bzMzIz+Rfl7CAEyJzJadTObwc2TOIaAns6m08XMmpZHTaGiYmZnD+jbcpYj4pCkYN6sVhslEtNxncZF7Ka3U3O8ims6+wZoO+xNuS9S9/ezZXl8jK8j+4zG9O/y8r/Fa/6HsH7/AJJ/0QAvztpxxWc6Ktx42LO2nHFZzoq3HjYTxADDO2nHFZzoq3HjYs7accVnOirceNhPEAMM7accVnOirceNiztpxxWc6Ktx42E8QAwztpxxWc6Ktx42LO2nHFZzoq3HjYTxADDO2nHFZzoq3HjYs7accVnOirceNhPEAMM7accVnOirceNiztpxxWc6Ktx42E8QAwztpxxWc6Ktx42LO2nHFZzoq3HjYTxADDO2nHFZzoq3HjYs7accVnOirceNhPEAMM7accVnOirceNjhVbacmR7M0nKlXHsp+pdt07R3eidpVnUpK8/S9RkRe5mReoUB0c/huf4K/SYA/szaW0kzgH49yRLTDxUfFuy5Li0NuolqlJOES6hThbLpIv2yK8iP2MxDcrP/ANHgfwG/0kIB/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAJ0DASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwAEBQYDCv/EADgQAAECAwUIAQEFCAMAAAAAAAIBAwAEBQYHExeWERJSVVeR1NYhMRU0QVFzFBYiJDNCYYGxssL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25oq9bmv2yYl7T1Oh2Js5PtWclJWzTf2Ral21dJWYStiFRx5ltaQ6L8jgt4O2bUTU1YwhxOklLsf5dsRvAvSaUBQCbYtghNiSfVEP7PHfX5TaW6m38o8Lr2WXSvHccRxBlb2LZtLvqpKQD9m7URV+cJz4xARNjm6O1NgpDGxLsNsttA22gtCjaIIIAig/2iKfCIm36J8QBXliXUS9jV6eBFliXUS9jV6eBC1hNcA9osJrgHtAEuWJdRL2NXp4EWWJdRL2NXp4ELWE1wD2iwmuAe0AS5Yl1EvY1engRZYl1EvY1engQtYTXAPaLCa4B7QBLliXUS9jV6eBFliXUS9jV6eBC1hNcA9osJrgHtAEuWJdRL2NXp4EWWJdRL2NXp4ELWE1wD2iwmuAe0AS5Yl1EvY1engRZYl1EvY1engQtYTXAPaLCa4B7QBLliXUS9jV6eBFliXUS9jV6eBC1hNcA9osJrgHtAEuWJdRL2NXp4EWWJdRL2NXp4ELWE1wD2iwmuAe0ARZbuMTEk4F4N6bhtzTTohM2nGaknMBccmp1hZRrFl3hbJogQ0VVNPwRYyLM12uVeq2tok3NM49l6uzK/tbTqywzcvVJUKtKIrSoSocpLTLUo4W+qGbRGiChbET3ZZgyaImgUgIlbPdTfbIhUFJstm0C3SJN4di7FghsfJSsxeDfAkyw1Mq1W7KNgUwAumg/udS1VN40Vflfkl/FflYDFCs0W7qp1eTqw1iWkK7WqtXDqTVMnqtLTMzU1l/htuksT80BBg7SxWG0JDHYq7FRNyN91267USq1r+BVBdtibcp8p9frZtNqfkqbUX8FWO6d+70v9Vr/1G4X6/wCh/wCEgC/O27jmtZ0Vbj1uLO27jmtZ0Vbj1uE+KAMM7buOa1nRVuPW4s7buOa1nRVuPW4T4oAwztu45rWdFW49biztu45rWdFW49bhPigDDO27jmtZ0Vbj1uLO27jmtZ0Vbj1uE+KAMM7buOa1nRVuPW4s7buOa1nRVuPW4T4oAwztu45rWdFW49biztu45rWdFW49bhPigDDO27jmtZ0Vbj1uLO27jmtZ0Vbj1uE+KAMM7buOa1nRVuPW4s7buOa1nRVuPW4T4oAsO+27nebEapWCMzEAFbGW1b3jJU2JvuWdBsf8qZiifnG2spRnJavW1tQMy0/IWznaHUqe2LU01My7NPoMnS3Am2plhlQcN6XJxtA3kwiHeUS2inSVr7uz+uEbxj+gz+k3/wBBgP/Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAIcDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAFBgECAwr/xAA6EAAAAwUECAMDDQAAAAAAAAABAgMABAUGBxETF5YSIVJVV5HU1hQxQRUiUSQmMjRCRXN0gYaxwtH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25I0enmPzkg7zPE4HJMuP6UuOjrLSfsiaVZrhIvARspIjfvKYwhUq7jcp3Nr2JTicULot5sjpTH5OmUtQKpJCQoEMmhOAGTKYPMAP7PLpjrC02iFvwbwpeiiqao6igKAV1qxOaQ6YiYTEL7NtABHXdKarwgBYpoltCwoMxoO6CaKaRE0wKkUEwApAIUoF+yUoagALfINTAV4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQN1NS8xymLiNVkmkUS6RZwApi2gIaRTeAHRELbQGzUIWsuXSWwXk3BkUhKYBIWwSiHkHqDASwtZ9k+My9LMSmR9jrjGEIk5QJJZxKvHPHw1J4i7+8RONGfCeJAXAwFKAORLTFAtvq03vNySZaiUlECFtM9TkUBEAHQ0ZWeBEydv0DmD3DmDWZMAIOppgwpIzBadROLucWLGHZwjsai0cPEkoY/RZ2eXmJi76k04Sg/vRDEubTXqCYGA5bBGwQDMlrdTcbQCKxr3BEg2yTPIaw8/OWwtD4CFoD6CLb0r9Xhf4qX9mzA+f6F/gGAvxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5Knjttoa2U5EBAIrGbR1B8yp49f22ye0wDyMXdp/m2TY9L6b0eDyk8TAd+fX50eoaC54rBFIcgi7u0QRdn0DkVUKdQVXYhNC3RMYwWNNuML+9Pzn+NMH/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAE0DASIAAhEBAxEB/8QAHAABAQACAgMAAAAAAAAAAAAABwAFBgIDBAgK/8QANRAAAQIEAwUHAwIHAAAAAAAAAQIDAAQFBgcRExIXITGWFVJVV5HU1iIyUYGxFDRBQ2Fzwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bm1V2+a/eTEvc9Todk25PtW3KSttN9j3Q7ddKMwmuAVHWmm1UZxExI6TeiFTSkqWtTOikObJKYYZS7SRiBik0UJCFNy94BTaVDmAvs9OofyvZG1+I6ML2WXVYjuOBwJlcWLzZIWSoqQOzQRx/suZjUQAQvZQSPpEMbEuw2y20htAQ0kNpCUBCUhPAJSkcAAOAA4QBXuxV5iYsdXj2EW7FXmJix1ePYQtaTXcT6RaTXcT6QBLuxV5iYsdXj2EW7FXmJix1ePYQtaTXcT6RaTXcT6QBLuxV5iYsdXj2EcV4XrUhaRiLiykqSoBQvAJKSQRmFdnq2SOeYBI5gEwuaTXcT6RaTY5IT6QAucNJlsy76cRsV1PtuFLCUXWJuTJGzsLqLC5Jj+JbCsytIWjaSCnMc48C3bvnKdWLls69KmuoVmiO0+sSM7IsqlW37auFE3LUkvtKW9sTQnbfrAdQHFADYWFHUIS8Labc2dRCV7JzTtAHI/kZ8jHq7czjYxmvRrTUFJsXDdZdHArDlVxGAb2uZDWmSlJ4J1Dl9xgNzRWaJh1UqxJ1YViVkK9WqrXVVJqmT1WlpmaqSpY5Nt0hioTSFoDBKtVlsKC05EkEDNJxuw3OYFVrX0kpOdk3yOKeB523xH+RmD/AEJjeXf5el/7Wv8AqMwef6J/YQBfvtw48VrPRV8fG4t9uHHitZ6Kvj43CfFAGG+3DjxWs9FXx8bi324ceK1noq+PjcJ8UAYb7cOPFaz0VfHxuLfbhx4rWeir4+NwnxQBhvtw48VrPRV8fG4xNMoshetdrd6ykrVmZWqSdHpMnMzrKpE1GSoztXmGpuXk5gtT8swXaw+2luoSspMbaFq0dhSVqZY7kfaP1/cwH//Z)![ref7]![ref7]![ref7]![ref7]

<a name="br23"></a> 

python scripts/sample.py --model\_path "models/MyLora.safetensors" --

base\_model "stabilityai/stable-diffusion-1-5" --prompt "a cat" --

negative\_prompt "blurry" --output\_dir "outputs/samples"

Powyższe załaduje model podstawowy 1.5, nałoży LoRę MyLora i wygeneruje obraz z zadanym

promptem. Możesz oczywiście generować wiele obrazów, zmieniać seed, itp. Dobre do

testowania LoRA w środowisku headless (np. automatyczny grid z różnymi wagami LoRA?).

• **Inne skrypty:**

• calculate\_loss.py – policzy indywidualny loss dla każdego obrazu w dataset (przydatne do

diagnozy, które obrazy są „trudne” do nauczenia) [<sub>152</sub>](https://github.com/Nerogar/OneTrainer#:~:text=dataset%20,every%20image%20in%20your%20dataset)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=dataset%20,every%20image%20in%20your%20dataset).

• Skrypty konwersji: convert\_model.py , convert\_model\_ui.py – konwersja modelu między

formatami (ckpt <-> diﬀusers).

• Debug: export\_debug.py – generuje plik debug (log + env) do zgłaszania problemów [<sub>153</sub>](https://github.com/Nerogar/OneTrainer#:~:text=If%20you%20encounter%20a%20reproducible,of%20your%20Github%20Issues%20submission)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=If%20you%20encounter%20a%20reproducible,of%20your%20Github%20Issues%20submission).

• Uruchamianie na Mac MPS czy AMD: dedykowane ﬂagi lub skróty w launch scripts, jak opisano w

dokumentacji launch (nie wgłębiamy się tutaj).

Generalnie, **wszystko co zrobisz w GUI, możesz zrobić w CLI** i vice versa. GUI jest wygodne do

interaktywnej konﬁguracji, CLI do automatyzacji i integracji z pipeline DevOps (np. możesz mieć skrypt

bash, który przygotowuje dane, odpala generate\_captions.py , potem train.py , a na końcu

publikuje model – pełna automatyzacja treningu). Dla rekrutera może to być o tyle istotne, że znajomość

trybu CLI świadczy o zrozumieniu, co dzieje się „pod maską” – np. wiesz jak wywołać trening, jak

parametry przełożyć na argumenty, itd.

*(Przykład użycia: Napisałeś własny kod generujący wariacje datasetu i chcesz trenować wiele LoRA z różnymi*

*parametrami – możesz w Pythonie wywoływać* train.py *z subprocess różnymi argumentami, logując*

*wyniki. OneTrainer CLI czyni to możliwym bez ręcznego klikania.)*

**Zaawansowane opcje OneTrainer**

W poprzednich sekcjach przewinęło się sporo zaawansowanych tematów. Tutaj zbierzemy je w jednym

miejscu i pokrótce omówimy, by podkreślić Twoją znajomość tych aspektów:

**Oﬄoading do RAM (przenoszenie obciążenia na pamięć RAM)**

OneTrainer potraﬁ automatycznie **oﬄoadować** część danych z GPU do CPU, co jest zbawienne, gdy

trenujemy bardzo duży model lub mamy ograniczony VRAM. Mechanizm ten jest kontrolowany przez

ustawienia **Train device** i **Temp device** w zakładce General [<sub>34</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=,To%20disable%20this)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=,To%20disable%20this)[35</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Train%20device%20%28default%20,To%20disable%20this)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Train%20device%20%28default%20,To%20disable%20this):

• Jeśli **Temp device = CPU**, program będzie przenosił na RAM te części modelu, które nie są w

danym momencie trenowane (np. w modelu SD część warstw U-Net może być przerzucana

podczas trenowania encodera tekstowego i odwrotnie). Używa do tego biblioteki Accelerate od

HuggingFace.

• Oﬄoading wydatnie zmniejsza wymagania VRAM kosztem zwiększenia zużycia RAM i obciążenia

magistrali CPU-GPU. Jak wspomniano, **64 GB RAM jest zalecane** przy takich operacjach [<sub>5</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection).

Faktycznie, np. przy trenowaniu LoRA na SDXL 1.0 z 8GB VRAM, można zaobserwować zajętość

RAM rzędu 40-50 GB, gdy wiele danych jest stale swapowanych.

• Gdy **Temp device = cuda** (czyli to samo co train device), oﬄoading jest wyłączony – wszystko

trzymane jest w VRAM. W praktyce przy małych modelach (SD1.5 z LoRA) tak jest optymalnie –

overhead oﬄoadingu nie jest potrzebny.

23

![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZADgDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAFBgIDBAr/xAA2EAACAQIEAwMJCAMAAAAAAAABAgMEBQAGBxESEyEXMZYVQVJVV2GR1NYiJDI0QlGBsXFzwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bomv2eb/AJygp8z3Ox5Jy5XxZcpKXLUfkjNMua7SagXtUuPPqYzaJVnoeTHyd6sq5cwcpeZslJpj93jVdQNUoiihGjgzgGjVh3gP5PXjPUbtwjf9sdGl8MMrajySCQLS6sZziPGSxZF8m7gE9eVJ05iAbScK7jZRhjgp4I4Y4kjjCxKIwFQIqhf0qo6ADfuHTAFfZi3tE1Y8Xj5DF2Yt7RNWPF4+QwtcqL0F+GLlRegvwwBL2Yt7RNWPF4+Qx5ajTRYtw2peqcRnVkCtm8rKzDbhKSLb24NuuxKkdfdhk5UXoL8McTAhZWBdNu8RsVVvc4HRh/nu82AJjl/O9hTLdPljMtRd6GGviS9Q5tkN0uc1AynnzR31WgKvEwQJTG3kTcxmMsfLCvYVTTwxpskUQXmcbBgACx33Y9NuP39/vxYAXS82XTq53ejuy3imoL7ertfHuUVsrrtTVNTczT9I47TBX1SMnJ3bmwRhg67E7EDMrrdpudwLrevsEod8k55HUd/flsbj9iNwfMTjepfy9r/2xf8AWMwe/wDhf6GAL+23Tj1refBWePpvF226cetbz4Kzx9N4T8WAMO23Tj1refBWePpvF226cetbz4Kzx9N4T8WAJ59VrZfJrfbcjQVt/uk9wpxW0ldYMx2WGGzhZBWVgq7za7dRs8Ehp1WAVBmkEjGOJwjlbC0n4h/P9HFgP//Z)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAIcDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAFBgECAwr/xAA6EAAAAwUECAMDDQAAAAAAAAABAgMABAUGBxETF5YSIVJVV5HU1hQxQRUiUSQmMjRCRXN0gYaxwtH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25I0enmPzkg7zPE4HJMuP6UuOjrLSfsiaVZrhIvARspIjfvKYwhUq7jcp3Nr2JTicULot5sjpTH5OmUtQKpJCQoEMmhOAGTKYPMAP7PLpjrC02iFvwbwpeiiqao6igKAV1qxOaQ6YiYTEL7NtABHXdKarwgBYpoltCwoMxoO6CaKaRE0wKkUEwApAIUoF+yUoagALfINTAV4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQN1NS8xymLiNVkmkUS6RZwApi2gIaRTeAHRELbQGzUIWsuXSWwXk3BkUhKYBIWwSiHkHqDASwtZ9k+My9LMSmR9jrjGEIk5QJJZxKvHPHw1J4i7+8RONGfCeJAXAwFKAORLTFAtvq03vNySZaiUlECFtM9TkUBEAHQ0ZWeBEydv0DmD3DmDWZMAIOppgwpIzBadROLucWLGHZwjsai0cPEkoY/RZ2eXmJi76k04Sg/vRDEubTXqCYGA5bBGwQDMlrdTcbQCKxr3BEg2yTPIaw8/OWwtD4CFoD6CLb0r9Xhf4qX9mzA+f6F/gGAvxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5Knjttoa2U5EBAIrGbR1B8yp49f22ye0wDyMXdp/m2TY9L6b0eDyk8TAd+fX50eoaC54rBFIcgi7u0QRdn0DkVUKdQVXYhNC3RMYwWNNuML+9Pzn+NMH/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAIADASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBAUGCv/EADUQAAECAgcHAgUDBQAAAAAAAAECAwAFBAYHERMXlhIhUlVXkdQx1hUiQVFzNLHCJDJCgcH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25pU+rzP65MUes8zkdSauU9qrlEotWm/hFaXa1yk0gTtKJjj0lsyh1L9BwW8G+llKyssYScT0lEsx/p20ptAtSaKEhCm2K4BTaVD1AX8PTtneL1bIv+0YLL2WXVWjuOBwJotrFc2jtkqKkJ+G3gE78JzdiIAuc2U3i5IhjYo7DbLbSG2wlpIbASgISkJ/xSkbgBf6DdAFeWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAEuWKuolrGrx4EWWKuolrGrx4ELWE1wJ7RYTXAntAD1IszKEAqtHtVbQpQSta647Gykg70ES5Xz33BO4Ded4jK1Iq5SF2rMvkFZaRMKDRqeX60vVteVPJ/S5WoJDTdHmAFDSlaLl7lNG/a+n1WHWkbBCUJAO5RO75bj/ANujTAdBSVrSdhgikgXkKUdnDITddduX6j7QBCicyWzqZzehzZM4o1Ans6m08XMmpZTptRqTSZmaPubblLFPpSFIwb1YrDYUFpuJuIHZTbdZubwJrOvkJQb6k15G8evrVsXj7EXg/QmPdO/p5X+Vr+Udg+v+k/sIAvzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAwzts45rOdFV49txZ22cc1nOiq8e24T4oAtctqs7W2somU4XhpLikmp1dGvkTuNxdq+2lRF4+QEqIvISbjdzmrT6DWCYSegVPbps1cpEzS9MVvyGsMobRLGwQtvFnUrlrSnllxGwNspAQq9YFwKhNv0o/Kj9lRuUT+yj/iV/GA//9k=)![](data:image/jpeg;base64,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)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAHkDASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwACAwUGCv/EADgQAAAEAwUIAgABDQEAAAAAAAECAwUABAcGERMXliExUlVXkdTWEhVRIiQ0QUJUcXOBk7HBwtP/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25Iz9bl/tkhL2nc2OxNnJ9KzkpK2aT+otSratpGYB7KRxx5lMWhUq8jgp4N82JTicUMIuJ6SUpj+bplLUCqSQkKBDJoWwAyZTBvAD/Xl+Y7QvN8Qv8AwjRS9FFU1R1FAUAsrVi2aQ/MRMJiF+tvABHbhKbMQgBcp8S3hcUIY0JdBNFNIiaYFSKCYAUgEKUC/slKGwAC/cGyAK8sTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIssTdRKsavDwIWsJLgL2iwkuAvaAJcsTdRKsavDwIwVpaJ8IwVFqkkJAMAnC1YYp7zCIAocJG8QC8AKF24AAN0LuElwF7RkBClC4ofG8bx+OyAD35JxpixS7zKvz+/Sks7tiDkW0LoLivMS7u4S7WQEwBBECGTmZ5I4CIm+QEEBABHYr/ZJ/uUz/aL/AOkHNc0E1KeT94CUxn+xF5yCJT3FtqwHAPkG268oXhuELwELhhhgA0jyy06c3eTdivEtIPr07Ph3JJsnnaWmZlzGX2JptKE/NEMTBvNioJgYDluEbhAOyWt1NxvAHV6/IESDfYm3IbQ377NheH4CF4D+oRj3Sv6O1/zUv+o7A7/6F/wEAX52045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAYZ2045q86Ktx63FnbTjmrzoq3HrcJ8UAPPryw1eYXCy1k3Rb7BKbs+7qndWC0zPLElWm0TW4rACzmzShFVVSSpkkkkRUPiHKY5SpAdQrTGom8f4f7CNsB//2Q==)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAJ0DASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwAEBQYDCv/EADgQAAECAwUIAQEFCAMAAAAAAAIBAwAEBQYHExeWERJSVVeR1NYhMRU0QVFzFBYiJDNCYYGxssL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25oq9bmv2yYl7T1Oh2Js5PtWclJWzTf2Ral21dJWYStiFRx5ltaQ6L8jgt4O2bUTU1YwhxOklLsf5dsRvAvSaUBQCbYtghNiSfVEP7PHfX5TaW6m38o8Lr2WXSvHccRxBlb2LZtLvqpKQD9m7URV+cJz4xARNjm6O1NgpDGxLsNsttA22gtCjaIIIAig/2iKfCIm36J8QBXliXUS9jV6eBFliXUS9jV6eBC1hNcA9osJrgHtAEuWJdRL2NXp4EWWJdRL2NXp4ELWE1wD2iwmuAe0AS5Yl1EvY1engRZYl1EvY1engQtYTXAPaLCa4B7QBLliXUS9jV6eBFliXUS9jV6eBC1hNcA9osJrgHtAEuWJdRL2NXp4EWWJdRL2NXp4ELWE1wD2iwmuAe0AS5Yl1EvY1engRZYl1EvY1engQtYTXAPaLCa4B7QBLliXUS9jV6eBFliXUS9jV6eBC1hNcA9osJrgHtAEuWJdRL2NXp4EWWJdRL2NXp4ELWE1wD2iwmuAe0ARZbuMTEk4F4N6bhtzTTohM2nGaknMBccmp1hZRrFl3hbJogQ0VVNPwRYyLM12uVeq2tok3NM49l6uzK/tbTqywzcvVJUKtKIrSoSocpLTLUo4W+qGbRGiChbET3ZZgyaImgUgIlbPdTfbIhUFJstm0C3SJN4di7FghsfJSsxeDfAkyw1Mq1W7KNgUwAumg/udS1VN40Vflfkl/FflYDFCs0W7qp1eTqw1iWkK7WqtXDqTVMnqtLTMzU1l/htuksT80BBg7SxWG0JDHYq7FRNyN91267USq1r+BVBdtibcp8p9frZtNqfkqbUX8FWO6d+70v9Vr/1G4X6/wCh/wCEgC/O27jmtZ0Vbj1uLO27jmtZ0Vbj1uE+KAMM7buOa1nRVuPW4s7buOa1nRVuPW4T4oAwztu45rWdFW49biztu45rWdFW49bhPigDDO27jmtZ0Vbj1uLO27jmtZ0Vbj1uE+KAMM7buOa1nRVuPW4s7buOa1nRVuPW4T4oAwztu45rWdFW49biztu45rWdFW49bhPigDDO27jmtZ0Vbj1uLO27jmtZ0Vbj1uE+KAMM7buOa1nRVuPW4s7buOa1nRVuPW4T4oAsO+27nebEapWCMzEAFbGW1b3jJU2JvuWdBsf8qZiifnG2spRnJavW1tQMy0/IWznaHUqe2LU01My7NPoMnS3Am2plhlQcN6XJxtA3kwiHeUS2inSVr7uz+uEbxj+gz+k3/wBBgP/Z)![ref8]![ref8]![ref7]![ref1]![ref1]![ref1]

<a name="br24"></a> 

• OneTrainer stara się być sprytny: np. można oﬄoadować **EMA weights** na CPU, by nie zajmowały

VRAM [<sub>89</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,training%20using%20ClipSeg%20or%20Rembg)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,training%20using%20ClipSeg%20or%20Rembg). Model może oﬄoadować tekstowe encodery gdy trenujemy U-Net i vice versa.

• Dla bardzo dużych modeli (Flux, SDXL) oﬄoading to często jedyna opcja na średniej karcie.

Lepiej, że program wolniej działa, niż jakby miał się nie uruchomić z braku pamięci.

Z punktu widzenia praktyki, **umiejętność ustawienia oﬄoadingu** świadczy o zrozumieniu ograniczeń

sprzętu. Np. w naszym przewodniku przy Flux wskazaliśmy żeby użyć cuda+cpu, bo ﬂux jest ogromny –

to pokazuje, że potraﬁsz dobrać strategie trenowania do dostępnych zasobów.

Jeśli chodzi o implementację: Oﬄoading w OT oparty jest pewnie o accelerate (z conﬁg Zero3

Oﬄoad). Pamiętaj, że wymaga to pewnej „stabilności” – np. w trakcie oﬄoadingu może dojść do

*garbage collection* i skokowych użyć pamięci (stąd 32GB to minimum, bo GC może nie nadążyć i

OutOfMemory) [<sub>154</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection).

Podsumowując: Oﬄoading to potężna funkcja, ale trzeba mieć na względzie posiadany RAM. Przy 16GB

RAM bym nie ryzykował; przy 32GB może zadziała, lecz może swapować na dysk, co zabije wydajność.

**Precyzja obliczeń (precision) i typy danych**

Nowoczesne treningi często korzystają z obniżonej precyzji (mixed precision) oraz kwantyzacji w celu

zmniejszenia zużycia pamięci i przyspieszenia obliczeń. OneTrainer daje sporo kontroli w tym zakresie w

zakładce Model (sekcja **Data Types**) oraz w opcjach LoRA.

• **FP32 vs FP16 vs BF16:** Domyślnie modele mogą być trenowane w trybie mieszanej precyzji FP16

(ﬂoat16) – niemal wszystkie obecne narzędzia to robią, bo FP32 jest zazwyczaj zbędne do

stabilnej nauki i drogie pamięciowo. BF16 (bﬂoat16) to alternatywa do FP16, z pewnymi zaletami

(szerszy zakres dynamiczny bez INF/NAN) – często preferowany na nowych GPU. OneTrainer

potraﬁ użyć BF16 jeśli jest wspierane. W praktyce, na kartach Nvidia Ampere+ BF16 jest świetną

opcją i w OT chyba tak jest ustawione np. w presetach SDXL. (Trening SDXL w BF16 jest

bezproblemowy i bezpieczniejszy niż FP16).

• **8-bit i 4-bit (quantization):** OneTrainer integruje zapewne biblioteki bitsandbytes, co pozwala

użyć 8-bitowych optymalizatorów (8-bit Adam) i przechowywania wag w 8-bitach. Ponadto

wspiera formy kwantyzacji LoRA:

• LoRA weight data type – wspomniana opcja, gdzie możesz wybrać np. int4 (NF4) dla wag

LoRA [<sub>155</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=randomly%20ignoring%20a%20percentage%20of,you%20train%20additional%20embeddings%2C%20this)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=randomly%20ignoring%20a%20percentage%20of,you%20train%20additional%20embeddings%2C%20this). NF4 (Normalized Float 4) to 4-bitowy format dynamiczny, który zaskakująco dobrze

sprawdza się do przechowywania modeli z minimalną utratą jakości. Użycie NF4 przy LoRA Flux

było wręcz zalecane by zmieścić model [<sub>142</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close).

• Również model bazowy może być wczytany w formie 8-bit lub 4-bit, choć w Diﬀusers to nie jest

natywne – OneTrainer mógłby użyć auto-kwantyzacji, ale najczęściej zostawia to

optymalizatorowi.

• **FP8:** Standard FP8 (8-bit ﬂoat) staje się realny w nowych bibliotekach (PyTorch 2.1+). Flux LoRA

zaleca FP8 minimum [<sub>141</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%2C%20but%20it%20should%20be)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%2C%20but%20it%20should%20be). Prawdopodobnie OneTrainer korzysta tu z triku: używa NF4 w weights i

BF16 w aktywacjach, co ekwiwalentnie daje efektywność ~8-bit. W dokumencie ﬂux było: „NF4

precision allows usage on lower VRAM but grid pattern artifact” [<sub>142</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close). W przyszłości być może

doczekamy się w OT opcji „WgradPrecision FP8”.

• **Zrozumienie vs Memkorzystność:** Umiejętność doboru precyzji to cenna praktyczna

umiejętność. Np. wiedza, że *przy dropout i DoRA w LoRA lepiej unikać FP16 bo może generować*

*NaNy – stąd BF16 bezpieczniejsze*. Albo że *8-bit Adam obniża zużycie pamięci optymalizatora o ~0.5x*

*przy minimalnej różnicy w konwergencji*.

24

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFUDASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBQYECv/EADcQAAECBAMFBgMHBQAAAAAAAAIBAwAEBQYHERMSFyExllJVV5HU1hUicyMkMkFCUbIzNIGxwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmir181+8mJe56nQ7JtyfatyUlbab+EXS7ddJWYStiFR15ltaQ6L8jot6Oc2ompqxpDqdJKYY/d2xHEDFJpQFAJti8EJsSTmiH8PHbXimZbKZ/tGDC9ll0sR3HEcQZXFi82l21UlIB+G5oirx0nOGoCJk5sjmmQpDGxLsNsttA22gtCjaIIIAig/pEU4IiZ8k4QBXuxLxExY6vT0EW7EvETFjq9PQQtaTXYHyi0muwPlAEu7EvETFjq9PQRbsS8RMWOr09BC1pNdgfKLSa7A+UAS7sS8RMWOr09BFuxLxExY6vT0ELWk12B8otJrsD5QBLuxLxExY6vT0Ea5MN22ao0SYh4pzDzRhNOybt3Kcs4y0H4Z9lacgvMPEgsECOIqg4iZpyhr0muwPlGBxoBMERODpKJIvFEQRzRA7PzIhLl+pNrnAF9m3NPT9VvG36mLhT9q1aSlTfpwo2y7KVWnM1imgYkeavStPmpeXcPkZtkSIKLspR5rIk5VzEXGc3GGnDWvWkhGYCRls2XSkRSJUzVURETNfySKA8IVmi4dVOrydWGsS0hXa1Vq4dSapk9VpaZmamsvwbbpLE/NAQaOZarDaEhjkq5KibkcbsN1zRKrWvkVQXOyb5TinPnbaZp+ypmi/kqx3Tv9vS/qtf8AUbhef+B/0kAX77cOO9az0VfHtuLfbhx3rWeir49twnxQBhvtw471rPRV8e24t9uHHetZ6Kvj23CfFAGG+3DjvWs9FXx7bi324cd61noq+PbcJ8UAYb7cOO9az0VfHtuMR41YdETRJVasiC4gptWdegKSmmyn4reTZyVeKlkmXHPLjCpHO1Xm79aX/gEBpLPpJsV29rqZmG5qnXpP0Oo04AZm5eZl2adQZOlODNszkvLm2449LE62giX2RDtbJ5ilCAx/QZ+k3/AYoD//2Q==)![](data:image/jpeg;base64,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)![ref1]![ref7]![ref7]![ref7]![ref7]

<a name="br25"></a> 

OneTrainer upraszcza te rzeczy, ale Ty, jako użytkownik zaawansowany, potraﬁsz je kontrolować.

Przykład: W training conﬁg w OT jest zapewne ﬂaga --mixed\_precision (auto/FP16/BF16) – można

wymusić np. --mixed\_precision no jakby FP32 potrzebne (czasem do debug).

W skrócie: Niższa precyzja = szybszy trening, mniejsze modele, ale potencjalne problemy (instability).

OneTrainer domyślnie stara się używać rozsądnej mieszanej precyzji. W testach nie stwierdzono by to

powodowało istotne problemy.

**Różne typy LoRA (LoRA, LoHa, DoRA)**

Tradycyjna LoRA to nie jedyny sposób na efektywne dostrajanie modeli. Wspominaliśmy: - **LoHa**

**(Lycoris):** Rozszerzenie LoRA, które wprowadza dodatkową macierz Hadamarda. Umożliwia to sieci

nauczenie się bardziej złożonych transformacji bez zwiększania wymiaru tak jak w zwykłej LoRA. LoHa

bywa lepsza do stylów artystycznych i drobnych detali, potraﬁ uchwycić tekstury. OneTrainer obsługuje

LoHa – wybierasz *Type: LoHa [<sub>98</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Image%3A%20image)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Image%3A%20image)*i dalej pracujesz analogicznie. W pliku LoRA wynikowym będzie po

prostu inne nazewnictwo tensorów (stąd np. Auto1111 wymaga skryptu do załadowania LoHa albo

wbudowanej obsługi – już jest mod na to). - **DoRA (Weight Decomposition LoRA): Nowość** stworzona i

szybko zaimplementowana w OneTrainer (deweloper OT jest na bieżąco z trendami) [<sub>156</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA). Pozwala

trenować LoRA w dwóch częściach – modulując długość i kierunek wektora wag osobno. Empiryczne

wyniki (choć głównie z NLP) pokazały, że to poprawia jakość adaptacji nawet do poziomu pełnego ﬁne-

tuningu [<sub>157</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA%20is%20a%20variation%20on,gap%20between%20those%20two%20behaviors)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA%20is%20a%20variation%20on,gap%20between%20those%20two%20behaviors). W OneTrainer aktywujesz to tickiem *Decompose Weights* w LoRA tab [<sub>104</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=optimizers%20,to%20help%20with%20overfitting%20by)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=optimizers%20,to%20help%20with%20overfitting%20by). W praktyce, DoRA

może pomóc gdy LoRA normalna nie daje rady doskonale odtworzyć czegoś. Z kolei wadą jest, że

powstałe LoRA są mniej standardowe – nie każde narzędzie je obsłuży (choć format pliku jest ten sam,

to wyjściowy adapter ma dwie pary matryc zamiast jednej – nie wiem czy WebUI to zaaplikuje

poprawnie bez aktualizacji). W repo comfyUI widziałem zgłoszenia dot. wsparcia DoRA [<sub>158</sub>](https://github.com/comfyanonymous/ComfyUI/issues/6673#:~:text=Add%20Support%20For%20OT%20Lora%2C,Lora%2C%20LoHa%2C%20Dora%20with)[</sub> ](https://github.com/comfyanonymous/ComfyUI/issues/6673#:~:text=Add%20Support%20For%20OT%20Lora%2C,Lora%2C%20LoHa%2C%20Dora%20with). - **LoRA**

**tekstowe vs unetowe:** Standardowo LoRA dotyczy U-Net (części generującej obraz). OneTrainer jednak

(jak i kohya) potraﬁ też trenować LoRA na text encoder. Taka LoRA tekstowa zmienia embeddingi słów w

CLIP – to inny efekt (coś jak textual inversion, ale w parametry CLIP). OneTrainer daje możliwość *Layer*

*Preset: custom* i wskazania warstw text encodera. Jeśli zaznaczyłbyś w LoRA tab np. layery CLIP-u, to LoRA

będzie także je obejmować. W praktyce mało kto tak robi (zwykle textual inversion jest lepsze do tego),

ale to możliwe. - **Kombinacje:** OneTrainer umożliwia trenowanie jednocześnie LoRA + embedding, LoRA

\+ Dreambooth (regularization) – tak jakby mix technik. To dość unikalne. Dla rekrutera: świadczy, że

narzędzie ma elastyczność do eksperymentów badawczych.

Z punktu widzenia kodu, obsługa LoHa i DoRA w OT to duży plus – nie musisz zmieniać programu, by

skorzystać z nowinek. Dla porównania, wiele GUI (np. Kohya GUI) wymagało osobnych forków, by

trenować LoHa.

Twoja świadomość typów LoRA pokazuje, że nie traktujesz LoRA jak czarnej skrzynki, tylko rozumiesz, że

to metoda *low-rank decomposition* i że są jej wariacje. Możesz np. w CV czy rozmowie wspomnieć:

„pracowałem z implementacją LoRA i jej rozszerzeń (LoHa, DoRA) – potraﬁę je zastosować i wiem kiedy

są korzystne (np. DoRA do stabilizacji trudnych treningów)”.

**Wybór trenowanych warstw modelu**

To dość niszowa, ale ciekawa opcja. Wspomnieliśmy w LoRA zakładce o **Layer Preset** i możliwości

custom. Dlaczego to jest ważne:

W pełnym ﬁne-tuningu możemy np. *zamrozić* pewne warstwy i trenować tylko inne (np. tylko ostatnie

bloki UNet). W LoRA analogicznie – można przyłożyć LoRA tylko do niektórych bloków. OneTrainer

najnowszy pozwala po prostu wpisać listę warstw (pewnie jako nazwy lub indeksy) w trybie custom [<sub>112</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP).

25

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAIcDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAABwAFBgECAwr/xAA6EAAAAwUECAMDDQAAAAAAAAABAgMABAUGBxETF5YSIVJVV5HU1hQxQRUiUSQmMjRCRXN0gYaxwtH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25I0enmPzkg7zPE4HJMuP6UuOjrLSfsiaVZrhIvARspIjfvKYwhUq7jcp3Nr2JTicULot5sjpTH5OmUtQKpJCQoEMmhOAGTKYPMAP7PLpjrC02iFvwbwpeiiqao6igKAV1qxOaQ6YiYTEL7NtABHXdKarwgBYpoltCwoMxoO6CaKaRE0wKkUEwApAIUoF+yUoagALfINTAV4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQNYYm4iVYzeHQMtXSWwXk1dJbBeTAS4Ym4iVYzeHQN1NS8xymLiNVkmkUS6RZwApi2gIaRTeAHRELbQGzUIWsuXSWwXk3BkUhKYBIWwSiHkHqDASwtZ9k+My9LMSmR9jrjGEIk5QJJZxKvHPHw1J4i7+8RONGfCeJAXAwFKAORLTFAtvq03vNySZaiUlECFtM9TkUBEAHQ0ZWeBEydv0DmD3DmDWZMAIOppgwpIzBadROLucWLGHZwjsai0cPEkoY/RZ2eXmJi76k04Sg/vRDEubTXqCYGA5bBGwQDMlrdTcbQCKxr3BEg2yTPIaw8/OWwtD4CFoD6CLb0r9Xhf4qX9mzA+f6F/gGAvxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5KnjttrG2nG9YzkqeO22T2mAwxtpxvWM5Knjttoa2U5EBAIrGbR1B8yp49f22ye0wDyMXdp/m2TY9L6b0eDyk8TAd+fX50eoaC54rBFIcgi7u0QRdn0DkVUKdQVXYhNC3RMYwWNNuML+9Pzn+NMH/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAJ0DASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwAEBQYDCv/EADgQAAECAwUIAQEFCAMAAAAAAAIBAwAEBQYHExeWERJSVVeR1NYhMRU0QVFzFBYiJDNCYYGxssL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+25oq9bmv2yYl7T1Oh2Js5PtWclJWzTf2Ral21dJWYStiFRx5ltaQ6L8jgt4O2bUTU1YwhxOklLsf5dsRvAvSaUBQCbYtghNiSfVEP7PHfX5TaW6m38o8Lr2WXSvHccRxBlb2LZtLvqpKQD9m7URV+cJz4xARNjm6O1NgpDGxLsNsttA22gtCjaIIIAig/2iKfCIm36J8QBXliXUS9jV6eBFliXUS9jV6eBC1hNcA9osJrgHtAEuWJdRL2NXp4EWWJdRL2NXp4ELWE1wD2iwmuAe0AS5Yl1EvY1engRZYl1EvY1engQtYTXAPaLCa4B7QBLliXUS9jV6eBFliXUS9jV6eBC1hNcA9osJrgHtAEuWJdRL2NXp4EWWJdRL2NXp4ELWE1wD2iwmuAe0AS5Yl1EvY1engRZYl1EvY1engQtYTXAPaLCa4B7QBLliXUS9jV6eBFliXUS9jV6eBC1hNcA9osJrgHtAEuWJdRL2NXp4EWWJdRL2NXp4ELWE1wD2iwmuAe0ARZbuMTEk4F4N6bhtzTTohM2nGaknMBccmp1hZRrFl3hbJogQ0VVNPwRYyLM12uVeq2tok3NM49l6uzK/tbTqywzcvVJUKtKIrSoSocpLTLUo4W+qGbRGiChbET3ZZgyaImgUgIlbPdTfbIhUFJstm0C3SJN4di7FghsfJSsxeDfAkyw1Mq1W7KNgUwAumg/udS1VN40Vflfkl/FflYDFCs0W7qp1eTqw1iWkK7WqtXDqTVMnqtLTMzU1l/htuksT80BBg7SxWG0JDHYq7FRNyN91267USq1r+BVBdtibcp8p9frZtNqfkqbUX8FWO6d+70v9Vr/1G4X6/wCh/wCEgC/O27jmtZ0Vbj1uLO27jmtZ0Vbj1uE+KAMM7buOa1nRVuPW4s7buOa1nRVuPW4T4oAwztu45rWdFW49biztu45rWdFW49bhPigDDO27jmtZ0Vbj1uLO27jmtZ0Vbj1uE+KAMM7buOa1nRVuPW4s7buOa1nRVuPW4T4oAwztu45rWdFW49biztu45rWdFW49bhPigDDO27jmtZ0Vbj1uLO27jmtZ0Vbj1uE+KAMM7buOa1nRVuPW4s7buOa1nRVuPW4T4oAsO+27nebEapWCMzEAFbGW1b3jJU2JvuWdBsf8qZiifnG2spRnJavW1tQMy0/IWznaHUqe2LU01My7NPoMnS3Am2plhlQcN6XJxtA3kwiHeUS2inSVr7uz+uEbxj+gz+k3/wBBgP/Z)![ref1]![ref7]![ref7]![ref7]![ref7]![ref7]

<a name="br26"></a> 

**Przykład zastosowania:** Trenujesz styl, który głównie wpływa na kolory/tony, a nie strukturę obrazu –

być może wystarczy LoRA na warstwach odpowiedzialnych za drobne szczegóły i kolory (to mogłyby być

warstwy mid-level). Wtedy, zamiast marnować budżet parametrowy na wszystkie warstwy, wybrałbyś

tylko te kluczowe.

OneTrainer developer wspomniał, że standardowo dawno temu LoRA była tylko na attention, potem

wprowadzili *blocks = attn+MLP, all, custom [<sub>113</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=OneTrainer%20now%20has%20the%20ability,want%20in%20the%20text%20field)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=OneTrainer%20now%20has%20the%20ability,want%20in%20the%20text%20field)[112</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP)*. To czyni narzędzie dość unikalnym – bo np. w Kohya

GUI musiałeś kombinować z parametrami network\_dim i skryptami, a tu masz gotowe.

Dlaczego rekruter miałby się tym przejąć? Bo pokazuje to *głębokie zrozumienie architektury Stable*

*Diﬀusion*. Aby sensownie wybrać warstwy, musisz wiedzieć jak U-Net jest zbudowany (bloki down, mid,

up, attn layers, MLP in feed-forward etc.). To dość zaawansowana wiedza inżynierska.

Możesz np. powiedzieć: „Aby uniknąć efektu 'purple bleed' w LoRA trenowanej dla modelu SD2.1,

ograniczyłem LoRę do warstw attention i pierwszych warstw decodera – to usunęło problem

nadpisywania palety kolorów.” Taka analiza robi wrażenie i narzędzie Ci to umożliwiło.

Podsumowując, OneTrainer to **rozbudowane środowisko** i Ty poznałeś/łaś jego zakamarki: oﬄoading,

precision, LoRA types, layer control. Te funkcje są zdecydowanie zaawansowane i wykraczają poza

„kliknij i czekaj”. Ich opanowanie dowodzi praktycznych umiejętności w trenowaniu modeli AI i

rozumienia mechanizmów uczenia.

**Praktyczne porady i najlepsze praktyki**

Na zakończenie, kilka dodatkowych porad z doświadczeń użytkowników OneTrainer i ogólnych zasad:

• **Zawsze monitoruj przebieg treningu:** Nie zostawiaj modelu na wiele godzin bez nadzoru,

zwłaszcza na początku. Obserwuj loss – jeżeli nagle staje się NaN lub rośnie do nieskończoności,

przerwij – coś poszło nie tak (zbyt duży LR, niestabilna precyzja FP16). OneTrainer co prawda

stara się temu zapobiec (Mixed Precision, grad clipping), ale czujność popłaca.

• **Regularnie korzystaj z próbek i walidacji:** Jak już wspomniano, sample images co pewien czas

to cenny feedback. Walidacja loss też się przydaje. Choć czasem „twoje oczy są najlepszą miarą” –

generuj obrazy testowe w docelowym UI, bo ostatecznie liczy się czy efekt wizualny Ci

odpowiada, nie minimalny loss.

• **Nie przeuczaj LoRA:** Częsty błąd – zbyt długo trenowana LoRA zaczyna „przepisywać” obrazy

treningowe w pamięci i traci zdolność generalizacji. Objawy: generowane obrazy wyglądają

bardzo podobnie do treningowych (overﬁtting) albo model reaguje tylko na bardzo specyﬁczny

prompt. Recepty:

• Używaj regularyzacji: dropout (w LoRA), augmentacji, prior images (przy DreamBooth).

• Zastosuj Early Stopping manualnie – gdy widzisz na próbkach, że już jest dobrze, zakończ

trening. LoRA często osiąga optimum szybciej niż by wskazywał spadek loss (loss może dalej

spadać minimalnie, ale obrazki już się nie poprawiają, a nawet pogarszają – bo np. kolorystyka

staje się monotonna).

• **Porównuj różne podejścia:** OneTrainer sprawia, że test A/B jest łatwy – np. możesz skopiować

conﬁg, zmienić jedną rzecz (np. LoRA rank 8 vs 16) i zrobić dwa treningi. Potem odpalić generację

z obu LoR i porównać. Wyciągaj wnioski i zapisuj je (Lessons Learned wiki OT zawiera sporo

takich wniosków od użytkowników).

• **Wykorzystuj Dev Corner:** Oﬁcjalne wiki OneTrainer ma sekcję Dev Corner [<sub>128</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Getting%20Started)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Getting%20Started)[159</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,28)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,28), gdzie

znajdują się wskazówki dla programistów i zaawansowanych użytkowników. Można tam znaleźć

np. omówienie struktury projektu [<sub>160</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,resolutions%20at%20the%20same%20time)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,resolutions%20at%20the%20same%20time), co ułatwi Ci ewentualne debugowanie czy dodawanie

26

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAoAFwDASIAAhEBAxEB/8QAHAAAAgIDAQEAAAAAAAAAAAAAAAcCAwQFBgEK/8QAQBAAAQIFAQMIBQgLAQAAAAAAAQIDAAQFBhESBxMhFyIxQVFVl9UyYYGRoQgUFUJTVnHRFhgjJSY1UoWSlvDS/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APuPrdYqkjUag01U3kpTNhKQAeanKuA52B7fX1xqDctbBfzU3wA6hI4HgDqyPSHSR6vw7PLjbeXWJ1K1pWiYm20MvpKy8h5kr+c7xjQGChwLa0EPkjSrmxrNRdeLLgYKC4rUph55aTu/RUpTjDakOc4laEhaAcaXFwDXtCcnJsVF6Zm3pkJdbCUkHmkh0nBKjkc3jwHb6o5Gr12qM1Kcal6i/LpSsgIwTgAnAwFDq4Z7MDj19DYZcRLVArKSXJlGAXFA7sJe44IxkZHxOe3iK00TVam4t5KVB1W7SpSlAjUeHFPE4OAfjAT/AEgrfej3uV/7hg2dPzM7KTxmXVvvJeay6ocSMDA4kngk49gxCn1jsP8AkYZliKAlqgSleStK0+iQdISOaSrJIPHBAHA8YBioA1OHrKhn2D/v+EWRjIURzwhaisAqHDIIA44BwPwGQO2J71X2LnuH5wF0EU71X2LnuH5wb1X2LnuH5wF0EYy5jSUpUlSFLJCNQPOI6gQCAfxwPXFYm0EAqWEE/VWppKsZxnGs8Pb8YBdXBs+mLqnK3JVmd3drTbdFcpUvRZ+oUOtyk7Kmf+lnX6lTRLPlqaD0luEomVkllwuJb5mrnE/J6sdKf5nfhUOCVG/rqyB1An6SyrHHnE5PXDxU60gZW42gA6SVLSkBXZkkDPq6YsyD0HMAlGNhFoy6ChmsX80FHUso2gXWCTgjpFTHDj1/HrxV/J8spx4uuVS+3NQOorv+6yok/wByxjr6ekw9YIBE/q8WJ3lfn+/XV5nFzGwKz5YqMvWdoTQVjIRtFu9AOMfUTVAkdHSOJ9ph4QQCYTsPtsE/xBtFA6tO0i8c+396CJciFtfeHaP4k3j5rDlggE1yIW194do/iTePmsHIhbX3h2j+JN4+aw5YIBRSOx2gU2oSVRlq/fzkzJPB5ludv+6p6TWUlKimZkpmpOS0yg6R+zebWg8QRgnNVCnZitLrsquqPKmbar03bc489Q6IpMxMystJTxeljpWv5uWaky2nehtwuNuFSACFKb6iElJUQANRJJAAGOkk8BCPsMhVV2pFJ1AbUKyDjjg/QNsnBx14IOOwjtgNnW7qr1t12sTFUtaemrQbp8k5Kz1vyU9cVddqq1TPz9lVKp5nHNyylMvu1IkU5K1DWogYg3tgt/TqTb20tAcJc0jZzduQVY9ILphUlf8AUngAehIgggJ8sNB7g2meHF1+VwcsNB7g2meHF1+VwQQByw0HuDaZ4cXX5XByw0HuDaZ4cXX5XBBAHLDQe4NpnhxdflcHLDQe4NpnhxdflcEEAcsNB7g2meHF1+VwcsNB7g2meHF1+VwQQE5XatRKhUafT2qFtEbdnnjLNOzuz66JWRacd0oSubnHqaiVlWUlQKnZlxDYAJJwCRkWvSm6WK9OqacYmbluGduKdl3ajJK3E1MysjIKbRoSnDe6prKwFFSgVqBURgAggP/Z)![ref7]![ref7]![ref7]

<a name="br27"></a> 

własnych funkcji. Dla rekrutera może mieć znaczenie, że potraﬁsz czytać kod narzędzia i

ewentualnie go modyﬁkować – w OT to możliwe, bo kod jest czysty (tkinter, PyTorch, Diﬀusers).

• **Common mistakes (częste błędy):** Wiki OT ma sekcję poświęconą typowym potknięciom

użytkowników migracji z kohya [<sub>161</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,12)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,12). Np. ludzie zapominają, że w OneTrainer workspace musi być

ustawiony poprawnie, inaczej generowane sample nie zapiszą się tam gdzie myślą; albo że przy

kontynuacji treningu z backup *nie należy zmieniać nic w konﬁguracji*, bo to może dać niespójność.

Zalecenie: jeśli wznawiasz trening, **ładuj ten sam plik preset, co użyty na początku**, i tylko

zaznacz „Continue from last backup” – nie przekonﬁguruj opcji, bo backup zawiera optymalizator,

który np. jest w środku cyklu scheduler itp.

• **Aktualizacje OneTrainer:** Narzędzie jest rozwijane aktywnie. Sprawdzaj GitHuba co pewien czas

– często pojawiają się usprawnienia UI, nowe optymalizatory (np. niedawno dodano *Prodigy*,

*Lion*), wsparcie nowych architektur. Aktualizację zrobisz łatwo: git pull i update.bat

(instaluje nowe require) [<sub>162</sub>](https://github.com/Nerogar/OneTrainer#:~:text=)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=)[163</sub>](https://github.com/Nerogar/OneTrainer#:~:text=1,reinstall)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=1,reinstall). Zadbaj o kompatybilność – czasem nowe wersje zmieniają

format presetów, więc warto też czytać release notes.

• **Społeczność:** Dołącz na **Discord OneTrainer** – link znajdziesz w repo [<sub>164</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,com%2FNerogar%2FOneTrainer%2Fissues)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,com%2FNerogar%2FOneTrainer%2Fissues). Tam możesz podzielić

się wynikami, zapytać o rady, a nawet współtworzyć rozwój (autor jest otwarty na feedback).

Bycie aktywnym w takiej społeczności pokazuje pasję i bycie na bieżąco.

• **Eksperymentuj i dokumentuj:** Prowadź notatki z eksperymentów (np. różne parametry LoRA i

ich efekt). To pozwoli Ci budować intuicję. Wiki *Info, Guides and Lessons Learned* zawiera

doświadczenia innych – np. jaki dropout działał dla jakiego typu stylu, czy warto trenować text

encoder itp. Warto się inspirować, ale każde nowe zadanie może być inne – Twoja dociekliwość

by testować różne rozwiązania jest atutem.

Na koniec: Posiadając repozytorium wiedzy tak przygotowane (w formie tego README), dysponujesz

świetnym materiałem, by pokazać rekruterowi. Prezentuje on, że:

• Znasz narzędzia AI **w praktyce** – potraﬁsz nie tylko ich użyć, ale i skonﬁgurować głęboko pod

wymagania.

• Rozumiesz **działanie LoRA i Stable Diﬀusion** – co widać po objaśnieniach parametrów takich jak

rank, alpha, dropout, maski, bucketing.

• Potraﬁsz **automatyzować i programować** – znajomość trybu CLI, skryptów, integracji z innymi

systemami to ważna umiejętność inżynierska.

• Masz **świadomość najnowszych trendów** – wspomnienie ﬂux, DoRA, LoHa pokazuje, że śledzisz

dynamiczny rozwój technologii generatywnych (2024/2025 to właśnie czasy SDXL, nowe

optymalizatory, ﬂux/diﬀusers eksperymenty).

• Jesteś **dokładny i zorganizowany** – struktura dokumentu, cytowanie źródeł z oﬁcjalnej

dokumentacji [<sub>165</sub>](https://github.com/Nerogar/OneTrainer#:~:text=,different%20prompts%20per%20image%20sample)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=,different%20prompts%20per%20image%20sample)[103</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can), porządek sekcji, wszystko to odzwierciedla umiejętność tworzenia

czytelnej dokumentacji technicznej, co również jest cenione.

Powodzenia w dalszych projektach z OneTrainer – niech ten przewodnik służy zarówno Tobie, jak i

każdemu, kto chce wejść w świat trenowania własnych modeli generatywnych!

**Źródła:** Dokumentacja OneTrainer (GitHub Wiki) oraz doświadczenia społeczności:

repozytorium OneTrainer [<sub>166</sub>](https://github.com/Nerogar/OneTrainer#:~:text=Installation)

\-

Oﬁcjalne

[2](https://github.com/Nerogar/OneTrainer#:~:text=)

\- Wiki OneTrainer: *Getting Started*, *The Program*, *Concepts*, *Training*, *LoRA*, *Flux*, *Tools* (ostatni dostęp

czerwiec 2025) [<sub>19</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=In%20the%20general%20tab%2C%20you,Image%3A%20image)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=In%20the%20general%20tab%2C%20you,Image%3A%20image)[102](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=warned%20that%20when%20loading%20a,Adaptive)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=warned%20that%20when%20loading%20a,Adaptive)[130](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Flux%20is%20a%20DiT%20Transformer,slow%20model%20to%20work%20with)

\- Wątki dyskusyjne i poradniki (Reddit, Medium) dla praktycznych spostrzeżeń [<sub>139</sub>](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,https%3A%2F%2Fgithub.com%2FNerogar%2FOneTrainer)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,https%3A%2F%2Fgithub.com%2FNerogar%2FOneTrainer)[156</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA).

27

![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAEAk0DASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBAr/xAAmEAABAwQCAgICAwAAAAAAAAAAAwUHF1aW0wECBAYRQRIhEyMx/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/AO5t69A6eW4eUv19ykLwv5E0+3ZFv9t83xEOOeee366pdOnPHHHH1x9EkYyR7oo88e8yYn/X14/FL3Tz+nXnnj5+e3PHHT99ufvn7AAspglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrNjN692ZfIcfC6ewe0OPXjnxFOPId3vyXDy/numpzz15XU447c9Ov+devx8deP1wAB/9k=)![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAEAk0DASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBAr/xAAmEAABAwQCAgICAwAAAAAAAAAAAwUHF1aW0wECBAYRQRIhEyMx/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/AO5t69A6eW4eUv19ykLwv5E0+3ZFv9t83xEOOeee366pdOnPHHHH1x9EkYyR7oo88e8yYn/X14/FL3Tz+nXnnj5+e3PHHT99ufvn7AAspglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrFMEr9lHN3DWAApglfso5u4axTBK/ZRzdw1gAKYJX7KObuGsUwSv2Uc3cNYACmCV+yjm7hrNjN692ZfIcfC6ewe0OPXjnxFOPId3vyXDy/numpzz15XU447c9Ov+devx8deP1wAB/9k=)![ref8]![](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAFUDASIAAhEBAxEB/8QAGgABAQADAQEAAAAAAAAAAAAABwADBQYECv/EADcQAAECBAMFBgMHBQAAAAAAAAIBAwAEBQYHERMSFyExllJVV5HU1hUicyMkMkFCUbIzNIGxwv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD7bmir181+8mJe56nQ7JtyfatyUlbab+EXS7ddJWYStiFR15ltaQ6L8jot6Oc2ompqxpDqdJKYY/d2xHEDFJpQFAJti8EJsSTmiH8PHbXimZbKZ/tGDC9ll0sR3HEcQZXFi82l21UlIB+G5oirx0nOGoCJk5sjmmQpDGxLsNsttA22gtCjaIIIAig/pEU4IiZ8k4QBXuxLxExY6vT0EW7EvETFjq9PQQtaTXYHyi0muwPlAEu7EvETFjq9PQRbsS8RMWOr09BC1pNdgfKLSa7A+UAS7sS8RMWOr09BFuxLxExY6vT0ELWk12B8otJrsD5QBLuxLxExY6vT0Ea5MN22ao0SYh4pzDzRhNOybt3Kcs4y0H4Z9lacgvMPEgsECOIqg4iZpyhr0muwPlGBxoBMERODpKJIvFEQRzRA7PzIhLl+pNrnAF9m3NPT9VvG36mLhT9q1aSlTfpwo2y7KVWnM1imgYkeavStPmpeXcPkZtkSIKLspR5rIk5VzEXGc3GGnDWvWkhGYCRls2XSkRSJUzVURETNfySKA8IVmi4dVOrydWGsS0hXa1Vq4dSapk9VpaZmamsvwbbpLE/NAQaOZarDaEhjkq5KibkcbsN1zRKrWvkVQXOyb5TinPnbaZp+ypmi/kqx3Tv9vS/qtf8AUbhef+B/0kAX77cOO9az0VfHtuLfbhx3rWeir49twnxQBhvtw471rPRV8e24t9uHHetZ6Kvj23CfFAGG+3DjvWs9FXx7bi324cd61noq+PbcJ8UAYb7cOO9az0VfHtuMR41YdETRJVasiC4gptWdegKSmmyn4reTZyVeKlkmXHPLjCpHO1Xm79aX/gEBpLPpJsV29rqZmG5qnXpP0Oo04AZm5eZl2adQZOlODNszkvLm2449LE62giX2RDtbJ5ilCAx/QZ+k3/AYoD//2Q==)![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref1]![ref1]![ref7]![ref7]![ref7]![ref7]

<a name="br28"></a> 

[1](https://github.com/Nerogar/OneTrainer#:~:text=,to%20track%20the%20training%20progress)

[2](https://github.com/Nerogar/OneTrainer#:~:text=)

[3](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,r%20requirements.txt)

[6](https://github.com/Nerogar/OneTrainer#:~:text=1.%20Clone%20the%20repository%20,install.sh)

[7](https://github.com/Nerogar/OneTrainer#:~:text=3,r%20requirements.txt)

[8](https://github.com/Nerogar/OneTrainer#:~:text=4,r%20requirements.txt)

[9](https://github.com/Nerogar/OneTrainer#:~:text=Some%20Linux%20distributions%20are%20missing,libGL)

[10](https://github.com/Nerogar/OneTrainer#:~:text=sudo%20apt)[ ](https://github.com/Nerogar/OneTrainer#:~:text=sudo%20apt)[11](https://github.com/Nerogar/OneTrainer#:~:text=Usage)[ ](https://github.com/Nerogar/OneTrainer#:~:text=Usage)[12](https://github.com/Nerogar/OneTrainer#:~:text=GUI%20Mode)[ ](https://github.com/Nerogar/OneTrainer#:~:text=GUI%20Mode)[13](https://github.com/Nerogar/OneTrainer#:~:text=)[ ](https://github.com/Nerogar/OneTrainer#:~:text=)[14](https://github.com/Nerogar/OneTrainer#:~:text=All%20functionality%20is%20split%20into,directory.%20This%20currently%20includes)[ ](https://github.com/Nerogar/OneTrainer#:~:text=All%20functionality%20is%20split%20into,directory.%20This%20currently%20includes)[15](https://github.com/Nerogar/OneTrainer#:~:text=,every%20image%20in%20your%20dataset)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,every%20image%20in%20your%20dataset)[16](https://github.com/Nerogar/OneTrainer#:~:text=CLI%20Mode)[ ](https://github.com/Nerogar/OneTrainer#:~:text=CLI%20Mode)[17](https://github.com/Nerogar/OneTrainer#:~:text=To%20learn%20more%20about%20the,h)[ ](https://github.com/Nerogar/OneTrainer#:~:text=To%20learn%20more%20about%20the,h)[42](https://github.com/Nerogar/OneTrainer#:~:text=,switching%20to%20a%20different%20application)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,switching%20to%20a%20different%20application)[88](https://github.com/Nerogar/OneTrainer#:~:text=%2A%20Training%20methods%3A%20Full%20fine,model%20on%20multiple%20different%20prompts)[ ](https://github.com/Nerogar/OneTrainer#:~:text=%2A%20Training%20methods%3A%20Full%20fine,model%20on%20multiple%20different%20prompts)[89](https://github.com/Nerogar/OneTrainer#:~:text=,training%20using%20ClipSeg%20or%20Rembg)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,training%20using%20ClipSeg%20or%20Rembg)[116](https://github.com/Nerogar/OneTrainer#:~:text=,and%20Sample%20Steps%20are%20Flawed)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,and%20Sample%20Steps%20are%20Flawed)[126](https://github.com/Nerogar/OneTrainer#:~:text=,training%20without%20switching%20to%20a)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,training%20without%20switching%20to%20a)[148](https://github.com/Nerogar/OneTrainer#:~:text=in%20your%20dataset)[ ](https://github.com/Nerogar/OneTrainer#:~:text=in%20your%20dataset)[149](https://github.com/Nerogar/OneTrainer#:~:text=,create%20masks%20for%20your%20dataset)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,create%20masks%20for%20your%20dataset)[150](https://github.com/Nerogar/OneTrainer#:~:text=,create%20masks%20for%20your%20dataset)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,create%20masks%20for%20your%20dataset)[151](https://github.com/Nerogar/OneTrainer#:~:text=,automatically%20create%20captions%20for%20your)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,automatically%20create%20captions%20for%20your)[152](https://github.com/Nerogar/OneTrainer#:~:text=dataset%20,every%20image%20in%20your%20dataset)[ ](https://github.com/Nerogar/OneTrainer#:~:text=dataset%20,every%20image%20in%20your%20dataset)[153](https://github.com/Nerogar/OneTrainer#:~:text=If%20you%20encounter%20a%20reproducible,of%20your%20Github%20Issues%20submission)[ ](https://github.com/Nerogar/OneTrainer#:~:text=If%20you%20encounter%20a%20reproducible,of%20your%20Github%20Issues%20submission)[160](https://github.com/Nerogar/OneTrainer#:~:text=,resolutions%20at%20the%20same%20time)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,resolutions%20at%20the%20same%20time)[162](https://github.com/Nerogar/OneTrainer#:~:text=)

[163](https://github.com/Nerogar/OneTrainer#:~:text=1,reinstall)[ ](https://github.com/Nerogar/OneTrainer#:~:text=1,reinstall)[165](https://github.com/Nerogar/OneTrainer#:~:text=,different%20prompts%20per%20image%20sample)[ ](https://github.com/Nerogar/OneTrainer#:~:text=,different%20prompts%20per%20image%20sample)[<sub>166</sub>](https://github.com/Nerogar/OneTrainer#:~:text=Installation)[</sub> ](https://github.com/Nerogar/OneTrainer#:~:text=Installation)GitHub - Nerogar/OneTrainer: OneTrainer is a one-stop solution for all your stable diﬀusion

training needs.

<https://github.com/Nerogar/OneTrainer>

[4](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection)

[5](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection)

[154](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,OOMing%20due%20to%20garbage%20collection)[<sub>164</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,com%2FNerogar%2FOneTrainer%2Fissues)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki#:~:text=,com%2FNerogar%2FOneTrainer%2Fissues)Home - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki>

[18](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=1)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=1)[53](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=In%20the%20top%20left%2C%20next,one%20you%20want%20to%20train)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=In%20the%20top%20left%2C%20next,one%20you%20want%20to%20train)[54](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=In%20,001.txt)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=In%20,001.txt)[55](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Define%20the%20filepath%20for%20the,high%20can%20cause%20VRAM%20issues)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Define%20the%20filepath%20for%20the,high%20can%20cause%20VRAM%20issues)[56](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Concept%20page)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Concept%20page)[78](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Prepare%20your%20dataset%20with%20images,and%20varied%29%20captions)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Prepare%20your%20dataset%20with%20images,and%20varied%29%20captions)[101](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Next%20click%20on%20the%20,tab)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=Next%20click%20on%20the%20,tab)[<sub>115</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=6)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers#:~:text=6)Onboarding Guide for Newcomers - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Onboarding-Guide-for-Newcomers>

[19](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=In%20the%20general%20tab%2C%20you,Image%3A%20image)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=In%20the%20general%20tab%2C%20you,Image%3A%20image)[20](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=runtime%20to%20store%20your%20cached,This%20means)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=runtime%20to%20store%20your%20cached,This%20means)[21](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Workspace%20Directory%20%28default%20,backup%20from%20the%20selected%20workspace)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Workspace%20Directory%20%28default%20,backup%20from%20the%20selected%20workspace)[22](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=projects%2Ftries.%20,enable%20and%20disable%20the%20debug)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=projects%2Ftries.%20,enable%20and%20disable%20the%20debug)[23](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=backup%20from%20the%20selected%20workspace,being%20sent%20through%20the%20VAE)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=backup%20from%20the%20selected%20workspace,being%20sent%20through%20the%20VAE)[24](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=mode%20during%20training.%20,All)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=mode%20during%20training.%20,All)[25](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=they%20will%20go%20through%20the,switch%20on%20the%20Debug%20mode)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=they%20will%20go%20through%20the,switch%20on%20the%20Debug%20mode)[26](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=the%20Debug%20mode.%20,for%20how%20often%20you%20would)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=the%20Debug%20mode.%20,for%20how%20often%20you%20would)[27](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Expose%20Tensorboard%20%28default%20,for%20choosing%20the%20GPU%20to)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Expose%20Tensorboard%20%28default%20,for%20choosing%20the%20GPU%20to)[30](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Expose%20Tensorboard%20%28default%20,example%3A%20cuda%3A1)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Expose%20Tensorboard%20%28default%20,example%3A%20cuda%3A1)[31](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Validation%20%28default%20,To%20disable%20this)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Validation%20%28default%20,To%20disable%20this)[34](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=,To%20disable%20this)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=,To%20disable%20this)[35](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Train%20device%20%28default%20,To%20disable%20this)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Train%20device%20%28default%20,To%20disable%20this)[<sub>36</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Temp%20device%20%28default%20,cuda)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General#:~:text=%2A%20Temp%20device%20%28default%20,cuda)General - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/General>

[28](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Validation)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Validation)[29](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,validation%20loss%20graph%20for%20each)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,validation%20loss%20graph%20for%20each)[32](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Quick%20steps%20to%20enable%20it%3A)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Quick%20steps%20to%20enable%20it%3A)[33](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept)[84](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Sections)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Sections)[85](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Train%20Text%20Encoder%20,2)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Train%20Text%20Encoder%20,2)[86](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20text%20encoder%20LR%20overrides,the%20base%20LR%20if%20set)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20text%20encoder%20LR%20overrides,the%20base%20LR%20if%20set)[87](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Optimizer%20Info)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Optimizer%20Info)[90](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20options%20available%20for%20mask,1)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=The%20options%20available%20for%20mask,1)[91](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Normalize%20Masked%20Area%20Loss%3A%20a,of%20the%20image)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Normalize%20Masked%20Area%20Loss%3A%20a,of%20the%20image)[92](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Normalize%20Masked%20Area%20Loss%3A%20a,of%20the%20image)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Normalize%20Masked%20Area%20Loss%3A%20a,of%20the%20image)[93](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Masked%20Training)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=Masked%20Training)[94](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=training%20images,nothing%20where%20the%20mask%20is)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=training%20images,nothing%20where%20the%20mask%20is)[<sub>95</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training#:~:text=,graph%20for%20each%20validation%20concept)Training - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Training>

[37](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Here%20you%20define%20the%20base,to%20both%20LoRA%20and%20Finetune)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Here%20you%20define%20the%20base,to%20both%20LoRA%20and%20Finetune)[38](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=it%20this%20is%20where%20you,SD1.5%20LoRA)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=it%20this%20is%20where%20you,SD1.5%20LoRA)[39](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,a%20custom%20VAE%2C%20provide%20a)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,a%20custom%20VAE%2C%20provide%20a)[41](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=secrets,in%20the%20backup%20tab%20and)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=secrets,in%20the%20backup%20tab%20and)[43](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=it%20this%20is%20where%20you,and%20the%20optional%20checkpoint%20format)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=it%20this%20is%20where%20you,and%20the%20optional%20checkpoint%20format)[44](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Hugging%20Face%20link%20or%20a,unless%20you%20have%20a%20reason)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=Hugging%20Face%20link%20or%20a,unless%20you%20have%20a%20reason)[45](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=saved,unless%20you%20have%20a%20reason)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=saved,unless%20you%20have%20a%20reason)[<sub>46</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,unless%20you%20have%20a%20reason)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model#:~:text=,unless%20you%20have%20a%20reason)Model - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Model>

[40](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Model%20Details%3A)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Model%20Details%3A)[47](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[130](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Flux%20is%20a%20DiT%20Transformer,slow%20model%20to%20work%20with)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Flux%20is%20a%20DiT%20Transformer,slow%20model%20to%20work%20with)[136](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,the%20repo%20must%20be%20in)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,the%20repo%20must%20be%20in)[137](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,work%20and%20are%20likely%20not)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,work%20and%20are%20likely%20not)[138](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,Flux%20Gym%2C%20AI%20Toolkit)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,Flux%20Gym%2C%20AI%20Toolkit)[140](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,quite%20a%20bit%20of%20VRAM)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,quite%20a%20bit%20of%20VRAM)[141](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%2C%20but%20it%20should%20be)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%2C%20but%20it%20should%20be)[142](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,cards%20are%20likely%20too%20close)[143](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Current%20Information%3A)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=Current%20Information%3A)[144](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,to%20produce%20a%20purple%20output)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=,to%20produce%20a%20purple%20output)[<sub>145</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=noted%20that%20a%20grid%20pattern,quite%20a%20bit%20of%20VRAM)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux#:~:text=noted%20that%20a%20grid%20pattern,quite%20a%20bit%20of%20VRAM)Flux - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Flux>

[48](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,according%20to%20generalised%20aspect%20ratios)[49](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,are%20changed%20during%20a%20restart)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,are%20changed%20during%20a%20restart)[50](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=ratios)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=ratios)[51](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,images%20and%20saved%20to%20disc)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=,images%20and%20saved%20to%20disc)[<sub>52</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=images%20and%20saved%20to%20disc)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data#:~:text=images%20and%20saved%20to%20disc)Data - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Data>

[57](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=The%20Concepts%20tab%20configures%20where,want%20to%20use%20during%20training)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=The%20Concepts%20tab%20configures%20where,want%20to%20use%20during%20training)[58](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,using%20the%20currently%20selected%20configuration)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,using%20the%20currently%20selected%20configuration)[59](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=The%20tab%20comprises%20the%20following,elements)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=The%20tab%20comprises%20the%20following,elements)[60](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,concept%20within%20the%20current%20configuration)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,concept%20within%20the%20current%20configuration)[61](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,create%20a%20new%20concept%20configuration)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,create%20a%20new%20concept%20configuration)[62](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,along%20with%20all%20its%20settings)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,along%20with%20all%20its%20settings)[63](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,a%20concept%20from%20the%20configuration)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,a%20concept%20from%20the%20configuration)[64](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Concepts%20Settings%20)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Concepts%20Settings%20)[65](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,provided%20when%20closing%20the%20window)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,provided%20when%20closing%20the%20window)[66](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=OneTrainer%20will%20train%20using%20this,concept)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=OneTrainer%20will%20train%20using%20this,concept)[67](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,can%20also%20click%20the)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,can%20also%20click%20the)[68](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,Choose%20one%20of%20three%20options)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,Choose%20one%20of%20three%20options)[69](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=1,Default%3A%20False)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=1,Default%3A%20False)[70](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=captions%20,From%20image%20file%20name)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=captions%20,From%20image%20file%20name)[71](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=2,Default%3A%20False)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=2,Default%3A%20False)[72](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=For%20example%2C%20,single%20concept%20for%20easier%20management)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=For%20example%2C%20,single%20concept%20for%20easier%20management)[73](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,image%20augmentations%20and%20latent%20caching)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,image%20augmentations%20and%20latent%20caching)[74](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,will%20always%20be%20the%20same)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,will%20always%20be%20the%20same)[75](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,There%20are%20two%20modes)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,There%20are%20two%20modes)[76](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,if%20they%20are%20overly%20influential)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,if%20they%20are%20overly%20influential)[77](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Uses%20an%20exact%20number%20of,if%20they%20are%20overly%20influential)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Uses%20an%20exact%20number%20of,if%20they%20are%20overly%20influential)[79](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Image%20Augmentation%20Tab)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Image%20Augmentation%20Tab)[80](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Image%20Augmentation%20Tab)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=Image%20Augmentation%20Tab)[81](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,centered%20crop%20to%20add%20variety)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,centered%20crop%20to%20add%20variety)[82](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,or%20by%20a%20fixed%20value)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=,or%20by%20a%20fixed%20value)[<sub>83</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=which%20is%20particularly%20important%20for,or%20using%20image%20variations)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts#:~:text=which%20is%20particularly%20important%20for,or%20using%20image%20variations)Concepts -

Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Concepts>

[96](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=LoRA%20Options%20Tab)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=LoRA%20Options%20Tab)[97](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=This%20tab%20is%20only%20visible,top%20right%20dropdown)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=This%20tab%20is%20only%20visible,top%20right%20dropdown)[98](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Image%3A%20image)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Image%3A%20image)[100](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Lycoris%20project%29.%20,data%20that%20can%20be%20stored)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=Lycoris%20project%29.%20,data%20that%20can%20be%20stored)[102](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=warned%20that%20when%20loading%20a,Adaptive)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=warned%20that%20when%20loading%20a,Adaptive)[103](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=layers%20your%20LoRA%20will%20have,known%20as%20DoRA%20and%20can)[104](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=optimizers%20,to%20help%20with%20overfitting%20by)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=optimizers%20,to%20help%20with%20overfitting%20by)[107](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,you%20want%20to%20learn%20more)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,you%20want%20to%20learn%20more)[108](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=techniques,loading%20the%20LoRA%20into%20memory)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=techniques,loading%20the%20LoRA%20into%20memory)[109](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=result%20in%20much%20better%20learning,What%20precision%20is%20used%20when)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=result%20in%20much%20better%20learning,What%20precision%20is%20used%20when)[110](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=%2A%20Dropout%20probability%20%28default%20,you%20train%20additional%20embeddings%2C%20this)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=%2A%20Dropout%20probability%20%28default%20,you%20train%20additional%20embeddings%2C%20this)[111](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,custom)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,custom)[112](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=,either%20attention%20only%20or%20attention%2BMLP)[<sub>155</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=randomly%20ignoring%20a%20percentage%20of,you%20train%20additional%20embeddings%2C%20this)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA#:~:text=randomly%20ignoring%20a%20percentage%20of,you%20train%20additional%20embeddings%2C%20this)LoRA - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/LoRA>

[99](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=LoHa)[ ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=LoHa)[105](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA)[ ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA)[106](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA%20is%20a%20variation%20on,gap%20between%20those%20two%20behaviors)[ ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA%20is%20a%20variation%20on,gap%20between%20those%20two%20behaviors)[113](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=OneTrainer%20now%20has%20the%20ability,want%20in%20the%20text%20field)[ ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=OneTrainer%20now%20has%20the%20ability,want%20in%20the%20text%20field)[114](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=Layer%20)[ ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=Layer%20)[156](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA)[ ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA)[<sub>157</sub>](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA%20is%20a%20variation%20on,gap%20between%20those%20two%20behaviors)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/#:~:text=DoRA%20is%20a%20variation%20on,gap%20between%20those%20two%20behaviors)OneTrainer: New LoRA functionality, DoRA, and more. : r/StableDiﬀusion

[https://www.reddit.com/r/StableDiﬀusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/](https://www.reddit.com/r/StableDiffusion/comments/1ejf0oh/onetrainer_new_lora_functionality_dora_and_more/)

[117](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Dataset%20Tools)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Dataset%20Tools)[118](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=If%20you%20set%20an%20initial,or)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=If%20you%20set%20an%20initial,or)[119](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=A%20tool%20that%20help%20to,BLIP%20and%20BLIP2%20only)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=A%20tool%20that%20help%20to,BLIP%20and%20BLIP2%20only)[120](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Mask%20Generation)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Mask%20Generation)[121](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=With%20ClipSeg%2C%20you%20can%20use,of%20the%20areas%20you%20specify)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=With%20ClipSeg%2C%20you%20can%20use,of%20the%20areas%20you%20specify)[122](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=With%20the%20manual%20paint%20features%2C,trying%20to%20use%20a%20brush)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=With%20the%20manual%20paint%20features%2C,trying%20to%20use%20a%20brush)[123](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Video%20Tools)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=Video%20Tools)[124](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=chunks)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=chunks)[<sub>125</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=necessary%20to%20install%20ffmpeg%20for,some%20video%20formats)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools#:~:text=necessary%20to%20install%20ffmpeg%20for,some%20video%20formats)Tools - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki/Tools>

[<sub>127</sub>](https://www.linkedin.com/pulse/next-level-sd-15-based-models-training-took-me-70-find-g%C3%B6z%C3%BCkara-v5ubf#:~:text=Next%20Level%20SD%201,size%20click%20here%20to%20read)[</sub> ](https://www.linkedin.com/pulse/next-level-sd-15-based-models-training-took-me-70-find-g%C3%B6z%C3%BCkara-v5ubf#:~:text=Next%20Level%20SD%201,size%20click%20here%20to%20read)Next Level SD 1.5 Based Models Training - Took Me 70+ ... - LinkedIn

[https://www.linkedin.com/pulse/next-level-sd-15-based-models-training-took-me-70-ﬁnd-g%C3%B6z%C3%BCkara-v5ubf](https://www.linkedin.com/pulse/next-level-sd-15-based-models-training-took-me-70-find-g%C3%B6z%C3%BCkara-v5ubf)

[128](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Getting%20Started)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Getting%20Started)[129](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Sampling%20and%20Backup)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,Sampling%20and%20Backup)[159](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,28)[ ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,28)[<sub>161</sub>](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,12)[</sub> ](https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index#:~:text=,12)Page Index - Nerogar/OneTrainer GitHub Wiki

<https://github-wiki-see.page/m/Nerogar/OneTrainer/wiki_index>

[131](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=So%20you%20got%20no%20answer,further%2C%20here%20is%20the%20answer)[ ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=So%20you%20got%20no%20answer,further%2C%20here%20is%20the%20answer)[132](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=At%20least%20I%20got%20it,it%20first%2C%20see%20results%20etc)[ ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=At%20least%20I%20got%20it,it%20first%2C%20see%20results%20etc)[133](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=%2A%20Go%20to%20https%3A%2F%2Fhuggingface.co%2Fblack)[ ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=%2A%20Go%20to%20https%3A%2F%2Fhuggingface.co%2Fblack)[134](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=%2A%20go%20to%20the%20%22model%22,base%20model)[ ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=%2A%20go%20to%20the%20%22model%22,base%20model)[135](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,dev)[ ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,dev)[<sub>139</sub>](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,https%3A%2F%2Fgithub.com%2FNerogar%2FOneTrainer)[</sub> ](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/#:~:text=,https%3A%2F%2Fgithub.com%2FNerogar%2FOneTrainer)OneTrainer Flux Training setup mystery solved : r/StableDiﬀusion

[https://www.reddit.com/r/StableDiﬀusion/comments/1f93un3/onetrainer_ﬂux_training_setup_mystery_solved/](https://www.reddit.com/r/StableDiffusion/comments/1f93un3/onetrainer_flux_training_setup_mystery_solved/)

[146](https://lemmy.world/post/1615233#:~:text=OneTrainer%20was%20built%20from%20the,few%20different%20goals%20in%20mind)[ ](https://lemmy.world/post/1615233#:~:text=OneTrainer%20was%20built%20from%20the,few%20different%20goals%20in%20mind)[<sub>147</sub>](https://lemmy.world/post/1615233#:~:text=settings%20if%20you%20know%20what,you%20are%20doing)[</sub> ](https://lemmy.world/post/1615233#:~:text=settings%20if%20you%20know%20what,you%20are%20doing)Releasing OneTrainer, a new training tool for Stable Diﬀusion - Lemmy.World

<https://lemmy.world/post/1615233>

[<sub>158</sub>](https://github.com/comfyanonymous/ComfyUI/issues/6673#:~:text=Add%20Support%20For%20OT%20Lora%2C,Lora%2C%20LoHa%2C%20Dora%20with)[</sub> ](https://github.com/comfyanonymous/ComfyUI/issues/6673#:~:text=Add%20Support%20For%20OT%20Lora%2C,Lora%2C%20LoHa%2C%20Dora%20with)Add Support For OT Lora, Loha and Dora for HunYuan Video in ...

<https://github.com/comfyanonymous/ComfyUI/issues/6673>

28

![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref1]![ref1]![ref7]![ref7]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref7]![ref7]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref1]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref1]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]![ref7]

[ref1]: data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAASABMDASIAAhEBAxEB/8QAGQABAQADAQAAAAAAAAAAAAAAAAUDBAcK/8QAJxAAAgEDAwMDBQAAAAAAAAAAAQIDABEhBAUSEzFRBiJBYXFygcH/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A9x2+7vueg3HcI4tz1CquqCqoBAVbtYLZza98drVLPqHeby8901PAyW6fu7D5vzIz/PBp6hTnve6M3XeNmMsQCPbmC2QQuRkWBuD4zmMq9eGQsNR1SFsOk6jnm/ZRe+MdsfsB2/b9bNJotK7GdmaFCWLWJJHcjlSse0qF23RK6S8xp0DXkkGQPAYAfalBQ1cMJncmKMnGSik9vJFa8kEAhS0MQ957RoPj8aUoLunVRBEAotxHwPrSlKD/2Q==
[ref2]: data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZACkDASIAAhEBAxEB/8QAGwAAAgMAAwAAAAAAAAAAAAAABgcAAQUDCAr/xAA+EAABAwMCAwIHDQkAAAAAAAABAgMFBAYRAAcSEyExQRQVFhciMlIzNUJTVFVXcXN0lrLUgZGSk5Wx0dPW/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APbe2qbvmcvJinueUhLNtyRatukpLab8T3O7dEVz0zgEjz6lBh3E1FFym+QFVJSpa1M8hKXSOl2www2kbg7pNlCUoU3T3hxNJWkAKCVmPTzMH4fCnj7QAOmuDa9ll1e47jgWE02695sHjJUVJBjQQCeoZcyC4gDhWUoKvVGHKzTsNtNtIbQENJS0kJQEJSEDhCUpHRIAGAB0HdoFT5sVfSJux+Lx+g1R2yIBJ3E3XwASeK7gU4AyeIeA9RjtHeOmm3ymvYT+7U5bQ68CRjrnHZjrnpoOtVyUM9tvB1V1xV5XLWx0BWU0ndsddlZ5SIdtCic8LmFWykCPDMg9Rh9KC4cPvhLCw0lsOrZHlVb3xTv9LR+s1k70U7FNtLuU8ykjwWyrkIaZTyxxmOqXSW0pwEOOcQDikgFxISlXQdAv0fZd/jV/nQFLc1CbdSkxRy3jimoJ2alJ5Ui1F18tTVNVJKpzhtERTyFShaUsEq5rLYIUME4IG0N7ttznErNeiopObJvkdUnBxm2xkZ7CMg9xOjpz3CM+0b/KvWwv1j+z+w0Cu89u3HzrM/gq+P8Am9Ud7tt0gkyszgAk4sm+ScAZOALbJP1AEnu00NTQI64LztbcCNkLRhDOSqbioa2grG0QE1FBlivpjSh512coIxrlt5UtSUuKcIHRB7NE/kVS/Kaj+cj/AGaPUe+zn3ZH53NYmg//2Q==
[ref3]: data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZADEDASIAAhEBAxEB/8QAGQAAAwEBAQAAAAAAAAAAAAAAAAUHBgMK/8QAPRAAAQMCAwMGBxEAAAAAAAAAAgEDBQAEBgcTERIhFRciMVWWUVJXYZHU1hQyNEFUcnOBkpOVsbPC0dLT/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APbc2U7jifxkxb4nkoTBOHL9rDdra4aa5IxS7iqKW4ScQJHXuW1h3BuLHSDQ23SiZGrGkKOaS0yw2W7QpmBmk0oCgE3b4wQmxJOtEPk8dRfCe6m94K4ZXssulmO44jiDa5sYzZ2GqmpAnJqKibdq6Tm1NQETYe6O1NgpVjYt2G2W2gbBAaFGxQQQBFB4IIinBEROCInCglfNiXlEzY73p6hRzYl5RM2O96eoVWtJrxB9FGk14g+igkvNiXlEzY73p6hSTEpyGWUEslaz07iCzWdhmZZjF18sne3DErd2sNbjFyCAyliNrdXrF25vMO75ME30d9DG66TXiD6Kj+eVqw5l5fgbaE27O4LFxteIHuYzgDFSFeCqiiibVTq4UFC9zOfLr78SH/GimPJEX2fafcN/1ooI8EzC5dycvZyyTFtYTs1KzpyTUZfS1tc3MkttwbbiWL+6Aw0OlqsNoSGOxV3VRHQ53ZbrtRJWa6KqK7cE45TiPBevDfFPOm1F+JVrcu/B4v6Vr91OF6/qH8koJfz25cdqzPcrHHs3Rz25cdqzPcrHHs3VPooJhz25cdqzPcrHHs3SnEM7h7NmBvMM4WlnhvxkIG/M5WAxNE24tRU5Gyzwa0lDWoEbrFmbbSApJqmCGojvENlpe/7975qfp0DHXHzfbH+aKz1FB//Z
[ref4]: data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAD8DASIAAhEBAxEB/8QAGgABAQEAAwEAAAAAAAAAAAAABwAFAQMGCv/EADYQAAIBAgQDBAgEBwAAAAAAAAECAwQFAAYHERITIRUXIpYxQVJVV5HU1hZRc7E0NWFygbTC/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuja+54v8AnKCnzPcrJknLlfFlulpctRdkZplzVajUC+BLjz6mM2eRaih5ScjeqKuzmDlKJPSUmmG1PEo1A1SiKKEaOnzgGjVh6QH7PXmH834Rxfljo0vhhlbUeSQSBaXVjOcOzkuWQdmggb7nlSbjmIBs/Cu42UYY4KeCOGOJI0CRKI1CoEVQvQKqjoAB0AHTAFfdi3xE1Y83j6DF3Yt8RNWPN4+gwtcqL2F+WLlRewvywBL3Yt8RNWPN4+gxd2LfETVjzePoMLXKi9hfli5UXsL8sAO1WlrTRPCuomrCzSo6wzLnERSQuFJ4km7PcxE7cJYI/QkbevHFvlrMsX+x2K7Zxud/o81RVlBlime3iW+09XYqCS5XWS5ZketVq5XggmKjsun3YhdyPEV6WngI5hiTmRK7RPwjijYoVLI3pUkEjcerBbm6NRqRo5I28jm4Z1KtJ4zGTk2sDGIkbxlx0cqRxAkHocBkJebLp3c7vR3YXimoL7errfXuUVsrrtTVNTcjTdI47TBX1SOnI8XNgjDB12J4SBtLrdpudwLrevCSp3yTnkdV6H05b6j+o3B9ROPcy/w9r/Vi/wCsbB9P+F/YYAv77dOPet58lZ4+28Xfbpx71vPkrPH23hPxYAw77dOPet58lZ4+28Xfbpx71vPkrPH23hPxYAufWzThhyxdbzxSBlXfJOedt+EnxN+G9lG3rYj8huemM2C7U+fc45Kvlkiq1s2TqjME1bcLhRVltSrN2sNRaoYqOCvgpqsvHPKrSmaCJAm/CzMOHDIPQ/8AY37Yw1/lMn67f7DYD//Z
[ref5]: data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAGMDASIAAhEBAxEB/8QAHAABAQEAAQUAAAAAAAAAAAAAAAcGBQECAwQK/8QANBAAAQIEAwYGAQEJAAAAAAAAAgEDAAQFBgcRExIXITFVlhVSV5HU1iJRMjRBQmFzgbHC/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuaKvXzX7yYl7nqdDsm3J9q3JSVtpvwi6XbrpKzCVsQqOvMtrSHRfkdFvRzm1E1NWNIdTSSuGOUu2I4gYpNbAoJAxeCE2JJzRD8PHbX9T2Uz/SPBheyy6WI7jiOIMrixebS7aqSkA+G5oirx0nOGoCJk5sjmmQpFkYl2G2W2gbBBaFGxQQQBFB5CIpwRE5IicICVbsS9RMWO70+BDdiXqJix3enwIrWk15B9oaTXkH2gJLuxL1ExY7vT4EN2JeomLHd6fAitaTXkH2hpNeQfaAku7EvUTFju9PgQ3Yl6iYsd3p8CK1pNeQfaGk15B9oCS7sS9RMWO70+BDdiXqJix3enwIrWk15B9oaTXkH2gI+9hi6mwbeI2KqEBKqC5eSg2akiiiGg009tEVdrZXZ4pzj1xsCt0t2ZdoeIl+uzziDml21Qbgoqo4IircnLiMiUu7mq6bykekaoewWzktqEAFcxFEVeHBMo7dFvaI0BEMkyU0TI+WX7XPlygM1ZVwSV0WxS63IOK9LzKTcurpDsq5M0yfmqXOns5rkhTslMEnFc0VFhGXwZ2d3NEQG22hScuZEBoEbBMrqreaoI5IikuZEv8AMakS8VWEBngrNFw6qdXk6sNYlpCu1qrVw6k1TJ6rS0zM1NZfg23SWJ+aAg0cy1WG0JDHJVyVE5ocbsN1zRKrWvxVRXOyb5TiPBedt8U/qmaL/BVjcu/u9L/utf8AUcwvP/A/6SAl++3DjqtZ7Kvj63Dfbhx1Ws9lXx9binwgJhvtw46rWeyr4+tw324cdVrPZV8fW4p8ICYb7cOOq1nsq+PrcN9uHHVaz2VfH1uKfCAmG+3DjqtZ7Kvj63Dfbhx1Ws9lXx9binwgJhvtw46rWeyr4+tx0XGqwnEVuRm65PTriKEnIt2hd8u5OTRfjLyoTE7QpaTYOYdUGRem5iXlmiNDfeaaEzGoQgMbhpRZ63rKo1KqTaNTrR1SaeaQkJWfE6zUKm2yZCqirjTM4227sEQagnsEQ5EqN1CA/9k=
[ref6]: data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAEAAQDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAr/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/AL+AAf/Z
[ref7]: data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAASABQDASIAAhEBAxEB/8QAGgABAAIDAQAAAAAAAAAAAAAAAAQFAgYHCv/EACsQAQABAgMGBgIDAAAAAAAAAAECAxEABAUGEiEjMVETFCIyQYFxg9HS4f/EABQBAQAAAAAAAAAAAAAAAAAAAAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD3H65q+qZHUc9Ro6nmCJnCMYhItHmWAJpb82/inNo9bGW9qeZDzQC7zYVuW3+n+fee0MN7WtUk+PODPxaNqckKgyLnD1CPRudG3TFLB8WcIzjmE3WpPlSjzSLZuAlngg2e3YOo7P5jO5rJ1atXUa85Obqgo3IlOkh7u6v3hiHsn6NK5s62/LNV5N6cjhaBHpE+A+MMBu+bo0WvNaVNeHFhFendMRvL0DpQon64f1wwwFplqdONGBGnAPVwIxD3PwGGGGA//9k=
[ref8]: data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAAZAEYDASIAAhEBAxEB/8QAHAABAQABBQEAAAAAAAAAAAAABwAEAQIDBQYK/8QAOhAAAQIEAwMIBgsBAAAAAAAAAQIDAAQFBgcRExchlhIxUlVXkdTWFRYiNFHCJCYzQUJxcnN0gbGy/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APtuaVXr5r95MS9z1Oh2Tbk+1bkpK2036Iul266SZgVtKKjrzLZpDqX5HRb0c5spWVljSTqeklMMfo7aU4gYpNFCQhTbF4BTaVDnAX6PTyzvGauSM/hHBheyy6rEdxwOBMrixebR5ZKipCfRuYBO/Sc3aiAMnOSnMZJEMbEuw2y20htsJaSGwEoCEpCfwpSNwAz5hugCvZirtExY4vHgItmKu0TFji8eAha0mugnui0mugnugCXZirtExY4vHgItmKu0TFji8eAha0mugnui0mugnugCXZirtExY4vHgI0VhieSc8Q8WCMjmPW4HMZbxkZHI582Rhb0mugnui0Wjztp7hACguGdo94ydlzMy7UJNy0F1ilzz7uhWZdqkzlLpU1LVWaIdTPvzb1RRMreShkBbJ9hXLzFGBddPk3sY7fD7Db4bwzuZLYeSlwISq6bVUUoChklIyASBkANwigMxFZouHVTq8nVk1iWkK7WqtXF1JqmT1WlpmZqZl9zbdJYn5pCkaOatVhsKC05E5EDuU43YbnMCq1r2CUHOyb5G8c/PbYzHwIzB+4mPdO+70v8Ada+aO4PP/Sf8EAX7bcOOtazwVfHluLbbhx1rWeCr48twnxQBhttw461rPBV8eW4ttuHHWtZ4Kvjy3CfFAGG23DjrWs8FXx5biONuHABJqtZyG8/Uq+PLcJ8bHPs3P0K/5MAJF83dfdDvKgy83N0H1Hr9JEy9JzVOcM29cNAmWkmVqbMnNoDjMo84krYTmB+WdDHJe7yv8ZPyxQH/2Q==
[ref9]: data:image/jpeg;base64,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
